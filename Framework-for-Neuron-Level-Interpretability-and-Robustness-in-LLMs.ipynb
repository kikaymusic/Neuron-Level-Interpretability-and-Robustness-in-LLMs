{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6592af2-0359-415a-9624-d5b3e3768e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class F1Tracker:\n",
    "    def __init__(self, experiment_name, save_csv=True, csv_path=\"f1_results.csv\"):\n",
    "        self.experiment_name = experiment_name\n",
    "        self.percent_silenced = []\n",
    "        self.f1_scores = []\n",
    "        self.save_csv = save_csv\n",
    "        self.csv_path = csv_path\n",
    "        if self.save_csv:\n",
    "            with open(self.csv_path, mode='w', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow([\"experiment\", \"percent_silenced\", \"f1_score\"])\n",
    "\n",
    "    def add(self, percent, f1_score):\n",
    "        self.percent_silenced.append(percent)\n",
    "        self.f1_scores.append(f1_score)\n",
    "        if self.save_csv:\n",
    "            with open(self.csv_path, mode='a', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow([self.experiment_name, percent, f1_score])\n",
    "\n",
    "    def plot(self, show=True, save_path=None):\n",
    "        plt.plot(self.percent_silenced, self.f1_scores, marker='o')\n",
    "        plt.title(f\"F1-score - {self.experiment_name}\")\n",
    "        plt.xlabel(\"% Neuronas Silenciadas\")\n",
    "        plt.ylabel(\"F1-score\")\n",
    "        plt.ylim(0, 1)\n",
    "        plt.grid(True)\n",
    "        if save_path:\n",
    "            plt.savefig(save_path, bbox_inches='tight')\n",
    "        if show:\n",
    "            plt.show()\n",
    "        plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b95ddde-9331-4825-abeb-7d82472f93e6",
   "metadata": {},
   "source": [
    "# Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7b992ac-9b02-4d2e-8db1-aa133bfd0345",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import json\n",
    "import logging\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from transformers import AutoTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import neurox.data.extraction.transformers_extractor as transformers_extractor\n",
    "from neurox.data.writer import ActivationsWriter\n",
    "import neurox.data.loader as data_loader\n",
    "from transformers import AutoConfig\n",
    "from tqdm import tqdm\n",
    "import neurox.interpretation.linear_probe as linear_probe\n",
    "import neurox.interpretation.utils as utils\n",
    "import neurox.analysis.visualization as TransformersVisualizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import display\n",
    "import neurox.interpretation.probeless as probeless\n",
    "from neurox.interpretation.probeless import (\n",
    "    get_neuron_ordering,\n",
    "    get_neuron_ordering_for_all_tags\n",
    ")\n",
    "import ast\n",
    "from torch.cuda.amp import autocast\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from matplotlib_venn import venn2\n",
    "from neurox.interpretation.linear_probe import get_top_neurons\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "146875e6-a0bb-4f13-8ef4-14e4017c9de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 13:03:14,528 - INFO - üöÄ Logging configured\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "# ==========================\n",
    "# üìú Configure Logging \n",
    "# ==========================\n",
    "\n",
    "logger = logging.getLogger(\"synapse_logger\")\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Avoid duplicates\n",
    "if not logger.hasHandlers():\n",
    "\n",
    "    # üìÅ Handler \n",
    "    file_handler = logging.FileHandler(\"logs/synapse_extraction_csv_pth.log\", mode=\"w\")\n",
    "    file_handler.setLevel(logging.INFO)\n",
    "\n",
    "    # üñ•Ô∏è Handler \n",
    "    console_handler = logging.StreamHandler()\n",
    "    console_handler.setLevel(logging.INFO)\n",
    "\n",
    "    # Format\n",
    "    formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "    file_handler.setFormatter(formatter)\n",
    "    console_handler.setFormatter(formatter)\n",
    "\n",
    "    # Add handlers to main logger\n",
    "    logger.addHandler(file_handler)\n",
    "    logger.addHandler(console_handler)\n",
    "\n",
    "logger.info(\"üöÄ Logging configured\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8d46986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# SYNAPSE Model Configuration\n",
    "# ==========================\n",
    "\n",
    "# üß† Select the model (options: \"BERT\", \"BigBird\", \"DistilBERT\", \"Longformer\")\n",
    "MODEL = \"BigBird\"\n",
    "\n",
    "# üìÅ Paths based on model name\n",
    "BASE_PATH = f\"data/{MODEL}\"\n",
    "input_csv = f\"{BASE_PATH}/{MODEL}_tokens_PT.csv\"\n",
    "output_csv = f\"{BASE_PATH}/reduced/{MODEL}_tokens_reduced.csv\"\n",
    "labels_output_path = f\"{BASE_PATH}/labels_numeric.txt\"\n",
    "label_mapping_path = f\"{BASE_PATH}/labels_mapping.json\"\n",
    "activations_file = f\"{BASE_PATH}/activations.json\"\n",
    "weights_path = f\"{BASE_PATH}/best_model_{MODEL}.pth\"\n",
    "\n",
    "# üî¢ Number of labels\n",
    "NUM_LABELS = 5\n",
    "\n",
    "\n",
    "# üîß HuggingFace model mapping\n",
    "MODEL_HF = {\n",
    "    \"BERT\": \"bert-base-uncased\",\n",
    "    \"BigBird\": \"google/bigbird-roberta-base\",\n",
    "    \"DistilBERT\": \"distilbert-base-uncased\",\n",
    "    \"Longformer\": \"allenai/longformer-base-4096\"\n",
    "}[MODEL]\n",
    "\n",
    "# ‚öôÔ∏è Device selection\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7aa70ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded BigBird with pretrained weights on cpu\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# Load Model and Weights\n",
    "# ==========================\n",
    "from transformers import AutoConfig\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_HF, num_labels=NUM_LABELS)\n",
    "\n",
    "# Load trained weights from disk\n",
    "state_dict = torch.load(weights_path, map_location=device)\n",
    "model.load_state_dict(state_dict)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"‚úÖ Loaded {MODEL} with pretrained weights on {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d374908b-8bfa-4ea8-8ea5-0606a7beb8f4",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "603211a2-0c14-4ede-b934-e232421f3d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 13:03:16,055 - INFO - ‚ö° Reduced dataset found: data/BigBird/reduced/BigBird_tokens_reduced.csv. Skipping reduction.\n"
     ]
    }
   ],
   "source": [
    "reduction_ratio = 0.001\n",
    "\n",
    "# ==========================\n",
    "# ‚úÖ Skip dataset reduction if already available\n",
    "# ==========================\n",
    "if os.path.exists(output_csv) and os.path.exists(labels_output_path):\n",
    "    logger.info(f\"‚ö° Reduced dataset found: {output_csv}. Skipping reduction.\")\n",
    "    df_reduced = pd.read_csv(output_csv)\n",
    "    with open(labels_output_path, \"r\") as f:\n",
    "        labels = [int(line.strip()) for line in f]  # Labels as integers\n",
    "    with open(label_mapping_path, \"r\") as f:\n",
    "        label_mapping = json.load(f)  # Load label mapping\n",
    "else:\n",
    "    logger.info(f\"üîÑ Loading dataset from {input_csv}\")\n",
    "\n",
    "    chunk_size = 5000 \n",
    "    total_rows = sum(1 for _ in open(input_csv)) - 1  # Total rows excluding header\n",
    "    df_chunks = []\n",
    "\n",
    "    logger.info(f\"üîÑ Processing {total_rows} rows in chunks of {chunk_size}...\")\n",
    "\n",
    "    with tqdm(total=total_rows, desc=\"Processing rows\", unit=\" rows\") as pbar:\n",
    "        for chunk in pd.read_csv(input_csv, chunksize=chunk_size):\n",
    "            # Convert `input_ids` from string to list of integers\n",
    "            chunk['input_ids'] = chunk['input_ids'].apply(lambda x: list(map(int, x.strip(\"[]\").split(\",\"))))\n",
    "            df_chunks.append(chunk)\n",
    "            pbar.update(len(chunk))\n",
    "\n",
    "    df = pd.concat(df_chunks, ignore_index=True)\n",
    "\n",
    "    # ==========================\n",
    "    # üî¢ Encode labels as integers\n",
    "    # ==========================\n",
    "    df['label'], unique_labels = pd.factorize(df[\"label\"])\n",
    "    label_mapping = {label: int(idx) for idx, label in enumerate(unique_labels)}\n",
    "\n",
    "    # ==========================\n",
    "    # üß™ Reduce dataset maintaining class proportions\n",
    "    # ==========================\n",
    "    df_reduced, _ = train_test_split(df, train_size=reduction_ratio, stratify=df[\"label\"], random_state=42)\n",
    "    labels = df_reduced[\"label\"].tolist()\n",
    "\n",
    "    # ==========================\n",
    "    # üíæ Save reduced dataset and labels\n",
    "    # ==========================\n",
    "    df_reduced.to_csv(output_csv, index=False)\n",
    "    with open(labels_output_path, \"w\") as f:\n",
    "        for label in labels:\n",
    "            f.write(str(label) + \"\\n\")\n",
    "\n",
    "    with open(label_mapping_path, \"w\") as f:\n",
    "        json.dump(label_mapping, f, indent=4)\n",
    "\n",
    "    logger.info(f\"‚úÖ Reduced dataset saved to {output_csv}\")\n",
    "    logger.info(f\"‚úÖ Numeric labels saved to {labels_output_path}\")\n",
    "    logger.info(f\"‚úÖ Label mapping saved to {label_mapping_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997a332b-cc98-4354-b752-ad1134ad730c",
   "metadata": {},
   "source": [
    "### Create Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "495d4540-bc59-4807-b0af-8ffbd01daae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 13:03:16,402 - INFO - ‚úÖ Dataloader created\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# üì¶ Create DataLoader\n",
    "# ==========================\n",
    "class SyscallDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.data = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ids = torch.tensor(self.data.iloc[idx]['input_ids'])\n",
    "        label = torch.tensor(self.data.iloc[idx]['label'])\n",
    "        return input_ids, label\n",
    "\n",
    "# Initialize DataLoader with reduced dataset\n",
    "dataset = SyscallDataset(df_reduced)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "logger.info(\"‚úÖ Dataloader created\")\n",
    "\n",
    "# Ensure `input_ids` are lists of integers\n",
    "if isinstance(df_reduced[\"input_ids\"].iloc[0], str):\n",
    "    df_reduced[\"input_ids\"] = df_reduced[\"input_ids\"].apply(lambda x: list(map(int, x.strip(\"[]\").split(\",\"))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0da9ae4-251e-4f65-b65f-9663fc90f02c",
   "metadata": {},
   "source": [
    "# NeuroX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a112e7-860d-47fd-9d6d-eab42bc5be5f",
   "metadata": {},
   "source": [
    "## Activation Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08e2b162-ca24-4599-a29d-879d176fddf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 13:03:18,724 - INFO - ‚ö° Activations file found: data/BigBird/activations.json. Skipping extraction.\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(activations_file):\n",
    "    logger.info(f\"‚ö° Activations file found: {activations_file}. Skipping extraction.\")\n",
    "else:\n",
    "    transformers_extractor.extract_representations(\n",
    "        model, \n",
    "        df_reduced[\"input_ids\"].tolist(),  # Pass preprocessed tokens directly\n",
    "        activations_file,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    logger.info(f\"‚úÖ Activations saved to {activations_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf78272a-01de-43f0-a26d-9d93367256f2",
   "metadata": {},
   "source": [
    "## Load Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b34f817a-3592-4a9d-9b38-f9f18ed497b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 13:03:19,649 - INFO - ‚úÖ Loaded activations from data/BigBird/activations.json with 12 layers\n",
      "2025-07-09 13:03:19,659 - INFO - ‚úÖ Created input/output tensors and label mappings for classification\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading json activations from data/BigBird/activations.json...\n",
      "50 12.0\n",
      "Number of tokens:  50\n",
      "length of source dictionary:  17\n",
      "length of target dictionary:  5\n",
      "50\n",
      "Total instances: 50\n",
      "['s']\n",
      "Number of samples:  50\n",
      "Stats: Labels with their frequencies in the final set\n",
      "1 10\n",
      "3 15\n",
      "0 7\n",
      "4 9\n",
      "2 9\n"
     ]
    }
   ],
   "source": [
    "activations, num_layers = data_loader.load_activations(activations_file)\n",
    "logger.info(f\"‚úÖ Loaded activations from {activations_file} with {num_layers} layers\")\n",
    "\n",
    "# Load sentence-level classification data using activations\n",
    "tokens = data_loader.load_sentence_data(\n",
    "    output_csv, labels_output_path, activations\n",
    ")\n",
    "\n",
    "# Create sentence-level tensors for classification\n",
    "X, y, mapping = utils.create_tensors(\n",
    "    tokens,\n",
    "    activations,\n",
    "    task_specific_tag=\"NN\",\n",
    "    task_type=\"classification\"\n",
    ")\n",
    "\n",
    "label2idx, idx2label, src2idx, idx2src = mapping\n",
    "logger.info(\"‚úÖ Created input/output tensors and label mappings for classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cafa0a1-baf1-4926-a84a-bba21b52226b",
   "metadata": {},
   "source": [
    "## Train linear probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bea62171-4a9b-4c24-8ff5-7908550291da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases en y_train: [0 1 2 3 4]\n",
      "Training classification probe\n",
      "Creating model...\n",
      "Number of training instances: 50\n",
      "Number of classes: 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4806f4c82164f99ae33f7730e5c3c84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch [1/10]: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/10], Loss: 0.0820\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e53e0bce86ac4e2ba4eda5068bf40369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch [2/10]: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2/10], Loss: 0.0427\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "905ef547fab344aca400b1c0e65e048e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch [3/10]: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3/10], Loss: 0.0273\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30f1ea2c91ac4c449ba07254dcf49701",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch [4/10]: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4/10], Loss: 0.0251\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fcf561e7198431bbb4b414e29802634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch [5/10]: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5/10], Loss: 0.0199\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "959e9cda59dc4a44a10b03f27b60908d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch [6/10]: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6/10], Loss: 0.0168\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38307958756a4ef79ceec0e8f57af6e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch [7/10]: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7/10], Loss: 0.0164\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acbb7730ca8449d395b181615fe8ea4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch [8/10]: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8/10], Loss: 0.0160\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef0caac3f96549ceb707d7a29490492d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch [9/10]: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9/10], Loss: 0.0152\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bdf49dadcf5420885728b37cf9fe5bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch [10/10]: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10/10], Loss: 0.0144\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebe7954c67314729bdf313b3b605333b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 13:03:20,779 - INFO - üéØ Probe evaluation results: {'__OVERALL__': np.float64(0.96), '1': np.float64(1.0), '3': np.float64(0.9333333333333333), '0': np.float64(1.0), '4': np.float64(1.0), '2': np.float64(0.8888888888888888)}\n",
      "2025-07-09 13:03:20,783 - INFO - üîç Top global neurons: [8193 8194 6152 ... 4093 6142 8191]\n",
      "2025-07-09 13:03:20,785 - INFO - üîç Top neurons per class: {'1': array([6272, 8698, 8468, 5669, 7878, 9116, 9077, 7328, 8480, 7111, 8466,\n",
      "       7730, 8745, 9148, 8678, 9183, 8982, 6387, 7962, 9006, 6602, 8582,\n",
      "       8645, 6398, 8182, 9021, 8795, 6502, 5629, 9072, 9098, 8349, 8751,\n",
      "       7585, 7468, 7166, 7963, 7794, 9195, 6993, 8842, 7805, 7968, 8135,\n",
      "       9134, 8249, 8565, 8867, 9047, 7862, 8132, 7027, 9184, 8584, 8519,\n",
      "       8296, 8116, 7257, 7474, 8156, 8457, 8913, 8212, 7971, 6276, 9182,\n",
      "       9210, 7074, 7795, 9200, 8718, 9208, 7165, 7959, 8781, 8464, 8664,\n",
      "       8624, 8518, 8895, 7956, 8052, 8625, 7561, 9025, 8752, 5920, 7109,\n",
      "       8383, 8337, 9099, 8800, 8136, 6687, 8647, 9186, 9003, 5617, 8080,\n",
      "       9175, 7912, 8760, 8915, 6279, 7783, 8884, 6061, 7056, 5408, 7588,\n",
      "       6508, 9170, 5454, 4806, 8124, 7212, 8719, 4746, 8950, 7297, 4372,\n",
      "       9130, 6756, 5832, 5855, 7246, 8796, 8778, 8465, 7541, 9106, 9149,\n",
      "       9190, 8095, 6956, 9007, 7699, 8757, 8492, 6514, 8012, 8061, 6258,\n",
      "       7293, 7499, 6947, 7279, 6155, 8527, 5545, 8385, 5692, 6331, 7838,\n",
      "       8440, 8875, 6404, 6403, 6182, 8024, 8886, 8705, 5602, 6580, 8517,\n",
      "       7955, 6583, 8402, 6491, 6767, 7194, 7793, 8031, 6988, 6777, 8691,\n",
      "       7093, 8108, 6694, 8865, 6806, 8088, 6177, 9040, 8073, 8297, 7449,\n",
      "       8470, 9163, 6803, 6916, 7924, 7026, 5308, 8675, 8341, 8804, 4623,\n",
      "       9090, 8593, 8692, 8605, 7231, 8847, 7648, 6028, 8704, 6295, 6236,\n",
      "       9160, 8735, 7274, 6198, 7223, 7151, 4817, 7248, 4335, 8765, 7729,\n",
      "       8573, 8509, 6380, 5313, 6525, 8020, 6478, 8922, 7948, 7988, 9027,\n",
      "       7358, 8814, 6269, 9213, 5407, 6385, 6378, 8217, 8067, 4174, 4448,\n",
      "       7999, 3232, 5796, 8925, 7844, 7895, 5828, 5420, 8589, 8858, 3114,\n",
      "       7507, 5290, 5847, 8812, 8960, 5695, 7409]), '3': array([5832, 8508, 9196, 8869, 6272, 9035, 9215, 8122, 8851, 8894, 8954,\n",
      "       9175, 8811, 8722, 8940, 6165, 8893, 9150, 8528, 8029, 8589, 6600,\n",
      "       9152, 8975, 9203, 8321, 8596, 9183, 8784, 8848, 8707, 4937, 9084,\n",
      "       8859, 8985, 8451, 8809, 7746, 8774, 9125, 8477, 4799, 7018, 8571,\n",
      "       8170, 9186, 5945, 8827, 8525, 8534, 8619, 8654, 8674, 8771, 5926,\n",
      "       9176, 8254, 8884, 8641, 9016, 8963, 7693, 9087, 8284, 7854, 5206,\n",
      "       8552, 6223, 8514, 9157, 9110, 8562, 9213, 8702, 8672, 8943, 8219,\n",
      "       8473, 4429, 3888, 5935, 8025, 8517, 5614, 5956, 8461, 5000, 8713,\n",
      "       4184, 8669, 8027, 5136, 8549, 5390, 3999, 8585, 6152, 8658, 7104,\n",
      "       5506, 8696, 5127, 9031, 8277, 9028, 6926, 7952, 8502, 8681, 6142,\n",
      "       8987, 8878, 3360, 8098, 8021, 8288, 9121, 8561, 8509, 8504, 8014,\n",
      "       8441, 8532, 5076, 8675, 8891, 8973, 8990, 8904, 8453, 8496, 6381,\n",
      "       7869, 7873, 8925, 7843, 7250, 8693, 5688, 8651, 4491, 9005, 8467,\n",
      "       8821, 9136, 8048, 9046, 8901, 8407, 8425, 8909, 8716, 7519, 8013,\n",
      "       8728, 9140, 8816, 8883, 5978, 8879, 7907, 8929, 5889, 9083, 8311,\n",
      "       8418, 8621, 8895, 9168, 6285, 8250, 4817, 5411, 9073, 8719, 9149,\n",
      "       7577, 6098, 8230, 7931, 8427, 8664, 8563, 9002, 6552, 8486, 8319,\n",
      "       8794, 8505, 7616, 7659, 9082, 8593, 9067, 8521, 7819, 8812, 9074,\n",
      "       6866, 9020, 5854,  356, 8344, 8866, 5904, 7887, 5356, 8258, 8765,\n",
      "       8808, 9096, 7475, 3315, 5279, 3856, 7444, 7151, 7188, 3842, 8499,\n",
      "       5916, 7889, 8911, 8305, 4926, 7808, 8474, 6999, 8695, 7775, 9042,\n",
      "       3536, 4998, 8898, 8000, 6030, 8083, 8600, 8845, 4454, 5427, 8128,\n",
      "       7220]), '0': array([8898, 7693, 8602, 7923, 7842, 6629, 9023, 8966, 8852, 7161, 8773,\n",
      "       9139, 8709, 8677, 9135, 8761, 5803, 8664, 3509, 8417, 8484, 8781,\n",
      "       8554, 7928, 8829, 3998, 8762, 8710, 7561, 5916, 6293, 8958, 8795,\n",
      "       7287, 8029, 8517, 7468, 8978, 8715, 9075, 7819, 8019, 5925, 8053,\n",
      "       8590, 8515, 8837, 8808, 4783, 5506, 8499, 9205, 7564, 6100, 8721,\n",
      "       5696, 8885, 8555, 8486, 9155, 8650, 7873, 9201, 8563, 1830, 8326,\n",
      "       7963, 7708, 1566, 6021, 9070, 8726, 7461, 4215, 8463, 7056, 8702,\n",
      "       8810, 2154, 7087, 8705, 8866, 7896, 8345, 8520, 8877, 7286, 8839,\n",
      "       8730, 7317, 8822, 8518, 2295, 8951, 8787, 9027, 7786, 8769, 8993,\n",
      "       8799, 9001, 9195, 7797, 7743, 5846, 8031, 9171, 4421, 6985, 9161,\n",
      "       8507, 5257, 7737, 6575, 8249, 8651, 8529, 4357, 8902, 8656, 5267,\n",
      "       9143, 7011, 6167, 8669, 6165, 3697, 8023, 8962, 7783, 8990, 8105,\n",
      "       8511, 3363, 6413, 8604, 8576, 8991, 9206, 8904, 8429, 8798, 9028,\n",
      "       8134, 8388, 8820, 8170, 8848, 4221, 8766, 8468, 8001, 1829, 5824,\n",
      "       1569, 8663,  527, 8936, 1803, 7767, 7167, 8753, 7101, 8765, 5385,\n",
      "       8727, 8679, 7456, 7033, 6325, 9162, 9065, 3375, 8862, 8647, 7438,\n",
      "       8099, 7018, 8405, 8512, 7774, 8593, 5477, 8558, 8545, 7822, 5956,\n",
      "       6134, 3723, 8814, 8245, 8763, 8843, 8642, 3763, 7668, 8073, 6003,\n",
      "       6680, 9175, 9117, 9214, 2450, 7753, 7919, 5660, 5245, 7732, 6506,\n",
      "       7771, 6677, 9049, 8193, 8793, 5557, 7102, 7447, 6142, 3888, 6383,\n",
      "       7304, 2279, 7932, 8853, 5783, 7223, 9160, 4142, 8352, 5967, 9192,\n",
      "       7388, 1903, 9215, 5975, 5000, 9212, 2810, 9105, 7171, 7909, 6909,\n",
      "       8645, 8955, 8747, 6285, 8451, 8984, 4747, 8533, 9038, 7698, 7104,\n",
      "       8708, 8272]), '4': array([8611, 7797, 8327, 9207, 8234, 9199, 8872, 8612, 8761, 8490, 8724,\n",
      "       9035, 9211, 8920, 8255, 8859, 9041, 9099, 8634, 8763, 9167, 8533,\n",
      "       8108, 8912, 9037, 8638, 8870, 8191, 8733, 7683, 8650, 8181, 8762,\n",
      "       8713, 8544, 5472, 8964, 8956, 7764, 8325, 8336, 9136, 7738, 9074,\n",
      "       8769, 8838, 8804, 8854, 8456, 8780, 8995, 8824, 8519, 8629, 8034,\n",
      "       8765, 7861, 9036, 7759, 8532, 7748, 8163, 8553, 8064, 8989, 7762,\n",
      "       9055, 8693, 9213, 8653, 7836, 9067, 8830, 8790, 8324, 9183, 5753,\n",
      "       8464, 8573, 8132, 8457, 9192, 8070, 5942, 9102, 8441, 9157, 8642,\n",
      "       8363, 8127, 5821, 8418, 8855, 8702, 9042, 7945, 8552, 8649, 7726,\n",
      "       8726, 6571, 8865, 9127, 7915, 8620, 9051, 5814, 9038, 7155, 9046,\n",
      "       6921, 7969, 6581, 7769, 8165, 7879, 8734, 8485, 7912, 8220, 8480,\n",
      "       8013, 8622, 8508, 8827, 8675, 8339, 8136, 6949, 8484, 9159, 8499,\n",
      "       9100, 8778, 7813, 8250, 8784, 9101, 7383, 8406, 7465, 9013, 9022,\n",
      "       7899, 8978, 9115, 7780, 8864, 7358, 9125, 8937, 7951, 8528, 8571,\n",
      "       8102, 7687, 8387, 5207, 8493, 8914, 8080, 8444, 9214, 7340, 9064,\n",
      "       8472, 8943, 4724, 6237, 9093, 5822, 5443, 8712, 9154, 8755, 7753,\n",
      "       8952, 7933, 8836, 7763, 7136, 8877, 8048, 6752, 6033, 8679, 6429,\n",
      "       6030, 6994, 7895, 8216, 7306, 8617, 7856, 5943, 8432, 8155, 7042,\n",
      "       9198, 8799, 7695, 7632, 8413, 8566, 8517, 9086, 8880, 5926, 8550,\n",
      "       7735, 8525, 8850, 7564, 5832, 5385, 7180, 9075, 8100, 8845, 8993,\n",
      "       5508, 7133, 8746, 7749, 9171, 8682, 8474]), '2': array([7962, 8932, 8918, 3846, 8618, 8486, 7746, 8647, 8866, 3629, 8516,\n",
      "       8480, 8828, 7895, 7891, 8958, 9062, 8975, 9052, 9028, 3813, 8407,\n",
      "       6272, 8900, 8254, 8468, 7963, 8541, 8500, 3898, 8669, 6986, 8787,\n",
      "       7875, 8988, 9121, 9097, 8515, 5492, 8013, 8868, 6619, 8794, 8799,\n",
      "       8506, 7941, 8948, 7873, 7743, 9024, 8293, 6022, 3775, 5535, 8823,\n",
      "       7686, 7697, 8889, 8485, 2565, 8499, 5383, 8599, 9058, 8819, 8502,\n",
      "       9189, 6607, 8031, 4642, 7718, 9089, 5034, 8547, 8771, 5067, 9172,\n",
      "       8276, 2808, 8295, 9006, 8670, 8793, 8279, 2326, 8827, 5880, 9054,\n",
      "       5503, 6404, 7830, 3600, 7558, 4962, 4139, 9205, 7760, 5330, 9071,\n",
      "       8615, 4228, 9186, 6094, 7734, 8650, 6413, 5257, 6613, 8893, 6508,\n",
      "       7958, 8764, 9136, 8307, 9187, 8694, 8578, 6044, 8678, 5486, 8976,\n",
      "       8926, 7814, 5568, 9050, 6500, 5861, 8721, 9124, 8798, 8588, 9115,\n",
      "       5418, 4586, 9118, 7819, 3285, 8285, 7040, 8591, 7276, 8716, 8035,\n",
      "       9088, 9179, 8677, 8736, 2390, 5888, 5214, 6392, 8776, 2358, 5711,\n",
      "       8673, 8339, 8649, 9195, 6084, 7987, 6990, 9004, 7874, 8660, 6367,\n",
      "       7858, 7148, 5387, 5978, 8857, 8006, 2850, 8873, 9075, 7597, 8630,\n",
      "       7433, 7469, 8666, 7896, 7855, 7818, 3706, 8344, 5688, 6000, 8544,\n",
      "       5893, 1757, 3911, 5920, 2385, 9135, 3760, 8951, 7688, 3966, 9095,\n",
      "       5589, 8999, 3463, 9215, 8466, 8968, 8906, 3280, 6710, 5921, 7041,\n",
      "       8966, 7076, 8896, 7049, 9100, 8194, 8822, 4093, 4200, 8305, 3381,\n",
      "       5653, 7860, 8726, 4657, 7967, 3397, 8611, 5216, 8643, 8380, 8481,\n",
      "       7397, 7054, 2093, 7110, 6930, 7747, 6432, 5406, 8450, 3000, 6337,\n",
      "       4437, 9047, 5696, 8569, 8504])}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (accuracy) of the probe: 0.96\n"
     ]
    }
   ],
   "source": [
    "probe = linear_probe.train_logistic_regression_probe(X, y, lambda_l1=0.001, lambda_l2=0.001)\n",
    "scores = linear_probe.evaluate_probe(probe, X, y, idx_to_class=idx2label)\n",
    "logger.info(f\"üéØ Probe evaluation results: {scores}\")\n",
    "\n",
    "top_neurons_probe, per_class_top_neurons = linear_probe.get_top_neurons(probe, percentage=0.1, class_to_idx=label2idx)\n",
    "logger.info(f\"üîç Top global neurons: {top_neurons_probe}\")\n",
    "logger.info(f\"üîç Top neurons per class: {per_class_top_neurons}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caac4eb9-cda2-4050-b2db-d6cf6e2edb91",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f96bd6-4483-4548-aa6d-20944dc73066",
   "metadata": {},
   "source": [
    "## Original performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc1e0d41-7476-4c5e-891a-e0c61b45011b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y4/zbxddgn52lx1dx5ktc7jch6m0000gn/T/ipykernel_62353/2165693082.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/Users/kikay/Documents/investigacion/.venv/lib/python3.9/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "2025-07-09 13:04:45,014 - INFO - üìÅ Appended classification report with title 'üß™ Sample of 30 - Full Model Evaluation' to data/BigBird/classification_report_sample_eval.csv\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(input_csv)\n",
    "\n",
    "# üéØ Select 50 random examples and reset index\n",
    "sample_df = df.sample(n=50, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# üßπ Convert \"input_ids\" and \"attention_mask\" from string to list format\n",
    "def parse_list(x):\n",
    "    return ast.literal_eval(x)\n",
    "\n",
    "sample_df['input_ids'] = sample_df['input_ids'].apply(parse_list)\n",
    "sample_df['attention_mask'] = sample_df['attention_mask'].apply(parse_list)\n",
    "\n",
    "# üî¢ Encode labels to integers\n",
    "label_encoder = LabelEncoder()\n",
    "sample_df['label'] = label_encoder.fit_transform(sample_df['label'])\n",
    "labels_list = sample_df['label'].tolist()\n",
    "\n",
    "predictions_list = []\n",
    "model.eval()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "for i in range(len(sample_df)):\n",
    "    input_ids_tensor = torch.tensor(sample_df.loc[i, 'input_ids']).unsqueeze(0).to(device)\n",
    "    attention_mask_tensor = torch.tensor(sample_df.loc[i, 'attention_mask']).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with autocast():\n",
    "            device = torch.device(\"cpu\")\n",
    "            outputs = model(input_ids=input_ids_tensor, attention_mask=attention_mask_tensor)\n",
    "            logits = outputs['logits']\n",
    "            pred = torch.argmax(logits, dim=1).item()\n",
    "            predictions_list.append(pred)\n",
    "\n",
    "    del input_ids_tensor, attention_mask_tensor, outputs, logits\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# üìä Compute evaluation metrics\n",
    "accuracy = accuracy_score(labels_list, predictions_list)\n",
    "f1 = f1_score(labels_list, predictions_list, average='weighted')\n",
    "report_dict = classification_report(labels_list, predictions_list, output_dict=True)\n",
    "report_df = pd.DataFrame(report_dict).transpose()\n",
    "\n",
    "# Round for readability\n",
    "report_df = report_df.round(4)\n",
    "\n",
    "# Add accuracy as a separate row\n",
    "accuracy_row = pd.DataFrame({'precision': accuracy, 'recall': accuracy, 'f1-score': accuracy, 'support': sum(report_df['support'])}, index=['accuracy'])\n",
    "report_df = pd.concat([report_df, accuracy_row])\n",
    "\n",
    "# üìù Save or append to CSV\n",
    "\n",
    "experiment_title = \"üß™ Sample of 30 - Full Model Evaluation\"\n",
    "csv_report_path = f\"{BASE_PATH}/classification_report_sample_eval.csv\"\n",
    "\n",
    "# Remove incorrect 'accuracy' row if it exists\n",
    "report_df = report_df.drop(\"accuracy\", errors=\"ignore\")\n",
    "\n",
    "# Append correct accuracy row\n",
    "accuracy_row = pd.DataFrame({\n",
    "    'precision': [\"\"],\n",
    "    'recall': [\"\"],\n",
    "    'f1-score': [accuracy],\n",
    "    'support': [sum(report_df[\"support\"])]\n",
    "}, index=[\"overall_accuracy\"])\n",
    "\n",
    "# Combine\n",
    "final_df = pd.concat([report_df, accuracy_row])\n",
    "\n",
    "# Write to CSV with experiment title as a header\n",
    "with open(csv_report_path, \"a\") as f:\n",
    "    f.write(f\"\\n\\n# {experiment_title}\\n\")\n",
    "final_df.to_csv(csv_report_path, mode=\"a\")\n",
    "\n",
    "logger.info(f\"üìÅ Appended classification report with title '{experiment_title}' to {csv_report_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62225a32-2fc7-4fdb-ae4b-53a19393aae6",
   "metadata": {},
   "source": [
    "## Silence and evaluate neurons. Function definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4451f9be-7a5e-47b9-b264-e8328c6a13d8",
   "metadata": {},
   "source": [
    "### Full silencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f72508a7-d93f-4b9c-a991-367e87015919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_k_neurons_exact(probe, percentage: float) -> list[int]:\n",
    "    \"\"\"\n",
    "    Return exactly N = round(total_neurons * percentage) neuron indices, sorted by importance.\n",
    "    Importance is measured as the sum of absolute values of weights across all output classes.\n",
    "    \"\"\"\n",
    "    weight_matrix = probe.linear.weight.detach().abs()  # [num_classes, num_neurons]\n",
    "    importance = weight_matrix.sum(dim=0).cpu().numpy()  # [num_neurons]\n",
    "    total_neurons = len(importance)\n",
    "    top_n = round(total_neurons * percentage)\n",
    "\n",
    "    sorted_indices = importance.argsort()[-top_n:]  # Top-N by importance\n",
    "    return sorted_indices.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2971743e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cls_silence_hook(indices):\n",
    "    indices = [int(i) for i in indices]\n",
    "    indices_tensor = torch.tensor(indices, dtype=torch.long) if indices else None\n",
    "\n",
    "    def hook(module, input, output):\n",
    "        if output.dim() == 3:\n",
    "            new_output = output.clone()\n",
    "            cls_token = new_output[:, 0, :]\n",
    "            mask = torch.ones_like(cls_token)\n",
    "            if indices_tensor is not None:\n",
    "                local_indices = indices_tensor.to(new_output.device)\n",
    "                mask[:, local_indices] = 0.0\n",
    "            new_output[:, 0, :] = cls_token * mask\n",
    "            return new_output\n",
    "        return output\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32084878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# Get encoder layers dynamically\n",
    "# ==========================\n",
    "def get_encoder_layers(model):\n",
    "    if hasattr(model, \"bert\"):\n",
    "        return model.bert.encoder.layer\n",
    "    elif hasattr(model, \"longformer\"):\n",
    "        return model.longformer.encoder.layer\n",
    "    elif hasattr(model, \"distilbert\"):\n",
    "        return model.distilbert.transformer.layer\n",
    "    else:\n",
    "        raise NotImplementedError(\"‚ùå Unsupported model architecture.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b0222e8-2b6d-441f-b032-e0d960da0eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def silence_top_global_percentage_and_evaluate(\n",
    "    model,\n",
    "    sample_df,\n",
    "    labels_list,\n",
    "    probe,\n",
    "    label2idx,\n",
    "    percentage=0.10,\n",
    "    report_path=None,\n",
    "    experiment_title=None\n",
    "):\n",
    "    hidden_dim = model.config.hidden_size\n",
    "    num_layers = model.config.num_hidden_layers\n",
    "    total_neurons = num_layers * hidden_dim\n",
    "\n",
    "    top_neurons_global = get_top_k_neurons_exact(probe, percentage=percentage)\n",
    "    logger.info(f\"üîß Silencing exactly {len(top_neurons_global)} neurons ({percentage:.2%} of total {total_neurons})\")\n",
    "\n",
    "    # Save neuron indices\n",
    "    neurons_dir = f\"{BASE_PATH}/neurons\"\n",
    "    os.makedirs(neurons_dir, exist_ok=True)\n",
    "    json_path = f\"{neurons_dir}/top_{int(percentage * 100)}p_neurons_global.json\"\n",
    "    with open(json_path, \"w\") as f:\n",
    "        json.dump(top_neurons_global, f, indent=4)\n",
    "    logger.info(f\"üìÅ Saved neuron indices to {json_path}\")\n",
    "\n",
    "    # Register hooks per layer (compatible with BERT, DistilBERT, etc.)\n",
    "    encoder_layers = get_encoder_layers(model)\n",
    "    hook_handles = []\n",
    "    for i in range(num_layers):\n",
    "        indices_layer = [idx - i * hidden_dim for idx in top_neurons_global if i * hidden_dim <= idx < (i + 1) * hidden_dim]\n",
    "        if indices_layer:\n",
    "            logger.info(f\"üìå Layer {i}: silencing {len(indices_layer)} neurons\")\n",
    "            # Use 'output' submodule if exists (BERT, RoBERTa), else register on main layer (DistilBERT)\n",
    "            if hasattr(encoder_layers[i], \"output\"):\n",
    "                handle = encoder_layers[i].output.register_forward_hook(make_cls_silence_hook(indices_layer))\n",
    "            else:\n",
    "                handle = encoder_layers[i].register_forward_hook(make_cls_silence_hook(indices_layer))\n",
    "            hook_handles.append(handle)\n",
    "\n",
    "    # Inference\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    for i in range(len(sample_df)):\n",
    "        input_ids_tensor = torch.tensor(sample_df.loc[i, 'input_ids']).unsqueeze(0).to(model.device)\n",
    "        attention_mask_tensor = torch.tensor(sample_df.loc[i, 'attention_mask']).unsqueeze(0).to(model.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids_tensor, attention_mask=attention_mask_tensor)\n",
    "            logits = outputs['logits']\n",
    "            pred = torch.argmax(logits, dim=1).item()\n",
    "            predictions.append(pred)\n",
    "\n",
    "        del input_ids_tensor, attention_mask_tensor, outputs, logits\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # Metrics\n",
    "    accuracy = accuracy_score(labels_list, predictions)\n",
    "    f1 = f1_score(labels_list, predictions, average='weighted')\n",
    "    report_dict = classification_report(labels_list, predictions, output_dict=True)\n",
    "    report_df = pd.DataFrame(report_dict).transpose().round(4)\n",
    "    report_df = report_df.drop(\"accuracy\", errors=\"ignore\")\n",
    "\n",
    "    accuracy_row = pd.DataFrame({\n",
    "        'precision': [\"\"],\n",
    "        'recall': [\"\"],\n",
    "        'f1-score': [accuracy],\n",
    "        'support': [sum(report_df[\"support\"])]\n",
    "    }, index=[\"overall_accuracy\"])\n",
    "    final_df = pd.concat([report_df, accuracy_row])\n",
    "\n",
    "    # Save classification report\n",
    "    if report_path is None:\n",
    "        report_path = f\"{BASE_PATH}/results/full_silencing.csv\"\n",
    "    os.makedirs(os.path.dirname(report_path), exist_ok=True)\n",
    "\n",
    "    if experiment_title is None:\n",
    "        experiment_title = f\"Silencing top {percentage:.2%} global neurons\"\n",
    "\n",
    "    if not os.path.exists(report_path):\n",
    "        with open(report_path, \"w\") as f:\n",
    "            f.write(f\"# {experiment_title}\\n\")\n",
    "            final_df.to_csv(f)\n",
    "    else:\n",
    "        with open(report_path, \"a\") as f:\n",
    "            f.write(f\"\\n\\n# {experiment_title}\\n\")\n",
    "        final_df.to_csv(report_path, mode=\"a\")\n",
    "\n",
    "    logger.info(f\"üéØ Accuracy after silencing: {accuracy:.4f}\")\n",
    "    logger.info(f\"üìè Weighted F1 Score: {f1:.4f}\")\n",
    "    logger.info(f\"üìã Classification report saved to {report_path}\")\n",
    "\n",
    "    # Remove all hooks\n",
    "    for handle in hook_handles:\n",
    "        handle.remove()\n",
    "    logger.info(\"‚úÖ All hooks removed after evaluation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cffd66-99e9-487e-a2ea-e039e47daf75",
   "metadata": {},
   "source": [
    "## Global impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b029e16d-7756-4ec6-933d-dbbd0b1a8569",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages = [0.025, 0.05, 0.075, 0.10, 0.125, 0.15, 0.175, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.65, 0.75, 0.8, 0.95]\n",
    "\n",
    "for pct in percentages:\n",
    "    silence_top_global_percentage_and_evaluate(\n",
    "        model=model,\n",
    "        sample_df=sample_df,\n",
    "        labels_list=labels_list,\n",
    "        probe=probe,\n",
    "        label2idx=label2idx,\n",
    "        percentage=pct,\n",
    "        experiment_title=f\"Silencing {pct*100:.1f}% Global Neurons\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec3cbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "def plot_f1_scores_from_file(filepath, output_path= f\"{BASE_PATH}/figs/f1_curve_global.png\"):\n",
    "    with open(filepath, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Estructuras para almacenar los datos\n",
    "    results = defaultdict(list)  # clase -> lista de F1-scores\n",
    "    global_f1_scores = {}\n",
    "    percentages = []\n",
    "    current_percentage = None\n",
    "\n",
    "    # Parsear el contenido\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "\n",
    "        # Detectar inicio de bloque\n",
    "        if line.startswith(\"# Silencing\"):\n",
    "            match = re.search(r\"# Silencing ([\\d.]+)% Global Neurons\", line)\n",
    "            if match:\n",
    "                current_percentage = float(match.group(1))\n",
    "                percentages.append(current_percentage)\n",
    "            continue\n",
    "\n",
    "        if line.startswith(\",precision\") or not line:\n",
    "            continue\n",
    "\n",
    "        parts = line.split(\",\")\n",
    "        label = parts[0]\n",
    "\n",
    "        if label.isdigit():\n",
    "            class_index = int(label)\n",
    "            try:\n",
    "                f1 = float(parts[3])\n",
    "                results[class_index].append(f1)\n",
    "            except:\n",
    "                results[class_index].append(None)\n",
    "        elif label == \"weighted avg\":\n",
    "            try:\n",
    "                global_f1_scores[current_percentage] = float(parts[3])\n",
    "            except:\n",
    "                global_f1_scores[current_percentage] = None\n",
    "\n",
    "    # Ordenar porcentajes\n",
    "    sorted_percentages = sorted(global_f1_scores.keys())\n",
    "    global_f1 = [global_f1_scores[p] for p in sorted_percentages]\n",
    "\n",
    "    # Crear la figura\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # F1 global\n",
    "    plt.plot(sorted_percentages, global_f1, label=\"Global F1\", linewidth=2, marker='o')\n",
    "\n",
    "    # F1 por clase\n",
    "    for class_index in sorted(results.keys()):\n",
    "        f1s = results[class_index]\n",
    "        plt.plot(sorted_percentages, f1s, label=f\"Class {class_index}\", linestyle='--', marker='x')\n",
    "\n",
    "    # Formato\n",
    "    plt.title(\"F1 Scores vs. % of Silenced Global Neurons\")\n",
    "    plt.xlabel(\"% of Silenced Neurons\")\n",
    "    plt.ylabel(\"F1 Score\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Guardar como PNG\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    print(f\"Gr√°fica guardada como: {output_path}\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca23f20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f1_scores_from_file(f\"{BASE_PATH}/results/full_silencing.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f318510-19fb-424a-a75e-eeedc5ac36fc",
   "metadata": {},
   "source": [
    "## Impact per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8690a872-1583-4064-90dc-764a72df1b63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56729e96-13c8-467f-a563-4ac5c96a58fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_k_neurons_for_class_exact(probe, percentage: float, class_to_idx: dict, class_id: int) -> list[int]:\n",
    "    \"\"\"\n",
    "    Return top-k neurons most important for a specific class, measured by absolute weight.\n",
    "    \"\"\"\n",
    "    weight_matrix = probe.linear.weight.detach().abs()  # [num_classes, num_neurons]\n",
    "    class_weights = weight_matrix[class_id]  # [num_neurons]\n",
    "    total_neurons = class_weights.size(0)\n",
    "    top_n = round(percentage * total_neurons)\n",
    "    top_indices = class_weights.cpu().numpy().argsort()[-top_n:]\n",
    "    return top_indices.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0609da1d-3fde-4fc7-9913-bd3c3b4642da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# Get encoder layers dynamically\n",
    "# ==========================\n",
    "def get_encoder_layers(model):\n",
    "    if hasattr(model, \"bert\"):\n",
    "        return model.bert.encoder.layer\n",
    "    elif hasattr(model, \"longformer\"):\n",
    "        return model.longformer.encoder.layer\n",
    "    elif hasattr(model, \"distilbert\"):\n",
    "        return model.distilbert.transformer.layer\n",
    "    else:\n",
    "        raise NotImplementedError(\"‚ùå Unsupported model architecture.\")\n",
    "\n",
    "# ==========================\n",
    "# Silence and evaluate top per-class neurons\n",
    "# ==========================\n",
    "\n",
    "def silence_top_class_percentage_and_evaluate(\n",
    "    model,\n",
    "    sample_df,\n",
    "    labels_list,\n",
    "    probe,\n",
    "    label2idx,\n",
    "    class_id: int,\n",
    "    percentage: float = 0.1,\n",
    "    report_path: str = None,\n",
    "    experiment_title: str = None\n",
    "):\n",
    "    class_name = f\"class_{class_id}\"\n",
    "    hidden_dim = model.config.hidden_size\n",
    "    num_layers = model.config.num_hidden_layers\n",
    "    total_neurons = num_layers * hidden_dim\n",
    "\n",
    "    # Get top neurons for specific class\n",
    "    top_class_neurons = get_top_k_neurons_for_class_exact(\n",
    "        probe, percentage=percentage, class_to_idx=label2idx, class_id=class_id\n",
    "    )\n",
    "\n",
    "    logger.info(f\"üîß Silencing {len(top_class_neurons)} neurons for class {class_id} ({percentage:.2%} of total)\")\n",
    "\n",
    "    # Save neurons to JSON\n",
    "    neurons_dir = f\"{BASE_PATH}/neurons\"\n",
    "    os.makedirs(neurons_dir, exist_ok=True)\n",
    "    json_path = f\"{neurons_dir}/top_{int(percentage * 100)}p_neurons_{class_name}.json\"\n",
    "    with open(json_path, \"w\") as f:\n",
    "        json.dump(top_class_neurons, f, indent=4)\n",
    "    logger.info(f\"üìÅ Saved neuron indices to {json_path}\")\n",
    "\n",
    "    # Register hooks per layer\n",
    "    encoder_layers = get_encoder_layers(model)\n",
    "    hook_handles = []\n",
    "    for i in range(num_layers):\n",
    "        indices_layer = [idx - i * hidden_dim for idx in top_class_neurons if i * hidden_dim <= idx < (i + 1) * hidden_dim]\n",
    "        if indices_layer:\n",
    "            logger.info(f\"üìå Layer {i}: silencing {len(indices_layer)} neurons for class {class_id}\")\n",
    "            handle = encoder_layers[i].output.register_forward_hook(make_cls_silence_hook(indices_layer))\n",
    "            hook_handles.append(handle)\n",
    "\n",
    "    # Inference\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    for i in range(len(sample_df)):\n",
    "        input_ids_tensor = torch.tensor(sample_df.loc[i, 'input_ids']).unsqueeze(0).to(model.device)\n",
    "        attention_mask_tensor = torch.tensor(sample_df.loc[i, 'attention_mask']).unsqueeze(0).to(model.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids_tensor, attention_mask=attention_mask_tensor)\n",
    "            logits = outputs['logits']\n",
    "            pred = torch.argmax(logits, dim=1).item()\n",
    "            predictions.append(pred)\n",
    "\n",
    "        del input_ids_tensor, attention_mask_tensor, outputs, logits\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # Metrics\n",
    "    accuracy = accuracy_score(labels_list, predictions)\n",
    "    f1 = f1_score(labels_list, predictions, average='weighted')\n",
    "    report_dict = classification_report(labels_list, predictions, output_dict=True)\n",
    "    report_df = pd.DataFrame(report_dict).transpose().round(4)\n",
    "    report_df = report_df.drop(\"accuracy\", errors=\"ignore\")\n",
    "\n",
    "    accuracy_row = pd.DataFrame({\n",
    "        'precision': [\"\"],\n",
    "        'recall': [\"\"],\n",
    "        'f1-score': [accuracy],\n",
    "        'support': [sum(report_df[\"support\"])]\n",
    "    }, index=[\"overall_accuracy\"])\n",
    "    final_df = pd.concat([report_df, accuracy_row])\n",
    "\n",
    "    # Save classification report\n",
    "    if report_path is None:\n",
    "        report_path = f\"{BASE_PATH}/results/class_silencing{class_id}.csv\"\n",
    "    os.makedirs(os.path.dirname(report_path), exist_ok=True)\n",
    "\n",
    "    if experiment_title is None:\n",
    "        experiment_title = f\"Silencing top {percentage:.2%} neurons for class {class_id}\"\n",
    "\n",
    "    if not os.path.exists(report_path):\n",
    "        with open(report_path, \"w\") as f:\n",
    "            f.write(f\"# {experiment_title}\\n\")\n",
    "            final_df.to_csv(f)\n",
    "    else:\n",
    "        with open(report_path, \"a\") as f:\n",
    "            f.write(f\"\\n\\n# {experiment_title}\\n\")\n",
    "        final_df.to_csv(report_path, mode=\"a\")\n",
    "\n",
    "    logger.info(f\"üéØ Accuracy after class-specific silencing: {accuracy:.4f}\")\n",
    "    logger.info(f\"üìè Weighted F1 Score: {f1:.4f}\")\n",
    "    logger.info(f\"üìã Classification report saved to {report_path}\")\n",
    "\n",
    "    # Remove all hooks\n",
    "    for handle in hook_handles:\n",
    "        handle.remove()\n",
    "    logger.info(\"‚úÖ All hooks removed after evaluation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b3d65d1-ff4c-457b-90d9-a1a76563ef48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 13:04:45,063 - INFO - üîß Silencing 4608 neurons for class 4 (50.00% of total)\n",
      "2025-07-09 13:04:45,064 - INFO - üìÅ Saved neuron indices to data/BigBird/neurons/top_50p_neurons_class_4.json\n",
      "2025-07-09 13:04:45,065 - INFO - üìå Layer 0: silencing 234 neurons for class 4\n",
      "2025-07-09 13:04:45,065 - INFO - üìå Layer 1: silencing 125 neurons for class 4\n",
      "2025-07-09 13:04:45,066 - INFO - üìå Layer 2: silencing 296 neurons for class 4\n",
      "2025-07-09 13:04:45,066 - INFO - üìå Layer 3: silencing 338 neurons for class 4\n",
      "2025-07-09 13:04:45,067 - INFO - üìå Layer 4: silencing 381 neurons for class 4\n",
      "2025-07-09 13:04:45,067 - INFO - üìå Layer 5: silencing 378 neurons for class 4\n",
      "2025-07-09 13:04:45,068 - INFO - üìå Layer 6: silencing 439 neurons for class 4\n",
      "2025-07-09 13:04:45,068 - INFO - üìå Layer 7: silencing 440 neurons for class 4\n",
      "2025-07-09 13:04:45,069 - INFO - üìå Layer 8: silencing 438 neurons for class 4\n",
      "2025-07-09 13:04:45,069 - INFO - üìå Layer 9: silencing 487 neurons for class 4\n",
      "2025-07-09 13:04:45,070 - INFO - üìå Layer 10: silencing 499 neurons for class 4\n",
      "2025-07-09 13:04:45,070 - INFO - üìå Layer 11: silencing 553 neurons for class 4\n",
      "/Users/kikay/Documents/investigacion/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kikay/Documents/investigacion/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kikay/Documents/investigacion/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2025-07-09 13:05:58,079 - INFO - üéØ Accuracy after class-specific silencing: 0.6800\n",
      "2025-07-09 13:05:58,080 - INFO - üìè Weighted F1 Score: 0.5980\n",
      "2025-07-09 13:05:58,080 - INFO - üìã Classification report saved to data/BigBird/results/class_silencing4.csv\n",
      "2025-07-09 13:05:58,080 - INFO - ‚úÖ All hooks removed after evaluation\n"
     ]
    }
   ],
   "source": [
    "# percentages = [0.025, 0.05, 0.075, 0.10, 0.125, 0.15, 0.175, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.65, 0.75, 0.8, 0.95]\n",
    "percentages = [0.50]\n",
    "target_class_id = 4\n",
    "\n",
    "for pct in percentages:\n",
    "    silence_top_class_percentage_and_evaluate(\n",
    "        model=model,\n",
    "        sample_df=sample_df,\n",
    "        labels_list=labels_list,\n",
    "        probe=probe,\n",
    "        label2idx=label2idx,\n",
    "        class_id=target_class_id,\n",
    "        percentage=pct,\n",
    "        experiment_title=f\"Silencing {pct*100:.1f}% of Neurons for Class {target_class_id}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f09f679-c5bd-4b64-b72d-13adefa9d49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages = [0.025, 0.05, 0.075, 0.10, 0.125, 0.15, 0.175, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.65, 0.75, 0.8, 0.95]\n",
    "\n",
    "target_class_id = 3\n",
    "\n",
    "for pct in percentages:\n",
    "    silence_top_class_percentage_and_evaluate(\n",
    "        model=model,\n",
    "        sample_df=sample_df,\n",
    "        labels_list=labels_list,\n",
    "        probe=probe,\n",
    "        label2idx=label2idx,\n",
    "        class_id=target_class_id,\n",
    "        percentage=pct,\n",
    "        experiment_title=f\"Silencing {pct*100:.1f}% of Neurons for Class {target_class_id}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55026e28-3e0a-4272-9f64-a3ba04776f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages = [0.025, 0.05, 0.075, 0.10, 0.125, 0.15, 0.175, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.65, 0.75, 0.8, 0.95]\n",
    "\n",
    "target_class_id = 2\n",
    "for pct in percentages:\n",
    "    silence_top_class_percentage_and_evaluate(\n",
    "        model=model,\n",
    "        sample_df=sample_df,\n",
    "        labels_list=labels_list,\n",
    "        probe=probe,\n",
    "        label2idx=label2idx,\n",
    "        class_id=target_class_id,\n",
    "        percentage=pct,\n",
    "        experiment_title=f\"Silencing {pct*100:.1f}% of Neurons for Class {target_class_id}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f21b1e0-d603-4dd5-b662-9724969b598d",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages = [0.025, 0.05, 0.075, 0.10, 0.125, 0.15, 0.175, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.65, 0.75, 0.8, 0.95]\n",
    "\n",
    "target_class_id = 1\n",
    "\n",
    "for pct in percentages:\n",
    "    silence_top_class_percentage_and_evaluate(\n",
    "        model=model,\n",
    "        sample_df=sample_df,\n",
    "        labels_list=labels_list,\n",
    "        probe=probe,\n",
    "        label2idx=label2idx,\n",
    "        class_id=target_class_id,\n",
    "        percentage=pct,\n",
    "        experiment_title=f\"Silencing {pct*100:.1f}% of Neurons for Class {target_class_id}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59760190-c9cc-406e-b53b-6edef73639d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages = [0.025, 0.05, 0.075, 0.10, 0.125, 0.15, 0.175, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.65, 0.75, 0.8, 0.95]\n",
    "\n",
    "target_class_id = 0\n",
    "\n",
    "for pct in percentages:\n",
    "    silence_top_class_percentage_and_evaluate(\n",
    "        model=model,\n",
    "        sample_df=sample_df,\n",
    "        labels_list=labels_list,\n",
    "        probe=probe,\n",
    "        label2idx=label2idx,\n",
    "        class_id=target_class_id,\n",
    "        percentage=pct,\n",
    "        experiment_title=f\"Silencing {pct*100:.1f}% of Neurons for Class {target_class_id}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b6dfed-1928-40c7-99f8-0ed26e3b96b2",
   "metadata": {},
   "source": [
    "# Attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e2541c-cad9-4a8d-97a6-d2d0e8bd28cf",
   "metadata": {},
   "source": [
    "## FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a240dcaa-e052-424d-b037-145db9683c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "def run_fgsm_attack_and_evaluate(\n",
    "    model,\n",
    "    sample_df,\n",
    "    labels_list,\n",
    "    epsilon: float = 0.1,\n",
    "    report_path: str = f\"{BASE_PATH}/fgsm.csv\",\n",
    "    experiment_title: str = None\n",
    "):\n",
    "    logger.info(f\"‚öîÔ∏è Running FGSM attack with Œµ = {epsilon}\")\n",
    "    model.eval()\n",
    "    predictions_fgsm = []\n",
    "    loss_fn = CrossEntropyLoss()\n",
    "\n",
    "    is_longformer = hasattr(model, \"longformer\")\n",
    "\n",
    "    for i in range(len(sample_df)):\n",
    "        # ===============================\n",
    "        # üî¢ Prepare input tensors\n",
    "        # ===============================\n",
    "        input_ids_tensor = torch.tensor(sample_df.loc[i, 'input_ids'], dtype=torch.long).unsqueeze(0).to(model.device)\n",
    "        attention_mask_tensor = torch.tensor(sample_df.loc[i, 'attention_mask'], dtype=torch.long).unsqueeze(0).to(model.device)\n",
    "        true_label = torch.tensor([labels_list[i]], dtype=torch.long).to(model.device)\n",
    "\n",
    "        # ===============================\n",
    "        # üîç Extract embeddings as leaf tensor\n",
    "        # ===============================\n",
    "        with torch.no_grad():\n",
    "            embedding_output = model.base_model.embeddings(input_ids_tensor)\n",
    "        embeds = embedding_output.clone().detach().requires_grad_(True)\n",
    "\n",
    "        # ===============================\n",
    "        # üîÅ Forward pass\n",
    "        # ===============================\n",
    "        if is_longformer:\n",
    "            global_attention_mask = torch.zeros_like(attention_mask_tensor)\n",
    "            global_attention_mask[:, 0] = 1\n",
    "            outputs = model(\n",
    "                inputs_embeds=embeds,\n",
    "                attention_mask=attention_mask_tensor,\n",
    "                global_attention_mask=global_attention_mask\n",
    "            )\n",
    "        else:\n",
    "            outputs = model(\n",
    "                inputs_embeds=embeds,\n",
    "                attention_mask=attention_mask_tensor\n",
    "            )\n",
    "\n",
    "        logits = outputs.logits\n",
    "        loss = loss_fn(logits, true_label)\n",
    "\n",
    "        # ===============================\n",
    "        # üîÅ Backward pass\n",
    "        # ===============================\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # ===============================\n",
    "        # ‚öîÔ∏è FGSM perturbation\n",
    "        # ===============================\n",
    "        perturbation = epsilon * embeds.grad.data.sign()\n",
    "        adv_embeds = embeds + perturbation\n",
    "\n",
    "        # ===============================\n",
    "        # üîÆ Inference with adversarial input\n",
    "        # ===============================\n",
    "        with torch.no_grad():\n",
    "            if is_longformer:\n",
    "                adv_outputs = model(\n",
    "                    inputs_embeds=adv_embeds,\n",
    "                    attention_mask=attention_mask_tensor,\n",
    "                    global_attention_mask=global_attention_mask\n",
    "                )\n",
    "            else:\n",
    "                adv_outputs = model(\n",
    "                    inputs_embeds=adv_embeds,\n",
    "                    attention_mask=attention_mask_tensor\n",
    "                )\n",
    "            adv_logits = adv_outputs.logits\n",
    "            pred = torch.argmax(adv_logits, dim=1).item()\n",
    "            predictions_fgsm.append(pred)\n",
    "\n",
    "        del input_ids_tensor, attention_mask_tensor, embeds, adv_embeds, outputs, adv_outputs, logits, adv_logits\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # ===============================\n",
    "    # üìä Evaluation\n",
    "    # ===============================\n",
    "    accuracy = accuracy_score(labels_list, predictions_fgsm)\n",
    "    f1 = f1_score(labels_list, predictions_fgsm, average='weighted')\n",
    "    report_dict = classification_report(labels_list, predictions_fgsm, output_dict=True)\n",
    "    report_df = pd.DataFrame(report_dict).transpose().round(4).drop(\"accuracy\", errors=\"ignore\")\n",
    "\n",
    "    accuracy_row = pd.DataFrame({\n",
    "        'precision': [\"\"],\n",
    "        'recall': [\"\"],\n",
    "        'f1-score': [accuracy],\n",
    "        'support': [sum(report_df[\"support\"])]\n",
    "    }, index=[\"overall_accuracy\"])\n",
    "    final_df = pd.concat([report_df, accuracy_row])\n",
    "\n",
    "    # ===============================\n",
    "    # üíæ Save report\n",
    "    # ===============================\n",
    "    if experiment_title is None:\n",
    "        experiment_title = f\"FGSM Attack (Œµ = {epsilon})\"\n",
    "    if not os.path.exists(report_path):\n",
    "        with open(report_path, \"w\") as f:\n",
    "            f.write(f\"# {experiment_title}\\n\")\n",
    "            final_df.to_csv(f)\n",
    "    else:\n",
    "        with open(report_path, \"a\") as f:\n",
    "            f.write(f\"\\n\\n# {experiment_title}\\n\")\n",
    "        final_df.to_csv(report_path, mode=\"a\")\n",
    "\n",
    "    logger.info(f\"üéØ Accuracy under FGSM (Œµ={epsilon}): {accuracy:.4f}\")\n",
    "    logger.info(f\"üìè Weighted F1 Score: {f1:.4f}\")\n",
    "    logger.info(f\"üìã Classification report saved to {report_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666b89b9-b9d6-4f76-b93d-beabcaee9722",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "model.to(\"cpu\")\n",
    "device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ee84d3-e9d3-47ca-8590-8465da7aafff",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_fgsm_attack_and_evaluate(\n",
    "    model=model,\n",
    "    sample_df=sample_df,\n",
    "    labels_list=labels_list,\n",
    "    epsilon=0.1,\n",
    "    experiment_title=\"FGSM Adversarial Attack with Œµ = 0.1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c245bc3d-f654-4e2d-bdc2-bdeead37e0f1",
   "metadata": {},
   "source": [
    "## Random Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71365102-736c-4fc4-b060-228fe966b49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_random_noise_attack(\n",
    "    model,\n",
    "    sample_df,\n",
    "    labels_list,\n",
    "    epsilon=0.3,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    import torch\n",
    "    from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "    logger.info(f\"üé≤ Running random noise attack (epsilon={epsilon})\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    predictions_noise = []\n",
    "\n",
    "    is_longformer = hasattr(model, \"longformer\")\n",
    "\n",
    "    for i in range(len(sample_df)):\n",
    "        input_ids_tensor = torch.tensor(sample_df.loc[i, 'input_ids'], dtype=torch.long).unsqueeze(0).to(device)\n",
    "        attention_mask_tensor = torch.tensor(sample_df.loc[i, 'attention_mask'], dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            embeddings = model.base_model.embeddings(input_ids_tensor)\n",
    "            noisy_embeddings = embeddings + epsilon * torch.randn_like(embeddings)\n",
    "\n",
    "            if is_longformer:\n",
    "                global_attention_mask = torch.zeros_like(attention_mask_tensor)\n",
    "                global_attention_mask[:, 0] = 1\n",
    "                outputs = model(\n",
    "                    inputs_embeds=noisy_embeddings,\n",
    "                    attention_mask=attention_mask_tensor,\n",
    "                    global_attention_mask=global_attention_mask\n",
    "                )\n",
    "            else:\n",
    "                outputs = model(\n",
    "                    inputs_embeds=noisy_embeddings,\n",
    "                    attention_mask=attention_mask_tensor\n",
    "                )\n",
    "\n",
    "            logits = outputs.logits\n",
    "            pred = torch.argmax(logits, dim=1).item()\n",
    "            predictions_noise.append(pred)\n",
    "\n",
    "    accuracy = accuracy_score(labels_list, predictions_noise)\n",
    "    f1 = f1_score(labels_list, predictions_noise, average='weighted')\n",
    "    report = classification_report(labels_list, predictions_noise)\n",
    "\n",
    "    logger.info(f\"üìâ Random noise attack results (epsilon={epsilon}):\")\n",
    "    logger.info(f\"Accuracy: {accuracy:.4f} | F1 Score: {f1:.4f}\")\n",
    "    logger.info(f\"\\nClassification Report:\\n{report}\")\n",
    "\n",
    "    return accuracy, f1, predictions_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c5486c-42b6-4f4f-acd5-1697a6be21f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "epsilons = np.linspace(0.1, 1.0, 10)  # 10 valores de 0.1 a 1.0\n",
    "results = []\n",
    "\n",
    "for epsilon in epsilons:\n",
    "    logger.info(f\"\\nüé≤ Running random noise attack with Œµ={epsilon:.2f}\")\n",
    "\n",
    "    acc_noise, f1_noise, preds_noise = run_random_noise_attack(\n",
    "        model=model,\n",
    "        sample_df=sample_df,\n",
    "        labels_list=labels_list,\n",
    "        epsilon=epsilon,\n",
    "        device=\"cpu\"\n",
    "    )\n",
    "\n",
    "    logger.info(f\"üìâ Results for Œµ={epsilon:.2f} ‚Üí Accuracy: {acc_noise:.4f} | F1 Score: {f1_noise:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        \"epsilon\": round(epsilon, 2),\n",
    "        \"accuracy\": acc_noise,\n",
    "        \"f1_score\": f1_noise\n",
    "    })\n",
    "\n",
    "# Convertimos resultados a dataframe\n",
    "noise_sweep_df = pd.DataFrame(results)\n",
    "noise_sweep_df.to_csv(\"results/random_noise_sweep_up_to_1.csv\", index=False)\n",
    "\n",
    "logger.info(\"üìÅ Random noise sweep results saved to 'results/random_noise_sweep_up_to_1.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3a6abb-375e-452f-abb3-79cb8baddb50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e366135-17f4-4089-a9e4-3a847d88dda1",
   "metadata": {},
   "source": [
    "# Conjuntos disjuntos de neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b6ec2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c30e1c-0f78-480e-976a-1d9b4607ab32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 13:15:29,786 - INFO - Saved exclusive neurons for class 1 to data/BigBird/exclusive_neurons/exclusive_top50p_class_1.json\n",
      "2025-07-09 13:15:29,787 - INFO - Saved exclusive neurons for class 3 to data/BigBird/exclusive_neurons/exclusive_top50p_class_3.json\n",
      "2025-07-09 13:15:29,788 - INFO - Saved exclusive neurons for class 0 to data/BigBird/exclusive_neurons/exclusive_top50p_class_0.json\n",
      "2025-07-09 13:15:29,789 - INFO - Saved exclusive neurons for class 4 to data/BigBird/exclusive_neurons/exclusive_top50p_class_4.json\n",
      "2025-07-09 13:15:29,789 - INFO - Saved exclusive neurons for class 2 to data/BigBird/exclusive_neurons/exclusive_top50p_class_2.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1: 195 exclusive neurons out of 260 top neurons\n",
      "Class 3: 148 exclusive neurons out of 243 top neurons\n",
      "Class 0: 160 exclusive neurons out of 255 top neurons\n",
      "Class 4: 144 exclusive neurons out of 227 top neurons\n",
      "Class 2: 176 exclusive neurons out of 247 top neurons\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import os\n",
    "import json\n",
    "\n",
    "top_percentage = 0.5  # 50% \n",
    "\n",
    "# Detect and convert (layer, neuron) tuples to global indices if needed\n",
    "hidden_dim = model.config.hidden_size\n",
    "\n",
    "def tuple_to_global_index(neuron_tuples, hidden_dim):\n",
    "    return [layer * hidden_dim + neuron for (layer, neuron) in neuron_tuples]\n",
    "\n",
    "per_class_top_indices = {}\n",
    "for class_id, neuron_list in per_class_top_neurons.items():\n",
    "    if len(neuron_list) > 0 and isinstance(neuron_list[0], tuple):\n",
    "        per_class_top_indices[class_id] = tuple_to_global_index(neuron_list, hidden_dim)\n",
    "    else:\n",
    "        per_class_top_indices[class_id] = neuron_list\n",
    "\n",
    "# Exclusive neurons: present in top of class A but not in any other class\n",
    "exclusive_class_neurons = {}\n",
    "for cid, own_top in per_class_top_indices.items():\n",
    "    other = set()\n",
    "    for other_cid, other_top in per_class_top_indices.items():\n",
    "        if other_cid != cid:\n",
    "            other.update(other_top)\n",
    "    exclusive = sorted(set(own_top) - other)\n",
    "    exclusive_class_neurons[cid] = exclusive\n",
    "    print(f\"Class {cid}: {len(exclusive)} exclusive neurons out of {len(own_top)} top neurons\")\n",
    "\n",
    "# Save exclusive neurons to JSON\n",
    "exclusive_dir = f\"{BASE_PATH}/exclusive_neurons\"\n",
    "os.makedirs(exclusive_dir, exist_ok=True)\n",
    "for class_id, neuron_list in exclusive_class_neurons.items():\n",
    "    path = f\"{exclusive_dir}/exclusive_top{int(top_percentage*100)}p_class_{class_id}.json\"\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump([int(x) for x in neuron_list], f, indent=2)\n",
    "    logger.info(f\"Saved exclusive neurons for class {class_id} to {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd121ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def silence_exclusive_class_and_evaluate(\n",
    "    model,\n",
    "    sample_df,\n",
    "    labels_list,\n",
    "    exclusive_neuron_indices,\n",
    "    class_id,\n",
    "    report_path=None,\n",
    "    experiment_title=None\n",
    "):\n",
    "    hidden_dim = model.config.hidden_size\n",
    "    num_layers = model.config.num_hidden_layers\n",
    "\n",
    "    logger.info(f\"üîß Silencing {len(exclusive_neuron_indices)} EXCLUSIVE neurons for class {class_id}\")\n",
    "\n",
    "    encoder_layers = get_encoder_layers(model)\n",
    "    hook_handles = []\n",
    "    for i in range(num_layers):\n",
    "        indices_layer = [idx - i * hidden_dim for idx in exclusive_neuron_indices if i * hidden_dim <= idx < (i + 1) * hidden_dim]\n",
    "        if indices_layer:\n",
    "            logger.info(f\"üìå Layer {i}: silencing {len(indices_layer)} exclusive neurons for class {class_id}\")\n",
    "            if hasattr(encoder_layers[i], \"output\"):\n",
    "                handle = encoder_layers[i].output.register_forward_hook(make_cls_silence_hook(indices_layer))\n",
    "            else:\n",
    "                handle = encoder_layers[i].register_forward_hook(make_cls_silence_hook(indices_layer))\n",
    "            hook_handles.append(handle)\n",
    "\n",
    "    # --- Evaluation ---\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    for i in range(len(sample_df)):\n",
    "        input_ids_tensor = torch.tensor(sample_df.loc[i, 'input_ids']).unsqueeze(0).to(model.device)\n",
    "        attention_mask_tensor = torch.tensor(sample_df.loc[i, 'attention_mask']).unsqueeze(0).to(model.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids_tensor, attention_mask=attention_mask_tensor)\n",
    "            logits = outputs['logits']\n",
    "            pred = torch.argmax(logits, dim=1).item()\n",
    "            predictions.append(pred)\n",
    "        del input_ids_tensor, attention_mask_tensor, outputs, logits\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # --- Metrics & reporting ---\n",
    "    from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "    import pandas as pd\n",
    "    accuracy = accuracy_score(labels_list, predictions)\n",
    "    f1 = f1_score(labels_list, predictions, average='weighted')\n",
    "    report_dict = classification_report(labels_list, predictions, output_dict=True)\n",
    "    report_df = pd.DataFrame(report_dict).transpose().round(4)\n",
    "    report_df = report_df.drop(\"accuracy\", errors=\"ignore\")\n",
    "\n",
    "    accuracy_row = pd.DataFrame({\n",
    "        'precision': [\"\"],\n",
    "        'recall': [\"\"],\n",
    "        'f1-score': [accuracy],\n",
    "        'support': [sum(report_df[\"support\"])]\n",
    "    }, index=[\"overall_accuracy\"])\n",
    "    final_df = pd.concat([report_df, accuracy_row])\n",
    "\n",
    "    # --- Save classification report ---\n",
    "    if report_path is None:\n",
    "        report_path = f\"{BASE_PATH}/results/exclusive_class_silencing_{class_id}.csv\"\n",
    "    os.makedirs(os.path.dirname(report_path), exist_ok=True)\n",
    "    if experiment_title is None:\n",
    "        experiment_title = f\"Silencing exclusive neurons for class {class_id}\"\n",
    "    if not os.path.exists(report_path):\n",
    "        with open(report_path, \"w\") as f:\n",
    "            f.write(f\"# {experiment_title}\\n\")\n",
    "            final_df.to_csv(f)\n",
    "    else:\n",
    "        with open(report_path, \"a\") as f:\n",
    "            f.write(f\"\\n\\n# {experiment_title}\\n\")\n",
    "        final_df.to_csv(report_path, mode=\"a\")\n",
    "\n",
    "    logger.info(f\"üéØ Accuracy after exclusive silencing: {accuracy:.4f}\")\n",
    "    logger.info(f\"üìè Weighted F1 Score: {f1:.4f}\")\n",
    "    logger.info(f\"üìã Classification report saved to {report_path}\")\n",
    "\n",
    "    # Remove hooks\n",
    "    for handle in hook_handles:\n",
    "        handle.remove()\n",
    "    logger.info(\"‚úÖ All hooks removed after evaluation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e495203-de9e-413c-8dd7-48848971d1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 13:16:43,619 - INFO - üîß Silencing 195 EXCLUSIVE neurons for class 1\n",
      "2025-07-09 13:16:43,620 - INFO - üìå Layer 4: silencing 2 exclusive neurons for class 1\n",
      "2025-07-09 13:16:43,621 - INFO - üìå Layer 5: silencing 4 exclusive neurons for class 1\n",
      "2025-07-09 13:16:43,622 - INFO - üìå Layer 6: silencing 6 exclusive neurons for class 1\n",
      "2025-07-09 13:16:43,622 - INFO - üìå Layer 7: silencing 17 exclusive neurons for class 1\n",
      "2025-07-09 13:16:43,623 - INFO - üìå Layer 8: silencing 32 exclusive neurons for class 1\n",
      "2025-07-09 13:16:43,623 - INFO - üìå Layer 9: silencing 33 exclusive neurons for class 1\n",
      "2025-07-09 13:16:43,624 - INFO - üìå Layer 10: silencing 44 exclusive neurons for class 1\n",
      "2025-07-09 13:16:43,624 - INFO - üìå Layer 11: silencing 57 exclusive neurons for class 1\n",
      "2025-07-09 13:17:59,077 - INFO - üéØ Accuracy after exclusive silencing: 0.8600\n",
      "2025-07-09 13:17:59,078 - INFO - üìè Weighted F1 Score: 0.8552\n",
      "2025-07-09 13:17:59,078 - INFO - üìã Classification report saved to data/BigBird/results/exclusive_class_silencing_1.csv\n",
      "2025-07-09 13:17:59,078 - INFO - ‚úÖ All hooks removed after evaluation\n",
      "2025-07-09 13:17:59,079 - INFO - üîß Silencing 148 EXCLUSIVE neurons for class 3\n",
      "2025-07-09 13:17:59,079 - INFO - üìå Layer 0: silencing 1 exclusive neurons for class 3\n",
      "2025-07-09 13:17:59,080 - INFO - üìå Layer 4: silencing 3 exclusive neurons for class 3\n",
      "2025-07-09 13:17:59,080 - INFO - üìå Layer 5: silencing 7 exclusive neurons for class 3\n",
      "2025-07-09 13:17:59,080 - INFO - üìå Layer 6: silencing 10 exclusive neurons for class 3\n",
      "2025-07-09 13:17:59,081 - INFO - üìå Layer 7: silencing 10 exclusive neurons for class 3\n",
      "2025-07-09 13:17:59,081 - INFO - üìå Layer 8: silencing 6 exclusive neurons for class 3\n",
      "2025-07-09 13:17:59,081 - INFO - üìå Layer 9: silencing 11 exclusive neurons for class 3\n",
      "2025-07-09 13:17:59,082 - INFO - üìå Layer 10: silencing 30 exclusive neurons for class 3\n",
      "2025-07-09 13:17:59,082 - INFO - üìå Layer 11: silencing 70 exclusive neurons for class 3\n",
      "2025-07-09 13:19:14,369 - INFO - üéØ Accuracy after exclusive silencing: 0.8600\n",
      "2025-07-09 13:19:14,370 - INFO - üìè Weighted F1 Score: 0.8552\n",
      "2025-07-09 13:19:14,370 - INFO - üìã Classification report saved to data/BigBird/results/exclusive_class_silencing_3.csv\n",
      "2025-07-09 13:19:14,370 - INFO - ‚úÖ All hooks removed after evaluation\n",
      "2025-07-09 13:19:14,371 - INFO - üîß Silencing 160 EXCLUSIVE neurons for class 0\n",
      "2025-07-09 13:19:14,371 - INFO - üìå Layer 0: silencing 1 exclusive neurons for class 0\n",
      "2025-07-09 13:19:14,371 - INFO - üìå Layer 2: silencing 9 exclusive neurons for class 0\n",
      "2025-07-09 13:19:14,372 - INFO - üìå Layer 3: silencing 2 exclusive neurons for class 0\n",
      "2025-07-09 13:19:14,372 - INFO - üìå Layer 4: silencing 6 exclusive neurons for class 0\n",
      "2025-07-09 13:19:14,372 - INFO - üìå Layer 5: silencing 6 exclusive neurons for class 0\n",
      "2025-07-09 13:19:14,373 - INFO - üìå Layer 6: silencing 4 exclusive neurons for class 0\n",
      "2025-07-09 13:19:14,373 - INFO - üìå Layer 7: silencing 14 exclusive neurons for class 0\n",
      "2025-07-09 13:19:14,373 - INFO - üìå Layer 8: silencing 10 exclusive neurons for class 0\n",
      "2025-07-09 13:19:14,373 - INFO - üìå Layer 9: silencing 19 exclusive neurons for class 0\n",
      "2025-07-09 13:19:14,374 - INFO - üìå Layer 10: silencing 32 exclusive neurons for class 0\n",
      "2025-07-09 13:19:14,374 - INFO - üìå Layer 11: silencing 57 exclusive neurons for class 0\n",
      "2025-07-09 13:20:30,874 - INFO - üéØ Accuracy after exclusive silencing: 0.8400\n",
      "2025-07-09 13:20:30,876 - INFO - üìè Weighted F1 Score: 0.8306\n",
      "2025-07-09 13:20:30,876 - INFO - üìã Classification report saved to data/BigBird/results/exclusive_class_silencing_0.csv\n",
      "2025-07-09 13:20:30,876 - INFO - ‚úÖ All hooks removed after evaluation\n",
      "2025-07-09 13:20:30,877 - INFO - üîß Silencing 144 EXCLUSIVE neurons for class 4\n",
      "2025-07-09 13:20:30,877 - INFO - üìå Layer 6: silencing 2 exclusive neurons for class 4\n",
      "2025-07-09 13:20:30,878 - INFO - üìå Layer 7: silencing 10 exclusive neurons for class 4\n",
      "2025-07-09 13:20:30,878 - INFO - üìå Layer 8: silencing 5 exclusive neurons for class 4\n",
      "2025-07-09 13:20:30,878 - INFO - üìå Layer 9: silencing 13 exclusive neurons for class 4\n",
      "2025-07-09 13:20:30,879 - INFO - üìå Layer 10: silencing 50 exclusive neurons for class 4\n",
      "2025-07-09 13:20:30,879 - INFO - üìå Layer 11: silencing 64 exclusive neurons for class 4\n",
      "2025-07-09 13:21:46,830 - INFO - üéØ Accuracy after exclusive silencing: 0.8600\n",
      "2025-07-09 13:21:46,830 - INFO - üìè Weighted F1 Score: 0.8552\n",
      "2025-07-09 13:21:46,830 - INFO - üìã Classification report saved to data/BigBird/results/exclusive_class_silencing_4.csv\n",
      "2025-07-09 13:21:46,831 - INFO - ‚úÖ All hooks removed after evaluation\n",
      "2025-07-09 13:21:46,831 - INFO - üîß Silencing 176 EXCLUSIVE neurons for class 2\n",
      "2025-07-09 13:21:46,832 - INFO - üìå Layer 2: silencing 2 exclusive neurons for class 2\n",
      "2025-07-09 13:21:46,832 - INFO - üìå Layer 3: silencing 8 exclusive neurons for class 2\n",
      "2025-07-09 13:21:46,832 - INFO - üìå Layer 4: silencing 11 exclusive neurons for class 2\n",
      "2025-07-09 13:21:46,832 - INFO - üìå Layer 5: silencing 10 exclusive neurons for class 2\n",
      "2025-07-09 13:21:46,833 - INFO - üìå Layer 6: silencing 8 exclusive neurons for class 2\n",
      "2025-07-09 13:21:46,833 - INFO - üìå Layer 7: silencing 22 exclusive neurons for class 2\n",
      "2025-07-09 13:21:46,834 - INFO - üìå Layer 8: silencing 9 exclusive neurons for class 2\n",
      "2025-07-09 13:21:46,834 - INFO - üìå Layer 9: silencing 16 exclusive neurons for class 2\n",
      "2025-07-09 13:21:46,834 - INFO - üìå Layer 10: silencing 30 exclusive neurons for class 2\n",
      "2025-07-09 13:21:46,835 - INFO - üìå Layer 11: silencing 60 exclusive neurons for class 2\n",
      "2025-07-09 13:23:02,810 - INFO - üéØ Accuracy after exclusive silencing: 0.8200\n",
      "2025-07-09 13:23:02,810 - INFO - üìè Weighted F1 Score: 0.8056\n",
      "2025-07-09 13:23:02,811 - INFO - üìã Classification report saved to data/BigBird/results/exclusive_class_silencing_2.csv\n",
      "2025-07-09 13:23:02,811 - INFO - ‚úÖ All hooks removed after evaluation\n"
     ]
    }
   ],
   "source": [
    "# --- Run silencing experiments for each class with its exclusive neurons ---\n",
    "for class_id, neuron_indices in exclusive_class_neurons.items():\n",
    "    silence_exclusive_class_and_evaluate(\n",
    "        model=model,\n",
    "        sample_df=sample_df,\n",
    "        labels_list=labels_list,\n",
    "        exclusive_neuron_indices=neuron_indices,\n",
    "        class_id=class_id,\n",
    "        report_path=f\"{BASE_PATH}/results/exclusive_class_silencing_{class_id}.csv\",\n",
    "        experiment_title=f\"Silencing exclusive neurons for class {class_id}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffe637b",
   "metadata": {},
   "source": [
    "# GoEmotions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cd5efc",
   "metadata": {},
   "source": [
    "## Dataset Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "075a5800-8b1d-49a9-a078-ac3bed4a42cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìÅ Dataset and mappings\n",
    "GOEMOTIONS_PATH = \"data/goemotions\"\n",
    "INPUT_FILE = f\"{GOEMOTIONS_PATH}/test.tsv\"\n",
    "EMOTIONS_FILE = f\"{GOEMOTIONS_PATH}/emotions.txt\"\n",
    "\n",
    "# üéØ Target emotions (subset of original GoEmotions)\n",
    "TARGET_EMOTIONS = [\"anger\", \"disgust\", \"fear\", \"joy\", \"sadness\", \"surprise\"]\n",
    "\n",
    "# üß† Pretrained Model\n",
    "GOEMOTIONS_MODEL_HF = \"monologg/bert-base-cased-goemotions-original\"\n",
    "\n",
    "# üíæ Outputs\n",
    "SAMPLE_OUTPUT = f\"{GOEMOTIONS_PATH}/sample_60.json\"\n",
    "TOKENIZED_OUTPUT = f\"{GOEMOTIONS_PATH}/tokenized.pt\"\n",
    "LABELS_OUTPUT = f\"{GOEMOTIONS_PATH}/labels.pt\"\n",
    "LABEL_MAPPING_OUTPUT = f\"{GOEMOTIONS_PATH}/label_mapping.json\"\n",
    "CSV_REPORT_PATH = f\"{GOEMOTIONS_PATH}/classification_report_eval.csv\"\n",
    "CSV_REPORT_GOBAL_SILENCING = f\"{GOEMOTIONS_PATH}/classification_report_global_silencing.csv\"\n",
    "ACTIVATIONS_GOEMOTIONS = f\"{GOEMOTIONS_PATH}/activations.json\"\n",
    "SAMPLE_OUTPUT_JSON = \"data/goemotions/sample_df.json\"\n",
    "# üìü Device\n",
    "\n",
    "device_goemo = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e8f3cfa-1009-480a-9bf3-7648189e4b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Skipping dataset generation: data/goemotions/sample_60.json already exists.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(SAMPLE_OUTPUT):\n",
    "    # üì• Load emotion names\n",
    "    with open(EMOTIONS_FILE, \"r\") as f:\n",
    "        id2emotion = [line.strip() for line in f.readlines()]\n",
    "    emotion2id = {e: i for i, e in enumerate(id2emotion)}\n",
    "\n",
    "    # üéØ Select target emotions and their GoEmotions IDs\n",
    "    TARGET_EMOTIONS = [\"anger\", \"disgust\", \"fear\", \"joy\", \"sadness\", \"surprise\"]\n",
    "    target_ids = [emotion2id[e] for e in TARGET_EMOTIONS]\n",
    "\n",
    "    # üåê Mapping from GoEmotion ID to 0‚Äì5 label\n",
    "    goemo2local = {eid: i for i, eid in enumerate(target_ids)}\n",
    "\n",
    "    # üìä Load dataset\n",
    "    df = pd.read_csv(INPUT_FILE, sep=\"\\t\", header=None, names=[\"text\", \"labels\", \"split\"])\n",
    "    df = df.dropna(subset=[\"labels\"])\n",
    "    df[\"label_ids\"] = df[\"labels\"].apply(lambda x: list(map(int, str(x).split(\",\"))))\n",
    "\n",
    "    # üßº Filter: single-label only & target emotions\n",
    "    df_filtered = df[df[\"label_ids\"].apply(lambda ids: len(ids) == 1 and ids[0] in target_ids)].copy()\n",
    "    df_filtered[\"label_id\"] = df_filtered[\"label_ids\"].apply(lambda ids: goemo2local[ids[0]])\n",
    "\n",
    "    # üìâ Count examples per class\n",
    "    counts = df_filtered[\"label_id\"].value_counts()\n",
    "    print(\"Available examples for selected emotions:\")\n",
    "    print(counts)\n",
    "\n",
    "    # üéØ Balanced subset (max 10 per class)\n",
    "    max_per_class = 10\n",
    "    samples = []\n",
    "\n",
    "    for label in counts.index:\n",
    "        subset = df_filtered[df_filtered[\"label_id\"] == label]\n",
    "        sampled = shuffle(subset, random_state=42).iloc[:max_per_class]\n",
    "        samples.append(sampled[[\"text\", \"label_id\"]])\n",
    "\n",
    "    df_final = pd.concat(samples).reset_index(drop=True)\n",
    "\n",
    "    # üíæ Save to JSON\n",
    "    df_final.to_json(SAMPLE_OUTPUT, orient=\"records\", lines=True, force_ascii=False)\n",
    "    print(f\"\\n‚úÖ Saved dataset: {len(df_final)} examples (max {max_per_class} per emotion)\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Skipping dataset generation: {SAMPLE_OUTPUT} already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6171c43b",
   "metadata": {},
   "source": [
    "## Original Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6ee02c",
   "metadata": {},
   "source": [
    "### Load model, tokenizer and inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1427f3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 18:05:15,964 - WARNING - ‚ö†Ô∏è Skipping: data/goemotions/tokenized.pt already exists.\n",
      "2025-07-09 18:05:15,965 - WARNING - ‚ö†Ô∏è Skipping: data/goemotions/labels.pt already exists.\n",
      "2025-07-09 18:05:15,966 - WARNING - ‚ö†Ô∏è Skipping: data/goemotions/label_mapping.json already exists.\n",
      "2025-07-09 18:05:15,966 - WARNING - ‚ö†Ô∏è Skipping: data/goemotions/sample_df.json already exists.\n",
      "2025-07-09 18:05:15,967 - INFO - üß† Emotions (IDs): [0, 1, 2, 3, 4, 5]\n",
      "2025-07-09 18:05:15,967 - INFO - üî¢ Label mapping: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5}\n"
     ]
    }
   ],
   "source": [
    "# üì• Load dataset\n",
    "with open(SAMPLE_OUTPUT, \"r\") as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "\n",
    "texts = [x[\"text\"] for x in data]\n",
    "labels = [x[\"label_id\"] for x in data]\n",
    "\n",
    "# üî¢ Label mappings\n",
    "label2id = {label: i for i, label in enumerate(sorted(set(labels)))}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "label_ids = [label2id[label] for label in labels]\n",
    "\n",
    "# üî† Tokenize and save only if not already saved\n",
    "tokenizer = AutoTokenizer.from_pretrained(GOEMOTIONS_MODEL_HF)\n",
    "\n",
    "if not os.path.exists(TOKENIZED_OUTPUT):\n",
    "    encodings = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    torch.save(encodings, TOKENIZED_OUTPUT)\n",
    "    logger.info(\"‚úÖ Tokenized inputs saved.\")\n",
    "else:\n",
    "    logger.warning(f\"‚ö†Ô∏è Skipping: {TOKENIZED_OUTPUT} already exists.\")\n",
    "\n",
    "if not os.path.exists(LABELS_OUTPUT):\n",
    "    torch.save(torch.tensor(label_ids), LABELS_OUTPUT)\n",
    "    logger.info(\"‚úÖ Label tensor saved.\")\n",
    "else:\n",
    "    logger.warning(f\"‚ö†Ô∏è Skipping: {LABELS_OUTPUT} already exists.\")\n",
    "\n",
    "if not os.path.exists(LABEL_MAPPING_OUTPUT):\n",
    "    with open(LABEL_MAPPING_OUTPUT, \"w\") as f:\n",
    "        json.dump(label2id, f, indent=2)\n",
    "    logger.info(\"‚úÖ Label mapping saved.\")\n",
    "else:\n",
    "    logger.warning(f\"‚ö†Ô∏è Skipping: {LABEL_MAPPING_OUTPUT} already exists.\")\n",
    "\n",
    "# ‚úÖ NEW: Generate sample_df for later neuron silencing evaluation\n",
    "if not os.path.exists(SAMPLE_OUTPUT_JSON):\n",
    "    logger.info(\"üìÑ Creating and saving sample_df.json for evaluation hooks...\")\n",
    "    sample_rows = []\n",
    "    for text in texts:\n",
    "        encoded = tokenizer(text, truncation=True, padding=\"max_length\", max_length=128)\n",
    "        sample_rows.append({\n",
    "            \"input_ids\": encoded[\"input_ids\"],\n",
    "            \"attention_mask\": encoded[\"attention_mask\"]\n",
    "        })\n",
    "    sample_df = pd.DataFrame(sample_rows)\n",
    "    sample_df.to_json(SAMPLE_OUTPUT_JSON, orient=\"records\", lines=True)\n",
    "    logger.info(f\"‚úÖ sample_df saved to {SAMPLE_OUTPUT_JSON}\")\n",
    "else:\n",
    "    logger.warning(f\"‚ö†Ô∏è Skipping: {SAMPLE_OUTPUT_JSON} already exists.\")\n",
    "\n",
    "# Summary\n",
    "logger.info(\"üß† Emotions (IDs): %s\", sorted(label2id.keys()))\n",
    "logger.info(\"üî¢ Label mapping: %s\", label2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7c6bd3",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da771ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Target GoEmotions IDs: [2, 11, 14, 17, 25, 26]\n",
      "üó∫Ô∏è Mapping to local labels: {2: 0, 11: 1, 14: 2, 17: 3, 25: 4, 26: 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 60/60 [00:01<00:00, 36.52it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "# Define the target GoEmotions IDs\n",
    "target_emotion_names = [\"anger\", \"disgust\", \"fear\", \"joy\", \"sadness\", \"surprise\"]\n",
    "\n",
    "# Load emotion mapping\n",
    "with open(EMOTIONS_FILE, \"r\") as f:\n",
    "    id2emotion = [line.strip() for line in f.readlines()]\n",
    "emotion2id = {e: i for i, e in enumerate(id2emotion)}\n",
    "\n",
    "target_ids = [emotion2id[e] for e in target_emotion_names]\n",
    "target_ids_tensor = torch.tensor(target_ids).to(device_goemo)\n",
    "\n",
    "# Map GoEmotions IDs ‚Üí local labels\n",
    "label2id = {goid: i for i, goid in enumerate(target_ids)}\n",
    "id2label = {i: goid for goid, i in label2id.items()}\n",
    "\n",
    "print(f\"üéØ Target GoEmotions IDs: {target_ids}\")\n",
    "print(f\"üó∫Ô∏è Mapping to local labels: {label2id}\")\n",
    "\n",
    "# Load model_goem\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "model_goem = AutoModelForSequenceClassification.from_pretrained(GOEMOTIONS_MODEL_HF)\n",
    "model_goem.to(device_goemo)\n",
    "model_goem.eval()\n",
    "\n",
    "# Load data\n",
    "inputs = torch.load(TOKENIZED_OUTPUT, weights_only=False)\n",
    "labels = torch.load(LABELS_OUTPUT).tolist()\n",
    "\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(len(labels))):\n",
    "        input_ids = inputs[\"input_ids\"][i].unsqueeze(0).to(device_goemo)\n",
    "        attention_mask = inputs[\"attention_mask\"][i].unsqueeze(0).to(device_goemo)\n",
    "\n",
    "        logits = model_goem(input_ids=input_ids, attention_mask=attention_mask).logits.squeeze(0)\n",
    "\n",
    "        selected_logits = logits[target_ids_tensor]\n",
    "        pred_local = torch.argmax(selected_logits).item()\n",
    "\n",
    "        predictions.append(pred_local)\n",
    "        true_labels.append(labels[i])  # already 0‚Äì5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c214269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Skipping save: data/goemotions/classification_report_eval.csv already exists.\n",
      "‚úÖ Accuracy: 0.8667\n",
      "‚úÖ F1 Score: 0.8649\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Report\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "f1 = f1_score(true_labels, predictions, average=\"weighted\")\n",
    "ordered_labels = sorted(label2id.values())\n",
    "\n",
    "report = classification_report(\n",
    "    true_labels,\n",
    "    predictions,\n",
    "    labels=ordered_labels,\n",
    "    target_names=[id2label[i] for i in ordered_labels],\n",
    "    output_dict=True,\n",
    "    zero_division=0\n",
    ")\n",
    "\n",
    "report_df = pd.DataFrame(report).transpose().round(4)\n",
    "accuracy_row = pd.DataFrame({\n",
    "    'precision': [\"\"],\n",
    "    'recall': [\"\"],\n",
    "    'f1-score': [accuracy],\n",
    "    'support': [sum(report_df[\"support\"])]\n",
    "}, index=[\"overall_accuracy\"])\n",
    "\n",
    "final_df = pd.concat([report_df, accuracy_row])\n",
    "\n",
    "if not os.path.exists(CSV_REPORT_PATH):\n",
    "    final_df.to_csv(CSV_REPORT_PATH)\n",
    "    print(f\"‚úÖ Report saved to {CSV_REPORT_PATH}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Skipping save: {CSV_REPORT_PATH} already exists.\")\n",
    "\n",
    "print(f\"‚úÖ Accuracy: {accuracy:.4f}\")\n",
    "print(f\"‚úÖ F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c26588",
   "metadata": {},
   "source": [
    "## Dataset Wrapper and DataLoader (Goemotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17c9a2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:‚úÖ Dataloader created successfully.\n"
     ]
    }
   ],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "class GoEmotionsDataset(Dataset):\n",
    "    def __init__(self, input_ids, labels):\n",
    "        self.input_ids = input_ids\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.input_ids[idx]), torch.tensor(self.labels[idx])\n",
    "\n",
    "# Load input IDs and labels from disk\n",
    "input_data = torch.load(TOKENIZED_OUTPUT, weights_only=False)\n",
    "labels = torch.load(LABELS_OUTPUT).tolist()\n",
    "\n",
    "input_ids_list = input_data[\"input_ids\"].tolist()\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = GoEmotionsDataset(input_ids_list, labels)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "logger.info(\"‚úÖ Dataloader created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ec9474",
   "metadata": {},
   "source": [
    "## Extract Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0016430b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:‚ö° Activations already exist at data/goemotions/activations.json. Skipping extraction.\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(ACTIVATIONS_GOEMOTIONS):\n",
    "    logger.info(f\"‚ö° Activations already exist at {ACTIVATIONS_GOEMOTIONS}. Skipping extraction.\")\n",
    "else:\n",
    "    logger.info(\"üöÄ Starting activation extraction from model (CLS token only).\")\n",
    "    \n",
    "    transformers_extractor.extract_representations(\n",
    "        model=model_goem,\n",
    "        input_tokens_list=input_ids_list,   \n",
    "        output_file=ACTIVATIONS_GOEMOTIONS,\n",
    "        device=device_goemo,\n",
    "        output_type=\"json\",                \n",
    "        decompose_layers=False,\n",
    "        filter_layers=None\n",
    "    )\n",
    "\n",
    "    logger.info(f\"‚úÖ Activations successfully saved to {ACTIVATIONS_GOEMOTIONS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2363399",
   "metadata": {},
   "source": [
    "## Load Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa7eff78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def create_tensors_goemo(tokens_data, activations, task_specific_tag=\"NN\", task_type=\"classification\", dtype=torch.float32):\n",
    "    \"\"\"\n",
    "    Create input/output tensors from CLS activations and labels for classification tasks.\n",
    "\n",
    "    Args:\n",
    "        tokens_data (list): List of dicts with keys \"tokens\" and \"target\"\n",
    "        activations (list): List of numpy arrays with CLS activations\n",
    "        task_specific_tag (str): Not used for CLS, kept for compatibility\n",
    "        task_type (str): \"classification\" or \"regression\"\n",
    "        dtype (torch.dtype): Data type of the tensors\n",
    "\n",
    "    Returns:\n",
    "        X (torch.Tensor): Input features (num_samples, num_layers * hidden_size)\n",
    "        y (torch.Tensor): Labels\n",
    "        mapping (tuple): label2idx, idx2label, None, None\n",
    "    \"\"\"\n",
    "\n",
    "    logger.info(\"üîÑ Creating tensors from activations and labels\")\n",
    "\n",
    "    # Number of samples\n",
    "    num_samples = len(tokens_data)\n",
    "    assert num_samples == len(activations), \"Mismatch between tokens and activations\"\n",
    "\n",
    "    logger.info(f\"üß™ Number of samples: {num_samples}\")\n",
    "\n",
    "    # Flatten each activation: (num_layers, 1, hidden_dim) ‚Üí (num_layers * hidden_dim)\n",
    "    X = []\n",
    "    for i, sample in enumerate(activations):\n",
    "        if sample.ndim == 3 and sample.shape[1] == 1:\n",
    "            flattened = sample.squeeze(1).flatten()\n",
    "        elif sample.ndim == 2:\n",
    "            flattened = sample.flatten()\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected shape for activation {i}: {sample.shape}\")\n",
    "        X.append(flattened)\n",
    "    X = np.array(X)\n",
    "\n",
    "    \n",
    "    # Encode labels\n",
    "    labels = [sample[\"target\"] for sample in tokens_data]\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(labels)\n",
    "\n",
    "    # Logging label mapping\n",
    "    label2idx = {label: int(idx) for idx, label in enumerate(label_encoder.classes_)}\n",
    "    idx2label = {int(idx): label for label, idx in label2idx.items()}\n",
    "    logger.info(f\"üî¢ Labels mapping: {label2idx}\")\n",
    "\n",
    "    return (\n",
    "        torch.tensor(X, dtype=dtype),\n",
    "        torch.tensor(y),\n",
    "        (label2idx, idx2label, None, None)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "37c29373",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:‚úÖ Activations loaded from data/goemotions/activations.json with 12 layers\n",
      "INFO:__main__:üîÑ Creating tensors from activations and labels\n",
      "INFO:__main__:üß™ Number of samples: 60\n",
      "INFO:__main__:üî¢ Labels mapping: {np.int64(0): 0, np.int64(1): 1, np.int64(2): 2, np.int64(3): 3, np.int64(4): 4, np.int64(5): 5}\n",
      "INFO:__main__:‚úÖ Tensors and label mappings created successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading json activations from data/goemotions/activations.json...\n",
      "60 12.0\n"
     ]
    }
   ],
   "source": [
    "from neurox.data.loader import load_activations\n",
    "from neurox.interpretation import utils\n",
    "\n",
    "# ‚ö° Load activations\n",
    "activations, num_layers = load_activations(ACTIVATIONS_GOEMOTIONS)\n",
    "logger.info(f\"‚úÖ Activations loaded from {ACTIVATIONS_GOEMOTIONS} with {num_layers} layers\")\n",
    "\n",
    "# üß† Prepare dataset with correct structure\n",
    "sentence_data = [{\"tokens\": [\"[CLS]\"], \"target\": label} for label in labels]\n",
    "\n",
    "# üì¶ Convert to tensors\n",
    "X, y, mapping = create_tensors_goemo(\n",
    "    sentence_data,\n",
    "    activations,\n",
    "    task_specific_tag=\"NN\",\n",
    "    task_type=\"classification\"\n",
    ")\n",
    "\n",
    "label2idx, idx2label, _, _ = mapping\n",
    "logger.info(\"‚úÖ Tensors and label mappings created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670171ad",
   "metadata": {},
   "source": [
    "## Train Probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cbc4f72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:üîß Training logistic regression probe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases en y_train: [0 1 2 3 4 5]\n",
      "Training classification probe\n",
      "Creating model...\n",
      "Number of training instances: 60\n",
      "Number of classes: 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3ef48bb58614a1090927d94e476abea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch [1/10]: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/10], Loss: 0.1458\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12dbf99e25de4079844a88cd91dd0661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch [2/10]: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2/10], Loss: 0.0373\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f438df9a4d184269a52e0c20ea09a0df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch [3/10]: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3/10], Loss: 0.0210\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00f57eab17744088b607cca4ea33dd69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch [4/10]: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4/10], Loss: 0.0291\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bb11a86ebab4da9b6292353b37d4f17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch [5/10]: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5/10], Loss: 0.0214\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10a449cb2fe0416d8cf3cd5231be62c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch [6/10]: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6/10], Loss: 0.0147\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8627b62b3264fa1b32b864268d313ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch [7/10]: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7/10], Loss: 0.0131\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "332678bed14140fbb4f9a2cb20671d33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch [8/10]: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8/10], Loss: 0.0121\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88218252f2da430f8820780fed2b91cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch [9/10]: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9/10], Loss: 0.0114\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1992711c5d742c2ab3ec85b3cbf2b01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch [10/10]: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:üìà Evaluating the probe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10/10], Loss: 0.0112\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c512db6bbdcd4c1692db9da10459fc92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:üéØ Probe evaluation results:\n",
      "{'__OVERALL__': np.float64(1.0), np.int64(0): np.float64(1.0), np.int64(1): np.float64(1.0), np.int64(2): np.float64(1.0), np.int64(3): np.float64(1.0), np.int64(4): np.float64(1.0), np.int64(5): np.float64(1.0)}\n",
      "INFO:__main__:üß† Top global neurons: [8195 8196 8197 ... 8182 8183 8189]\n",
      "INFO:__main__:üß† Top neurons per class: {np.int64(0): array([7567, 3413, 7266, 7982, 7852, 9092, 8075, 8788, 4059, 4909, 9136,\n",
      "       5616, 6987, 4576, 8125, 7997, 9160, 8370, 7027, 6302, 9202, 7213,\n",
      "       5104, 7760, 7738, 6289, 8812, 5678, 4723, 1693, 8216, 7087, 6458,\n",
      "       6951, 5103, 4219, 8496, 8001, 3091, 7208, 6022, 8394, 6523, 7882,\n",
      "       7323, 6462, 5042, 8268, 7229, 6445, 6362, 2632, 6003, 7914, 6144,\n",
      "       6292, 6546, 6486, 9180, 3859, 9100, 6984, 8988, 8505, 6706, 7287,\n",
      "       9022, 8138, 7838, 8431, 9203, 5318, 8455, 8382, 7551, 7863, 8022,\n",
      "       5197, 7281, 6472, 4190, 6211, 6722, 6605, 4671, 7291, 2461, 5228,\n",
      "       5589, 9021, 8269, 8487, 5439, 8799, 8701, 4350, 7000, 7240, 5817,\n",
      "       7734, 8542, 8429, 8877, 8661, 7186, 8231, 3819, 6421, 3981, 7704,\n",
      "       7064, 8176, 4679, 5964, 7784, 6249, 6727, 6630, 8574, 6773, 9102,\n",
      "       5491, 5693, 5132, 8203, 4308, 6214, 6635, 4642, 5046, 9183, 8302,\n",
      "       4821, 4756, 9124, 2146, 4857, 3841, 7502, 7857, 7594, 8777, 6733,\n",
      "       4432, 5084, 4990, 7877, 8663, 3711, 6030, 6479, 8274, 7079, 6205,\n",
      "       5928, 8606, 7315, 8442, 8415, 3407, 7014, 7745, 5891, 9024, 8436,\n",
      "       2916, 5643, 8270, 6804, 5058, 3887, 4416, 8636, 6790, 7465, 3912,\n",
      "       7989, 5577, 8189, 7788, 5392, 7782, 8984, 8205, 7214, 8349, 7743,\n",
      "       4232, 8620, 6226, 8731, 8197, 8660, 8567, 7429, 8957, 6259, 7369,\n",
      "       6918, 8295, 3904, 8827, 5586, 7174, 8137, 4095, 7604, 5458, 9139,\n",
      "       3833, 5632, 8300, 4383, 8257, 4284, 5272, 7317, 7258, 3911, 7954,\n",
      "       7627, 5704, 8489, 4086, 3480, 8303, 5278, 3873, 5059, 8363, 7305,\n",
      "       8229, 4052, 7017, 7183, 8096, 4946,  465, 3540, 7227, 7602, 8267,\n",
      "       5584, 4766, 3929, 7531, 7366, 7731, 6900, 8551, 7744, 7631, 8346,\n",
      "       6122, 8447, 8640, 5573, 8010, 7251, 8675, 3673, 5682, 6200, 5485,\n",
      "       7900, 3687, 8832, 8748, 8785, 7730, 6919, 5987, 7128, 8707, 6872,\n",
      "       5493, 9128, 2622, 4851, 9211, 4935, 6216, 2745, 8841, 9008, 6925,\n",
      "       8308, 7991, 8972, 6382, 8671, 5778, 3765, 1577, 7447]), np.int64(1): array([6238, 8881, 6591, 8798, 9046, 3960, 8353, 5098, 7114, 2314, 6693,\n",
      "       6917, 6341, 4229, 7237, 7130, 6009, 3719, 7670, 4154, 7950, 3409,\n",
      "       2063, 4649, 6466, 5971, 3424, 7307, 6683, 4606, 3615, 4873, 6875,\n",
      "       7986, 4421, 6539, 7750, 7711, 8275, 5410, 7752, 3796, 7365, 9145,\n",
      "       9070, 6403, 8142, 5878, 1762, 8262, 7800, 8858, 7170, 6998, 7036,\n",
      "       8808, 7103, 7697, 4284, 6641, 1421, 1564, 3349, 3627, 8422, 6394,\n",
      "       8696, 2846, 8396, 8745, 4332, 6981, 4376, 5203, 8075, 7044, 8477,\n",
      "       6137, 2371, 9004, 5144, 7490, 7963, 6779, 6671, 5744, 6300, 9110,\n",
      "       4078, 6374, 6714, 6345, 8208, 8995, 9016, 4263, 7591, 5855,  777,\n",
      "       2815, 8354, 8514, 8257, 8741, 8330, 8099, 8039, 7322, 6808, 7162,\n",
      "       4976, 7140, 8708, 2811, 6842, 3431, 7501, 8512, 6379, 7448, 7643,\n",
      "       8802, 8853, 8962, 6339, 2772, 3562, 8384, 6893, 8671, 6325, 8721,\n",
      "       8895, 6764, 7003, 6443, 5487, 8884, 6791, 6596, 8165, 5895, 8926,\n",
      "       7098, 6149, 8471, 8898, 1413, 6479, 7761, 5584, 7211, 4518, 3905,\n",
      "       6334, 5360, 7766, 7769, 5110, 8183, 6703, 6544, 6853, 9182, 7309,\n",
      "       5571, 6461, 7746, 8333, 6402, 4602, 7461, 7562, 9139, 6219, 4190,\n",
      "       5277, 6503, 6309, 6335, 4588, 8986, 4388, 8177, 8769, 8129, 4142,\n",
      "       8421, 3873, 5213, 8005, 5270, 9054, 7483, 7218, 7397, 7534, 6401,\n",
      "       6551, 6746, 5503, 5020, 8269, 8547, 7439, 8394, 6312, 3016, 7801,\n",
      "       6820, 3809, 7741, 9180, 4579, 6248, 7463, 8342, 5272, 7251, 3091,\n",
      "       3217, 7283, 6211, 7188, 9143, 8251, 6699, 7045, 8115, 4727, 4265,\n",
      "       8219, 4697, 7438, 3991, 9010, 8987, 3413, 7423, 8816, 7331, 8570,\n",
      "       7736, 8286, 3749, 5339, 8788, 7107, 3931, 7570, 8812, 5616, 8659,\n",
      "       7359, 3972, 8842, 9095, 7022, 5256, 3477, 5132, 8037, 3941, 3269,\n",
      "       9022, 3929, 8593, 7588, 4162, 5417, 6530, 4550, 4187, 6967, 6652,\n",
      "       7943, 4552, 5458, 8300, 8496, 6949, 6774, 7455, 7754, 8974, 5489,\n",
      "       4962, 3250, 6775, 3572]), np.int64(2): array([4153, 7100, 6159, 4115, 4301, 4973, 8095, 8474, 8944, 3616, 6974,\n",
      "       6382, 6994, 8101, 3696, 8305, 7892, 8285, 7116, 4546, 7513, 9110,\n",
      "       3901, 8270, 8196, 6367, 8816, 3582, 6447, 7864, 5966, 6744, 8914,\n",
      "       6099, 7996, 3001, 3072, 7961, 7623, 3846, 6299, 8363, 8451, 7875,\n",
      "       2714, 3202, 4593, 3598, 8296, 8632, 8181, 9138, 5331, 5133, 6959,\n",
      "       8927, 8329, 8895, 5901, 8855, 8303, 7775, 7886, 7418, 6296, 8533,\n",
      "       6124, 5788, 8539, 9038, 7184, 9101, 8483, 7193, 8097, 8014, 9035,\n",
      "       8019, 4993, 2387, 5692, 6337, 9024, 5648, 5536, 8692, 6540, 6180,\n",
      "       8199, 6989, 5244, 6715, 6759, 3431, 5356, 5045, 8628, 8592, 6470,\n",
      "       9086, 7158, 5255, 7105, 4910, 5761, 9026, 3850, 8353, 8136, 8010,\n",
      "       3240, 8318, 6899, 7069, 7221, 5826, 4296, 8571, 8861, 1648, 7800,\n",
      "       5988, 8925, 8321, 7762, 6406, 6933, 6455, 9084, 3273, 4088, 6303,\n",
      "       9173, 4449, 7341, 8121, 6734, 7672, 9168, 5507, 4876, 6298, 8840,\n",
      "       6448, 6806, 2818, 3856, 4542, 8953, 7045, 6232, 6752, 7602, 4046,\n",
      "       4610, 7670, 2107, 7223, 4768, 2038, 5216, 5568, 5467, 8800, 4623,\n",
      "       7368, 6551, 8662, 7700, 5004, 6503, 5277, 4805, 3356, 7997, 6569,\n",
      "       8493, 8070, 6233, 7937, 7333, 7114, 4618, 7988, 7863, 7501, 4057,\n",
      "       5213, 7155, 5833, 8414, 3970, 9097, 6603, 6737, 7264, 8548, 8874,\n",
      "       3528, 4429, 8161, 6213, 3692, 4890, 6967, 7143, 8643, 4948, 3732,\n",
      "       7483, 8834, 8717, 7551, 4350, 8920, 8144, 4868, 5768, 8886, 6126,\n",
      "       2354, 7308, 8836, 3951, 8002, 8258, 6836, 5771, 8946, 6848, 5997,\n",
      "       9031, 8617, 8162, 6987, 7529, 7060, 6932, 7652, 7490, 3451, 6274,\n",
      "       7779, 8847, 4923, 7257, 7985, 8530, 6686, 8751, 8135, 7752, 7603,\n",
      "       6625, 6412, 7220, 4870, 3188, 8705, 8984, 8513, 8481, 7950, 8205,\n",
      "       4652, 6689, 6144, 5922, 2964, 3710, 8251, 8025, 4390, 8697, 6056,\n",
      "       4035, 6556, 8438, 3041, 6103, 5710]), np.int64(3): array([7792, 8061, 5711, 9185, 8418, 8017, 8515, 7684, 8952, 6406, 7307,\n",
      "       7842, 7317, 7123, 6772, 8396, 9018, 7033, 8169, 8200, 4181, 8401,\n",
      "       5604, 7415, 5141, 4922, 7909, 3038, 5576, 6668, 6569, 5099, 8611,\n",
      "       8054, 8508, 4658, 8333, 6068, 6496, 7990, 9131, 6860, 8800, 1553,\n",
      "       5869, 5932, 6082, 8948, 8916, 7599, 6857, 7892, 6295, 8986, 8477,\n",
      "       5390, 6004, 9173, 8143, 7319, 3223, 8173, 8819, 3967, 7948, 6935,\n",
      "       8049, 7009, 5066, 4721, 8466, 5832, 9175, 6508, 8481, 7350, 8365,\n",
      "       8382, 7956, 4995, 3436, 6747, 7393, 6126, 8265, 8825, 5839, 7283,\n",
      "       6089, 7016, 8373, 5707, 8639, 5074, 3658, 7968, 9210, 7787, 6371,\n",
      "       9213, 8346, 4987, 7202, 8400, 5568, 4568, 8022, 5540, 8079, 8296,\n",
      "       6152, 7984, 7286, 8288, 3400, 7517, 9214, 3413, 8827, 7056, 7090,\n",
      "       6527, 8440, 5041, 8252, 8896, 5782, 5106, 4306, 8291, 8002, 7348,\n",
      "       8614, 6303, 1798, 8968, 6853, 8353, 7005, 6943, 2425, 7543, 5749,\n",
      "       4622, 8529, 7272, 5481, 6698, 8609, 7289, 7067, 8417, 5890, 7084,\n",
      "       6718, 7791, 7510, 5788, 8196, 6416, 8619, 7760, 3459, 6941, 9136,\n",
      "       7825, 8245, 7929, 8065, 7075, 7432, 8470, 8663, 8552, 3414, 5255,\n",
      "       3415, 7249, 8213, 6243, 9095, 7689, 7484, 8774, 9141, 8935, 8863,\n",
      "       8498, 9049, 7372, 9111, 5111, 6300, 4354, 6579, 3798, 9059, 6379,\n",
      "       7530, 8641, 5691, 3663, 7232, 7917, 8006, 4002, 7589, 5013, 3971,\n",
      "       8685, 8635, 7720, 6042, 6278, 8905, 1624, 8223, 7701, 3358, 6053,\n",
      "       8881, 8299, 5842, 8793, 6096, 6848, 8705, 8137, 8115, 6760, 6851,\n",
      "       7487, 8616, 5572, 8203, 8870, 4853, 5673, 9071, 8114, 7652, 8648,\n",
      "       9150, 5670, 8038, 8117, 8980, 8069, 6978, 2723, 6585, 7860, 5976,\n",
      "       4227, 7104, 7242, 6512, 7311, 7228, 7632, 4793, 9019, 5814, 6879,\n",
      "       8753, 7861, 7611, 7003, 8937, 6391, 7059, 7136, 9057, 7263, 7696,\n",
      "       6992, 9211, 4382, 4631, 8307, 9124, 7353, 8803, 8493, 7329, 5244,\n",
      "       4593, 1764, 6272, 5688, 7528, 8244, 9112, 7995]), np.int64(4): array([9206, 6606, 8366, 7542, 8181, 8573, 7539, 7780, 8180, 8364, 7954,\n",
      "       7962, 8382, 8921, 6296, 3732, 7854, 9019, 7288, 6605, 7614, 8408,\n",
      "       7452, 7366, 9027, 6576, 4928, 7317, 8984, 7132, 7029, 8643, 8638,\n",
      "       7565, 7786, 8468, 4410, 6028, 8409, 7218, 8169, 8845, 6421, 6454,\n",
      "       9152, 7186, 6278, 7540, 7818, 8471, 8871, 7795, 6314, 4077, 9065,\n",
      "       4247, 6308, 8444, 4105, 3299, 8540, 8413, 5314, 4315, 6248, 8306,\n",
      "       8686, 7256, 7606, 7704, 8925, 7946, 8736, 7014, 8687, 3998, 5150,\n",
      "       4010, 7280, 6648, 4108, 7570, 8467, 8641, 8975, 3911, 7102, 7872,\n",
      "       8198, 7017, 8721, 3202, 4678, 6447, 7116, 5831, 8297, 8536, 6689,\n",
      "       2803, 7232, 6259, 7560, 6772, 8535, 7234, 5052, 5379, 3796, 6652,\n",
      "       7891, 5726, 7207, 8260, 3627, 5996, 3464, 5000, 4534, 7018, 8869,\n",
      "       4272, 8983, 5015, 8915, 7033, 7897, 6932, 7361, 7762, 6760, 8578,\n",
      "       7118, 7521, 8802, 4723, 7009, 8937, 3889, 7107, 5107, 7527, 7916,\n",
      "       7064, 6988, 5110, 4418, 3941, 9021, 3344, 4717, 6310, 8450, 8574,\n",
      "       8856, 4067, 7524, 8711, 4800, 8866, 3970, 4500, 8257, 5767, 8152,\n",
      "       6978, 8489, 8620, 5315, 7744, 7109, 8199, 6095, 7743, 5900, 7747,\n",
      "       6362, 5696, 4738, 8023, 5270, 6205, 7577, 2819, 4007, 8628, 8195,\n",
      "       8582, 6526, 8477, 7463, 6239, 5020, 6686, 5467, 9144, 8699, 8442,\n",
      "       8117, 8840, 4661, 6217, 8215, 6443, 8244, 4078, 1935, 7922, 7776,\n",
      "       8606, 4284, 5825, 6834, 8680, 4775, 4332, 8000, 8559, 2196, 6023,\n",
      "       8143, 4100, 6270, 8307, 7104, 7000, 4170, 7627, 8555, 8411, 8971,\n",
      "       5648, 8046, 7588, 6752, 7638, 7824, 4747, 8935, 7717, 8332, 8336,\n",
      "       8451, 6395, 9110, 7497, 7573, 7238, 8258, 6948, 7548, 7174, 8182,\n",
      "       3567, 4786, 8349, 8016, 8474, 8284, 8624, 8524, 8225, 6167, 7746,\n",
      "       3904, 5447, 6417, 7054, 4677, 5396, 5240, 8630, 3443, 4639, 6241,\n",
      "       6082, 8075, 6058, 8144, 7462, 9066, 7856, 7220, 6369, 3734, 3901,\n",
      "       6569, 6546, 9180, 8684, 7501, 6157, 5328, 4412, 3853, 9061, 9055]), np.int64(5): array([5285, 8104, 4863, 5789, 6178, 8572, 2998, 7543, 8539, 5046, 7935,\n",
      "       5523, 5607, 4641, 7084, 4839, 4089, 8640, 8722, 7852, 4638, 4568,\n",
      "       6798, 6053, 8125, 8158, 8598, 8604, 1700, 7268, 4529, 3721, 8460,\n",
      "       6625, 9158, 5826, 9185, 8161, 6344, 6996, 8394, 7939, 5437, 8481,\n",
      "       7805, 9152, 7323, 9193, 4892, 9122, 8288, 7606, 8597, 7225, 6921,\n",
      "       5315, 8859, 7663, 8096, 7430, 6942, 3663, 8355, 6656, 9162, 9004,\n",
      "       5052, 6220, 6240, 6683, 4183, 8630, 6502, 6844, 4510, 8015, 5260,\n",
      "       3308, 6703, 7943, 8755, 7452, 6952, 7912, 8932, 7213, 8253, 7619,\n",
      "       7702, 7769, 8760, 6483, 3820, 6847, 7714, 9042, 6174, 6931, 8257,\n",
      "       7845, 8150, 8624, 5631, 8933, 3442, 6592, 8611, 6486, 5229, 3098,\n",
      "       8579, 7528, 8703, 7639, 7248, 7075, 7636, 5065, 6235, 7921, 6362,\n",
      "       6157, 9006, 8010, 6523, 7053, 3436, 8615, 5837, 4671, 8761, 7755,\n",
      "       8465, 1577, 9038, 8965, 5232, 7156, 6964, 8813, 6492, 4088, 8370,\n",
      "       6281, 9078, 9169, 9123, 5104, 8549, 8866, 6154, 6479, 1471, 7306,\n",
      "       9101, 9096, 7007, 6988, 8674, 8896, 5863, 8500, 8983, 8045, 8470,\n",
      "       5308, 7946, 2857, 1200, 6889, 8614, 3779, 3783, 5969, 9187, 8774,\n",
      "       6257, 7948, 8348, 7288, 7474, 5601, 6494, 6746, 5196, 6946, 7219,\n",
      "       8141, 8417, 7114, 8747, 9179, 7076, 5103, 8777, 7094, 6030, 8574,\n",
      "       8673, 9046, 7594, 9037, 7832, 8364, 7221, 4875, 6702, 7247, 5959,\n",
      "       7338, 5021, 4627, 7412, 9022, 7781, 8508, 7911, 5814, 4918, 7671,\n",
      "       8404, 6604, 5261, 7227, 4601, 8861, 4729, 5801, 6003, 9025, 6714,\n",
      "       4886, 8163, 7829, 9060, 5484, 5642, 4073, 7382, 8860, 8576, 6919,\n",
      "       6332, 8805, 7239, 5793, 5189, 7132, 5946, 6354, 3580, 4727, 3717,\n",
      "       6851, 8378, 8411, 8083, 4393, 5867, 8034, 8513, 8280, 5724, 8709,\n",
      "       9000, 7226, 1705, 6606, 4490, 6766, 8250, 7238, 7723, 8001, 6537,\n",
      "       7113, 8091, 8021, 7079, 7364, 9131, 6368, 5027, 5014, 8382, 7043])}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (accuracy) of the probe: 1.00\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Convert tensors to numpy arrays (required by train_logistic_regression_probe)\n",
    "X_np = X.numpy() if isinstance(X, torch.Tensor) else X\n",
    "y_np = y.numpy() if isinstance(y, torch.Tensor) else y\n",
    "\n",
    "# üß™ Train logistic regression probe\n",
    "logger.info(\"üîß Training logistic regression probe\")\n",
    "probe = linear_probe.train_logistic_regression_probe(\n",
    "    X_np, y_np,\n",
    "    lambda_l1=0.001,\n",
    "    lambda_l2=0.001\n",
    ")\n",
    "\n",
    "# üßæ Evaluate the trained probe\n",
    "logger.info(\"üìà Evaluating the probe\")\n",
    "scores = linear_probe.evaluate_probe(probe, X_np, y_np, idx_to_class=idx2label)\n",
    "logger.info(f\"üéØ Probe evaluation results:\\n{scores}\")\n",
    "\n",
    "# üîç Get top neurons\n",
    "top_neurons_probe, per_class_top_neurons = linear_probe.get_top_neurons(\n",
    "    probe,\n",
    "    percentage=0.1,\n",
    "    class_to_idx=label2idx\n",
    ")\n",
    "logger.info(f\"üß† Top global neurons: {top_neurons_probe}\")\n",
    "logger.info(f\"üß† Top neurons per class: {per_class_top_neurons}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393dc71c",
   "metadata": {},
   "source": [
    "## Global Silencing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594d8e58",
   "metadata": {},
   "source": [
    "## Silencing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b7ed7c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Load tokenized input and labels\n",
    "sample_df = pd.read_json(SAMPLE_OUTPUT_JSON, lines=True)\n",
    "labels_list = torch.load(LABELS_OUTPUT).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d187e65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:üîß Silencing exactly 230 neurons (2.50% of total 9216)\n",
      "INFO:__main__:üìÅ Saved neuron indices to data/BigBird/neurons/top_2p_neurons_global.json\n",
      "INFO:__main__:üìå Layer 2: silencing 1 neurons\n",
      "INFO:__main__:üìå Layer 3: silencing 1 neurons\n",
      "INFO:__main__:üìå Layer 4: silencing 9 neurons\n",
      "INFO:__main__:üìå Layer 5: silencing 11 neurons\n",
      "INFO:__main__:üìå Layer 6: silencing 14 neurons\n",
      "INFO:__main__:üìå Layer 7: silencing 11 neurons\n",
      "INFO:__main__:üìå Layer 8: silencing 33 neurons\n",
      "INFO:__main__:üìå Layer 9: silencing 46 neurons\n",
      "INFO:__main__:üìå Layer 10: silencing 46 neurons\n",
      "INFO:__main__:üìå Layer 11: silencing 58 neurons\n",
      "/Users/kikay/Documents/investigacion/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kikay/Documents/investigacion/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kikay/Documents/investigacion/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kikay/Documents/investigacion/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kikay/Documents/investigacion/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kikay/Documents/investigacion/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "INFO:__main__:üéØ Accuracy after silencing: 0.0167\n",
      "INFO:__main__:üìè Weighted F1 Score: 0.0256\n",
      "INFO:__main__:üìã Classification report saved to data/goemotions/classification_report_global_silencing.csv\n",
      "INFO:__main__:‚úÖ All hooks removed after evaluation\n"
     ]
    }
   ],
   "source": [
    "# percentages = [0.025, 0.05, 0.075, 0.10, 0.125, 0.15, 0.175, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.65, 0.75, 0.8, 0.95]\n",
    "percentages = [0.025]\n",
    "\n",
    "for pct in percentages:\n",
    "    silence_top_global_percentage_and_evaluate(\n",
    "        model=model_goem,                    # o tu variable del modelo cargado\n",
    "        sample_df=sample_df,\n",
    "        labels_list=labels_list,\n",
    "        probe=probe,\n",
    "        label2idx=label2idx,\n",
    "        percentage=pct,\n",
    "        experiment_title=f\"Silencing {pct*100:.1f}% Global Neurons\",\n",
    "        report_path=CSV_REPORT_GOBAL_SILENCING\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598ece4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# üßê Ver las primeras filas\n",
    "print(sample_df.head())\n",
    "\n",
    "# üîç Ver los tipos de cada columna\n",
    "print(sample_df.dtypes)\n",
    "\n",
    "# üß™ Ver si hay valores nulos\n",
    "print(sample_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f208db",
   "metadata": {},
   "source": [
    "# Diagnostico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34e234e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica dimensiones del probe\n",
    "print(\"üîç probe.linear.weight shape:\", probe.linear.weight.shape)\n",
    "\n",
    "# Deber√≠a dar (num_classes, total_neurons) ‚Üí en tu caso: (6, 9216)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d108b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "hidden_dim = model_goem.config.hidden_size\n",
    "num_layers = model_goem.config.num_hidden_layers\n",
    "total_neurons = hidden_dim * num_layers\n",
    "\n",
    "top_neurons_global = get_top_k_neurons_exact(probe, percentage=0.025)\n",
    "print(\"üéØ Total silenced neurons:\", len(top_neurons_global))\n",
    "print(\"üìä Sample neuron indices:\", top_neurons_global[:10])\n",
    "print(\"üìâ Min index:\", min(top_neurons_global), \"| Max index:\", max(top_neurons_global))\n",
    "\n",
    "# Mapeo por capa\n",
    "layer_counts = defaultdict(int)\n",
    "for idx in top_neurons_global:\n",
    "    layer = idx // hidden_dim\n",
    "    layer_counts[layer] += 1\n",
    "\n",
    "print(\"\\nüìö Neurons per layer (Top 2.5%)\")\n",
    "for layer in sorted(layer_counts):\n",
    "    print(f\"  Layer {layer}: {layer_counts[layer]} neurons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30afd2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üß∑ label2idx:\", label2idx)\n",
    "\n",
    "# Crea tensor con las IDs originales (de GoEmotions)\n",
    "target_goemotion_ids = torch.tensor(list(label2idx.keys()))\n",
    "print(\"üéØ target_goemotion_ids:\", target_goemotion_ids.tolist())\n",
    "\n",
    "# Confirma si las posiciones corresponden 1:1 con etiquetas de `labels_list` que t√∫ usas\n",
    "print(\"üß™ Sample labels_list:\", labels_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea339942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usa solo 1 ejemplo\n",
    "i = 0\n",
    "\n",
    "# Sin silenciamiento todav√≠a\n",
    "input_ids_tensor = torch.tensor(sample_df.loc[i, 'input_ids']).unsqueeze(0).to(model_goem.device)\n",
    "attention_mask_tensor = torch.tensor(sample_df.loc[i, 'attention_mask']).unsqueeze(0).to(model_goem.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model_goem(input_ids=input_ids_tensor, attention_mask=attention_mask_tensor)\n",
    "    logits = outputs.logits\n",
    "    selected_logits = logits[:, target_goemotion_ids]  # [1, 6]\n",
    "    pred_local = torch.argmax(selected_logits, dim=1).item()\n",
    "\n",
    "print(\"üî¢ Full logits:\", logits.tolist())\n",
    "print(\"üéØ Selected logits (target emotions):\", selected_logits.tolist())\n",
    "print(\"‚úÖ Predicted class index (0‚Äì5):\", pred_local)\n",
    "print(\"üè∑Ô∏è True label:\", labels_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a8be7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ö†Ô∏è Hook solo para capa 11 (donde vimos que hay muchas neuronas silenciadas)\n",
    "\n",
    "\n",
    "encoder_layers = get_encoder_layers(model_goem)\n",
    "hook_handles = []\n",
    "\n",
    "for i in range(num_layers):\n",
    "    indices_layer = [idx - i * hidden_dim for idx in top_neurons_global if i * hidden_dim <= idx < (i + 1) * hidden_dim]\n",
    "    if indices_layer:\n",
    "        handle = encoder_layers[i].output.register_forward_hook(make_cls_silence_hook2(indices_layer))\n",
    "        hook_handles.append(handle)\n",
    "\n",
    "# Misma inferencia que antes\n",
    "with torch.no_grad():\n",
    "    outputs = model_goem(input_ids=input_ids_tensor, attention_mask=attention_mask_tensor)\n",
    "    logits = outputs.logits\n",
    "    selected_logits = logits[:, target_goemotion_ids]\n",
    "    pred_local = torch.argmax(selected_logits, dim=1).item()\n",
    "\n",
    "print(\"üß™ Silenced logits:\", selected_logits.tolist())\n",
    "print(\"üéØ New prediction:\", pred_local)\n",
    "\n",
    "# Limpiar hooks\n",
    "for h in hook_handles:\n",
    "    h.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d019d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecuta una sola inferencia para ver qu√© capa da output y qu√© se usa como input al classifier\n",
    "with torch.no_grad():\n",
    "    outputs = model_goem(input_ids=input_ids_tensor, attention_mask=attention_mask_tensor, output_hidden_states=True)\n",
    "    hidden_states = outputs.hidden_states  # Tuple: (layer_0, ..., layer_n)\n",
    "    final_hidden = hidden_states[-1]  # shape: [1, seq_len, hidden_size]\n",
    "\n",
    "    print(\"üß† Final hidden state shape:\", final_hidden.shape)\n",
    "    print(\"üîç CLS vector (posici√≥n 0):\", final_hidden[:, 0, :].abs().sum().item())\n",
    "\n",
    "    logits = model_goem.classifier(final_hidden[:, 0, :])  # ¬øas√≠ lo hace el modelo?\n",
    "    print(\"üéØ Recomputed logits from CLS:\", logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5219f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel\n",
    "import logging\n",
    "\n",
    "# Suponemos que ya tienes estas variables cargadas:\n",
    "# model_goem, input_ids_tensor, attention_mask_tensor, top_neurons_global, make_cls_silence_hook2, get_encoder_layers\n",
    "\n",
    "# Configura el logger\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Accede a capas internas\n",
    "hidden_dim = model_goem.config.hidden_size\n",
    "num_layers = model_goem.config.num_hidden_layers\n",
    "encoder_layers = get_encoder_layers(model_goem)\n",
    "\n",
    "# --- 1. Inference sin silenciar (sin hook) ---\n",
    "with torch.no_grad():\n",
    "    outputs_original = model_goem(\n",
    "        input_ids=input_ids_tensor,\n",
    "        attention_mask=attention_mask_tensor,\n",
    "        output_hidden_states=True\n",
    "    )\n",
    "    hidden_states_original = outputs_original.hidden_states[-1][:, 0, :]  # [CLS] final layer\n",
    "\n",
    "# --- 2. Aplicar hooks para silenciar ---\n",
    "hook_handles = []\n",
    "for i in range(num_layers):\n",
    "    indices_layer = [idx - i * hidden_dim for idx in top_neurons_global if i * hidden_dim <= idx < (i + 1) * hidden_dim]\n",
    "    if indices_layer:\n",
    "        handle = encoder_layers[i].output.register_forward_hook(make_cls_silence_hook2(indices_layer))\n",
    "        hook_handles.append(handle)\n",
    "\n",
    "# --- 3. Inference con neuronas silenciadas ---\n",
    "with torch.no_grad():\n",
    "    outputs_silenced = model_goem(\n",
    "        input_ids=input_ids_tensor,\n",
    "        attention_mask=attention_mask_tensor,\n",
    "        output_hidden_states=True\n",
    "    )\n",
    "    hidden_states_silenced = outputs_silenced.hidden_states[-1][:, 0, :]  # [CLS] silenciado\n",
    "\n",
    "# --- 4. Comparar los vectores CLS ---\n",
    "diff = torch.abs(hidden_states_original - hidden_states_silenced)\n",
    "logger.info(f\"üîç CLS difference after silencing: mean={diff.mean()}, max={diff.max()}\")\n",
    "\n",
    "# Limpieza: eliminar hooks\n",
    "for handle in hook_handles:\n",
    "    handle.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758539a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(get_encoder_layers(model_goem)):\n",
    "    print(f\"Layer {i} -> {layer.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b601b4b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
