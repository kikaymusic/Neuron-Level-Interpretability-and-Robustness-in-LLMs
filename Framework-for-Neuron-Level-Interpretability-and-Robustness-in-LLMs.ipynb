{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6592af2-0359-415a-9624-d5b3e3768e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class F1Tracker:\n",
    "    def __init__(self, experiment_name, save_csv=True, csv_path=\"f1_results.csv\"):\n",
    "        self.experiment_name = experiment_name\n",
    "        self.percent_silenced = []\n",
    "        self.f1_scores = []\n",
    "        self.save_csv = save_csv\n",
    "        self.csv_path = csv_path\n",
    "        if self.save_csv:\n",
    "            with open(self.csv_path, mode='w', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow([\"experiment\", \"percent_silenced\", \"f1_score\"])\n",
    "\n",
    "    def add(self, percent, f1_score):\n",
    "        self.percent_silenced.append(percent)\n",
    "        self.f1_scores.append(f1_score)\n",
    "        if self.save_csv:\n",
    "            with open(self.csv_path, mode='a', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow([self.experiment_name, percent, f1_score])\n",
    "\n",
    "    def plot(self, show=True, save_path=None):\n",
    "        plt.plot(self.percent_silenced, self.f1_scores, marker='o')\n",
    "        plt.title(f\"F1-score - {self.experiment_name}\")\n",
    "        plt.xlabel(\"% Neuronas Silenciadas\")\n",
    "        plt.ylabel(\"F1-score\")\n",
    "        plt.ylim(0, 1)\n",
    "        plt.grid(True)\n",
    "        if save_path:\n",
    "            plt.savefig(save_path, bbox_inches='tight')\n",
    "        if show:\n",
    "            plt.show()\n",
    "        plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b95ddde-9331-4825-abeb-7d82472f93e6",
   "metadata": {},
   "source": [
    "# Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7b992ac-9b02-4d2e-8db1-aa133bfd0345",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import json\n",
    "import logging\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from transformers import AutoTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import neurox.data.extraction.transformers_extractor as transformers_extractor\n",
    "from neurox.data.writer import ActivationsWriter\n",
    "import neurox.data.loader as data_loader\n",
    "from transformers import AutoConfig\n",
    "from tqdm import tqdm\n",
    "import neurox.interpretation.linear_probe as linear_probe\n",
    "import neurox.interpretation.utils as utils\n",
    "import neurox.analysis.visualization as TransformersVisualizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import display\n",
    "import neurox.interpretation.probeless as probeless\n",
    "from neurox.interpretation.probeless import (\n",
    "    get_neuron_ordering,\n",
    "    get_neuron_ordering_for_all_tags\n",
    ")\n",
    "import ast\n",
    "from torch.cuda.amp import autocast\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from matplotlib_venn import venn2\n",
    "from neurox.interpretation.linear_probe import get_top_neurons\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "146875e6-a0bb-4f13-8ef4-14e4017c9de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-07 11:21:30,298 - INFO - üöÄ Logging configured\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "# ==========================\n",
    "# üìú Configure Logging \n",
    "# ==========================\n",
    "\n",
    "logger = logging.getLogger(\"synapse_logger\")\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Avoid duplicates\n",
    "if not logger.hasHandlers():\n",
    "\n",
    "    # üìÅ Handler \n",
    "    file_handler = logging.FileHandler(\"logs/synapse_extraction_csv_pth.log\", mode=\"w\")\n",
    "    file_handler.setLevel(logging.INFO)\n",
    "\n",
    "    # üñ•Ô∏è Handler \n",
    "    console_handler = logging.StreamHandler()\n",
    "    console_handler.setLevel(logging.INFO)\n",
    "\n",
    "    # Format\n",
    "    formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "    file_handler.setFormatter(formatter)\n",
    "    console_handler.setFormatter(formatter)\n",
    "\n",
    "    # Add handlers to main logger\n",
    "    logger.addHandler(file_handler)\n",
    "    logger.addHandler(console_handler)\n",
    "\n",
    "logger.info(\"üöÄ Logging configured\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8d46986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# SYNAPSE Model Configuration\n",
    "# ==========================\n",
    "\n",
    "# üß† Select the model (options: \"BERT\", \"BigBird\", \"DistilBERT\", \"Longformer\")\n",
    "MODEL = \"BigBird\"\n",
    "\n",
    "# üìÅ Paths based on model name\n",
    "BASE_PATH = f\"data/{MODEL}\"\n",
    "input_csv = f\"{BASE_PATH}/{MODEL}_tokens_PT.csv\"\n",
    "output_csv = f\"{BASE_PATH}/reduced/{MODEL}_tokens_reduced.csv\"\n",
    "labels_output_path = f\"{BASE_PATH}/labels_numeric.txt\"\n",
    "label_mapping_path = f\"{BASE_PATH}/labels_mapping.json\"\n",
    "activations_file = f\"{BASE_PATH}/activations.json\"\n",
    "weights_path = f\"{BASE_PATH}/best_model_{MODEL}.pth\"\n",
    "\n",
    "# üî¢ Number of labels\n",
    "NUM_LABELS = 5\n",
    "\n",
    "\n",
    "# üîß HuggingFace model mapping\n",
    "MODEL_HF = {\n",
    "    \"BERT\": \"bert-base-uncased\",\n",
    "    \"BigBird\": \"google/bigbird-roberta-base\",\n",
    "    \"DistilBERT\": \"distilbert-base-uncased\",\n",
    "    \"Longformer\": \"allenai/longformer-base-4096\"\n",
    "}[MODEL]\n",
    "\n",
    "# ‚öôÔ∏è Device selection\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7aa70ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded BigBird with pretrained weights on cpu\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# Load Model and Weights\n",
    "# ==========================\n",
    "from transformers import AutoConfig\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_HF, num_labels=NUM_LABELS)\n",
    "\n",
    "# Load trained weights from disk\n",
    "state_dict = torch.load(weights_path, map_location=device)\n",
    "model.load_state_dict(state_dict)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"‚úÖ Loaded {MODEL} with pretrained weights on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bb9cff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d374908b-8bfa-4ea8-8ea5-0606a7beb8f4",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "603211a2-0c14-4ede-b934-e232421f3d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-07 11:21:32,045 - INFO - ‚ö° Reduced dataset found: data/BigBird/reduced/BigBird_tokens_reduced.csv. Skipping reduction.\n"
     ]
    }
   ],
   "source": [
    "reduction_ratio = 0.001\n",
    "\n",
    "# ==========================\n",
    "# ‚úÖ Skip dataset reduction if already available\n",
    "# ==========================\n",
    "if os.path.exists(output_csv) and os.path.exists(labels_output_path):\n",
    "    logger.info(f\"‚ö° Reduced dataset found: {output_csv}. Skipping reduction.\")\n",
    "    df_reduced = pd.read_csv(output_csv)\n",
    "    with open(labels_output_path, \"r\") as f:\n",
    "        labels = [int(line.strip()) for line in f]  # Labels as integers\n",
    "    with open(label_mapping_path, \"r\") as f:\n",
    "        label_mapping = json.load(f)  # Load label mapping\n",
    "else:\n",
    "    logger.info(f\"üîÑ Loading dataset from {input_csv}\")\n",
    "\n",
    "    chunk_size = 5000 \n",
    "    total_rows = sum(1 for _ in open(input_csv)) - 1  # Total rows excluding header\n",
    "    df_chunks = []\n",
    "\n",
    "    logger.info(f\"üîÑ Processing {total_rows} rows in chunks of {chunk_size}...\")\n",
    "\n",
    "    with tqdm(total=total_rows, desc=\"Processing rows\", unit=\" rows\") as pbar:\n",
    "        for chunk in pd.read_csv(input_csv, chunksize=chunk_size):\n",
    "            # Convert `input_ids` from string to list of integers\n",
    "            chunk['input_ids'] = chunk['input_ids'].apply(lambda x: list(map(int, x.strip(\"[]\").split(\",\"))))\n",
    "            df_chunks.append(chunk)\n",
    "            pbar.update(len(chunk))\n",
    "\n",
    "    df = pd.concat(df_chunks, ignore_index=True)\n",
    "\n",
    "    # ==========================\n",
    "    # üî¢ Encode labels as integers\n",
    "    # ==========================\n",
    "    df['label'], unique_labels = pd.factorize(df[\"label\"])\n",
    "    label_mapping = {label: int(idx) for idx, label in enumerate(unique_labels)}\n",
    "\n",
    "    # ==========================\n",
    "    # üß™ Reduce dataset maintaining class proportions\n",
    "    # ==========================\n",
    "    df_reduced, _ = train_test_split(df, train_size=reduction_ratio, stratify=df[\"label\"], random_state=42)\n",
    "    labels = df_reduced[\"label\"].tolist()\n",
    "\n",
    "    # ==========================\n",
    "    # üíæ Save reduced dataset and labels\n",
    "    # ==========================\n",
    "    df_reduced.to_csv(output_csv, index=False)\n",
    "    with open(labels_output_path, \"w\") as f:\n",
    "        for label in labels:\n",
    "            f.write(str(label) + \"\\n\")\n",
    "\n",
    "    with open(label_mapping_path, \"w\") as f:\n",
    "        json.dump(label_mapping, f, indent=4)\n",
    "\n",
    "    logger.info(f\"‚úÖ Reduced dataset saved to {output_csv}\")\n",
    "    logger.info(f\"‚úÖ Numeric labels saved to {labels_output_path}\")\n",
    "    logger.info(f\"‚úÖ Label mapping saved to {label_mapping_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997a332b-cc98-4354-b752-ad1134ad730c",
   "metadata": {},
   "source": [
    "### Create Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "495d4540-bc59-4807-b0af-8ffbd01daae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-07 11:21:32,060 - INFO - ‚úÖ Dataloader created\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# üì¶ Create DataLoader\n",
    "# ==========================\n",
    "class SyscallDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.data = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ids = torch.tensor(self.data.iloc[idx]['input_ids'])\n",
    "        label = torch.tensor(self.data.iloc[idx]['label'])\n",
    "        return input_ids, label\n",
    "\n",
    "# Initialize DataLoader with reduced dataset\n",
    "dataset = SyscallDataset(df_reduced)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "logger.info(\"‚úÖ Dataloader created\")\n",
    "\n",
    "# Ensure `input_ids` are lists of integers\n",
    "if isinstance(df_reduced[\"input_ids\"].iloc[0], str):\n",
    "    df_reduced[\"input_ids\"] = df_reduced[\"input_ids\"].apply(lambda x: list(map(int, x.strip(\"[]\").split(\",\"))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0da9ae4-251e-4f65-b65f-9663fc90f02c",
   "metadata": {},
   "source": [
    "# NeuroX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a112e7-860d-47fd-9d6d-eab42bc5be5f",
   "metadata": {},
   "source": [
    "## Activation Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08e2b162-ca24-4599-a29d-879d176fddf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-07 11:21:32,077 - INFO - ‚ö° Activations file found: data/BigBird/activations.json. Skipping extraction.\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(activations_file):\n",
    "    logger.info(f\"‚ö° Activations file found: {activations_file}. Skipping extraction.\")\n",
    "else:\n",
    "    transformers_extractor.extract_representations(\n",
    "        model, \n",
    "        df_reduced[\"input_ids\"].tolist(),  # Pass preprocessed tokens directly\n",
    "        activations_file,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    logger.info(f\"‚úÖ Activations saved to {activations_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf78272a-01de-43f0-a26d-9d93367256f2",
   "metadata": {},
   "source": [
    "## Load Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b34f817a-3592-4a9d-9b38-f9f18ed497b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-07 11:21:32,116 - INFO - ‚úÖ Loaded activations from data/BigBird/activations.json with 12 layers\n",
      "2025-08-07 11:21:32,125 - INFO - ‚úÖ Created input/output tensors and label mappings for classification\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading json activations from data/BigBird/activations.json...\n",
      "50 12.0\n",
      "Number of tokens:  50\n",
      "length of source dictionary:  17\n",
      "length of target dictionary:  5\n",
      "50\n",
      "Total instances: 50\n",
      "['s']\n",
      "Number of samples:  50\n",
      "Stats: Labels with their frequencies in the final set\n",
      "4 9\n",
      "3 15\n",
      "2 9\n",
      "1 10\n",
      "0 7\n"
     ]
    }
   ],
   "source": [
    "activations, num_layers = data_loader.load_activations(activations_file)\n",
    "logger.info(f\"‚úÖ Loaded activations from {activations_file} with {num_layers} layers\")\n",
    "\n",
    "# Load sentence-level classification data using activations\n",
    "tokens = data_loader.load_sentence_data(\n",
    "    output_csv, labels_output_path, activations\n",
    ")\n",
    "\n",
    "# Create sentence-level tensors for classification\n",
    "X, y, mapping = utils.create_tensors(\n",
    "    tokens,\n",
    "    activations,\n",
    "    task_specific_tag=\"NN\",\n",
    "    task_type=\"classification\"\n",
    ")\n",
    "\n",
    "label2idx, idx2label, src2idx, idx2src = mapping\n",
    "logger.info(\"‚úÖ Created input/output tensors and label mappings for classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cafa0a1-baf1-4926-a84a-bba21b52226b",
   "metadata": {},
   "source": [
    "## Train linear probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bea62171-4a9b-4c24-8ff5-7908550291da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases en y_train: [0 1 2 3 4]\n",
      "Training classification probe\n",
      "Creating model...\n",
      "Number of training instances: 50\n",
      "Number of classes: 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23da4bb5ee1b43d9aabde65817bba206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch [1/10]: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/10], Loss: 0.0752\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e598a58bea9487a82399f51dbd510bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch [2/10]: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2/10], Loss: 0.0397\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ab11d0638a94fbca5547feba62b70a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch [3/10]: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3/10], Loss: 0.0254\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ded2725a15b4151ab836d829b523235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch [4/10]: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4/10], Loss: 0.0223\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b4b9e5bcbae4d48ab32991eea123e76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch [5/10]: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5/10], Loss: 0.0199\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "591d2269becb49159ce0eb082bd5a322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch [6/10]: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6/10], Loss: 0.0174\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e17707765abb4336852de79d347ff9c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch [7/10]: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7/10], Loss: 0.0160\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ca9c0959e62447eb4865ffb873bcc96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch [8/10]: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8/10], Loss: 0.0152\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a013bf5a84642e19a18a209b71952e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch [9/10]: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9/10], Loss: 0.0145\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09ce137e35294072bece21b5589fb7af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch [10/10]: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10/10], Loss: 0.0140\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae47d868354d483b9ec7e9b11ccdfa9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-07 11:21:32,277 - INFO - üéØ Probe evaluation results: {'__OVERALL__': np.float64(0.96), '4': np.float64(1.0), '3': np.float64(1.0), '2': np.float64(0.7777777777777778), '1': np.float64(1.0), '0': np.float64(1.0)}\n",
      "2025-08-07 11:21:32,281 - INFO - üîç Top global neurons: [8193 8194 8196 ... 8189 8190 8191]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (accuracy) of the probe: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-07 11:21:32,283 - INFO - üîç Top neurons per class: {'4': array([8457, 9014, 8769, 8833, 8987, 8723, 9181, 8488, 8980, 8398, 7879,\n",
      "       8869, 8952, 8485, 7898, 9147, 8925, 9171, 8722, 8711, 8853, 8634,\n",
      "       8712, 8544, 9063, 8572, 8956, 8293, 8662, 8507, 8738, 9207, 8583,\n",
      "       9052, 9008, 8127, 7779, 8984, 7764, 8534, 9127, 8316, 8931, 8495,\n",
      "       8873, 7688, 8482, 5548, 8797, 9027, 7849, 8721, 7715, 8319, 8923,\n",
      "       8700, 8865, 8638, 8074, 9060, 7753, 8157, 7857, 7836, 8866, 8415,\n",
      "       6026, 8884, 8989, 9043, 8056, 8872, 8034, 7797, 7933, 8020, 8681,\n",
      "       8689, 8724, 6614, 7866, 7686, 8163, 8480, 7815, 9164, 5824, 8851,\n",
      "       8971, 9007, 7865, 7950, 8941, 7791, 8655, 8234, 8576, 8196, 9062,\n",
      "       8255, 8095, 8454, 8736, 5592, 5507, 8798, 7250, 8395, 9152, 8926,\n",
      "       8285, 8617, 1866, 8958, 8637, 8967, 8666, 7901, 8369, 5551, 7734,\n",
      "       8011, 4724, 9073, 8938, 9083, 5902, 4109, 7825, 7223, 8696, 8096,\n",
      "       9005, 8750, 8459, 8543, 5601, 6534, 4675, 8694, 8164, 5938, 8763,\n",
      "       7685, 7763, 9089, 8490, 8396, 7958, 8620, 8720, 8445, 8742, 8336,\n",
      "       8868, 9174, 8713, 6442, 8859, 9208, 5791, 8757, 9067, 8991, 9061,\n",
      "       6510, 5654, 8557, 8508, 8889, 7928, 6581, 8130, 6990, 6028, 8651,\n",
      "       8431, 7693, 8308, 9053, 7643, 8691, 5834, 9140, 8777, 6250, 8204,\n",
      "       6258, 8671, 8451, 8517, 9195, 6724, 9029, 6429, 7877, 8030, 6645,\n",
      "       9066, 8087, 7869, 8731, 8824, 8183, 8966, 5023, 8259, 4652, 9046,\n",
      "       8877, 8179, 7886, 8289, 8581, 7628, 7824, 9205, 6389, 8890, 8855,\n",
      "       8648, 6967, 8505]), '3': array([5978, 6106, 5756, 5506, 9004, 9110, 5784, 8957, 6005, 8546, 5832,\n",
      "       8935, 8598, 9087, 8552, 4799, 8811, 5621, 8132, 8891, 8709, 5549,\n",
      "       8489, 8798, 8609, 5542, 8805, 9142, 8776, 9143, 9002, 8211, 8691,\n",
      "       9150, 8593, 5000, 5876, 3057, 6542, 8388, 8448, 5323, 9035, 6008,\n",
      "       8522, 8487, 6552, 7776, 7957, 7452, 8927, 6387, 8521, 8679, 8591,\n",
      "       9057, 3226, 8839, 8258, 8429, 8804, 5804, 7561, 6274, 8230, 8579,\n",
      "       8588, 8193, 6260, 8946, 9167, 9199, 9132, 8432, 8525, 8775, 8768,\n",
      "       9141, 8865, 5390, 5486, 7340, 8672, 9098, 8253, 6398, 6599, 8859,\n",
      "       4125, 7399, 8582, 7922, 8636, 8963, 8902, 5687, 5783, 8574, 9066,\n",
      "       3984, 6185, 9197, 3708, 8953, 4145, 7703, 8071, 5237, 7864, 7942,\n",
      "       7958, 8802, 8915, 8654, 5310, 9029, 8856, 8812, 9046, 5892, 9181,\n",
      "       8667, 8408, 8584, 8883, 6319, 8302, 5136, 7875, 8291, 8612, 8664,\n",
      "       5207, 8096, 5255, 8774, 8675, 8277, 8563, 9033, 7941, 8864, 8615,\n",
      "       4558, 4439, 5111, 8975, 8025, 7747, 8638, 5314, 5154, 3932, 9006,\n",
      "       5016, 9165, 9085, 5904, 8496, 7755, 9000, 8817, 5935, 8735, 8947,\n",
      "       8386, 3482, 9013, 6826, 5809, 4698, 8955, 7762, 7690, 7691, 5681,\n",
      "       4965, 7659, 8958, 8646, 8671, 8871, 9107, 8319, 5975, 8509, 4724,\n",
      "       8249, 8851, 5688, 5170, 8706, 8035, 9189, 8987, 6418, 8560, 8534,\n",
      "       5800, 3530, 3936, 8637, 5584, 8566, 8396, 3629, 5592, 7944, 8589,\n",
      "       2131, 8629, 9089, 6381, 6251, 8466, 8630, 6455, 7971, 9055, 8849,\n",
      "       8366, 5399, 8531, 8866, 8387, 8889, 8640, 6987, 7982, 8267, 5618,\n",
      "       8310, 7873, 8237, 8186, 6470, 3256]), '2': array([8516, 8903, 6511, 7528, 7061, 4572, 8866, 8486, 8787, 8455, 9189,\n",
      "       7286, 8932, 9056, 9071, 9097, 8991, 4415, 8720, 6700, 7010, 9203,\n",
      "       8507, 8618, 9124, 8500, 7896, 5503, 9173, 8498, 4586, 9031, 8844,\n",
      "       8857, 8279, 8468, 8466, 8893, 8637, 7941, 4308, 9049, 8565, 5945,\n",
      "       7746, 8585, 9186, 2928, 8558, 8334, 8591, 8013, 6022, 7769, 8938,\n",
      "       7730, 8936, 8371, 7808, 8721, 6404, 9054, 8019, 8639, 8963, 7583,\n",
      "       5255, 3600, 2808, 8966, 8189, 7724, 8798, 8339, 8737, 5307, 9144,\n",
      "       3663, 3087, 5034, 8475, 7695, 8868, 9179, 6619, 7685, 7702, 7732,\n",
      "       6987, 7963, 5743, 5387, 8725, 8254, 2304, 8512, 9024, 3273, 3121,\n",
      "       9201, 7782, 8660, 8790, 8645, 8976, 6610, 8727, 8178, 8561, 8232,\n",
      "       8827, 3139, 8764, 8515, 2326, 7791, 7686, 2850, 6945, 9147, 8451,\n",
      "       3487, 6303, 2370, 4446, 8988, 8595, 8969, 9087, 4125, 4747, 5688,\n",
      "       8885, 8295, 6756, 8520, 8611, 2649, 9070, 8952, 7819, 8407, 8990,\n",
      "       7822, 8673, 8907, 8588, 8574, 7167, 8994, 2620, 2951, 7397, 8604,\n",
      "       8570, 8909, 9112, 7726, 8145, 8955, 9089, 8289, 9065, 8854, 9156,\n",
      "       2551, 8082, 4797, 8001, 2447, 8191, 7558, 6560, 8547, 8472, 8799,\n",
      "       8053, 8707, 8953, 8911, 6479, 5969, 7718, 8900, 2916, 8326, 4437,\n",
      "       3362, 9107, 8576, 8304, 7946, 2553, 8839, 7403, 2924, 7074, 6576,\n",
      "       9132, 8919, 9040, 3109, 4726, 8063, 4028, 4599, 6615, 8508, 8843,\n",
      "       7771, 5920, 2336, 4397, 7576, 7051, 8216, 8822, 8925, 8234, 9146,\n",
      "       8504, 3627, 4566, 8962, 9187, 7920, 6607, 6047, 2413, 8971, 3999,\n",
      "       6904, 7303, 4784, 7693, 7833, 5667, 8677, 8886, 2772, 8011, 7760,\n",
      "       8889, 8025, 7531, 8923, 5709]), '1': array([8937, 9076, 8480, 8808, 8596, 7692, 8184, 7499, 9038, 8049, 8790,\n",
      "       8652, 8844, 9130, 7818, 8992, 8169, 8027, 7963, 8699, 6164, 8913,\n",
      "       8562, 3509, 4633, 7800, 9116, 9068, 8938, 8774, 8343, 6853, 6065,\n",
      "       8635, 4744, 6632, 8404, 8450, 8780, 8420, 6879, 7626, 7790, 8930,\n",
      "       6332, 7815, 4353, 7681, 9131, 7558, 8434, 7735, 8121, 4682, 8096,\n",
      "       7111, 7557, 7787, 8214, 7350, 6390, 9208, 5870, 8864, 8443, 8102,\n",
      "       7488, 9114, 9129, 6511, 9112, 6138, 9167, 6583, 8492, 6898, 5395,\n",
      "       8918, 8736, 8861, 8666, 9088, 5452, 4154, 7144, 8363, 7146, 6393,\n",
      "       8625, 8560, 6663, 9156, 7332, 8718, 8859, 7372, 7878, 6437, 8607,\n",
      "       7934, 6953, 6878, 7944, 7476, 8061, 4583, 5907, 6979, 9104, 8537,\n",
      "       8116, 7853, 8798, 9021, 7696, 8709, 8375, 7095, 4994, 9164, 8440,\n",
      "       7763, 7902, 5629, 7370, 8908, 4174, 7327, 8680, 8640, 9069, 5785,\n",
      "       6635, 4813, 6176, 6295, 7352, 6944, 9198, 6455, 4689, 8978, 7982,\n",
      "       8118, 8543, 8582, 8592, 4250, 8322, 6916, 8332, 7729, 8347, 8649,\n",
      "       4731, 8712, 6731, 5140, 8373, 2889, 7021, 8884, 5879, 9121, 8034,\n",
      "       8923, 8974, 6234, 3978, 5857, 8323, 8769, 4277, 6712, 8796, 8191,\n",
      "       8771, 8828, 9047, 5322, 9204, 8312, 7872, 8823, 4951, 5345, 5277,\n",
      "       7799, 8935, 8077, 8738, 4754, 7915, 6403, 7974, 3707, 8755, 7437,\n",
      "       4366, 7414, 9159, 7492, 5068, 6673, 6499, 8873, 8556, 7726, 8432,\n",
      "       6240, 8964, 6451, 9170, 7315, 7052, 8476, 5638, 5164, 9108, 8975,\n",
      "       8804, 6025, 8722, 6604, 8902, 7377, 8759, 7837, 7425, 8979, 6419,\n",
      "       9111, 5920, 8982, 9145, 7118, 8909, 6639, 4329, 7393, 7666]), '0': array([8006, 8708, 8510, 8517, 9102, 8520, 8518, 8094, 7839, 7726, 8535,\n",
      "       9097, 8629, 8616, 6079, 8892, 6581, 8056, 9194, 9117, 8973, 8856,\n",
      "       2450, 6645, 4853, 9168, 5769, 7317, 7821, 8902, 8645, 8873, 7841,\n",
      "       8405, 8709, 8547, 3509, 6223, 8453, 8666, 8644, 9075, 8729, 9187,\n",
      "       8783, 7783, 8191, 8985, 9171, 8961, 8665, 8816, 5383, 5725, 9141,\n",
      "       9016, 8941, 7689, 8045, 9149, 6413, 8064, 7755, 8790, 6268, 7166,\n",
      "       8601, 8305, 8603, 8257, 8949, 8936, 7896, 1941, 2030, 7676, 9088,\n",
      "       7461, 5549, 9199, 9201, 7286, 8919, 2154, 8534, 7779, 9028, 8487,\n",
      "       8194, 8830, 8907, 7107, 7519, 8190, 8933, 8345, 5088, 1903, 8993,\n",
      "       8761, 7737, 6068, 9077, 2131, 8459, 8552, 5822, 6272, 7101, 8048,\n",
      "       2769, 3487, 5701, 8326, 9135, 8166, 7923, 6614, 8539, 8852, 9050,\n",
      "       8743, 4501, 6500, 8388, 8730, 8515, 7445, 7873, 8602, 4082, 7761,\n",
      "       9108, 8477, 8621, 6606, 8726, 7465, 8889, 6434, 8447, 8573, 9139,\n",
      "       8255, 9159, 8295, 8029, 8622, 8020, 9214, 7970, 5167, 9191, 8470,\n",
      "       8737, 9045, 7920, 8478, 9067, 8031, 8782, 3967, 9099, 6387, 8820,\n",
      "       9152, 8951, 8978, 9206, 9063, 5832, 8193, 8330, 7869,  297, 1928,\n",
      "       7967, 1765, 7906, 5531, 8787, 8302, 8822, 8237, 8516, 7167, 8824,\n",
      "       7977, 8125, 9070, 6919, 7302, 8842, 3990, 6600, 6687, 8863, 9116,\n",
      "       9205, 8316, 8772, 8991, 7123, 9019, 2688, 5472, 8614, 7973, 7926,\n",
      "       9096, 7637, 3109, 9022, 5985, 8721, 8853, 7023, 8543, 2190, 9023,\n",
      "       8626, 9105, 5753, 7986, 8512, 7959, 2822, 7889, 6854, 5674, 5916,\n",
      "       8227,  518, 9026, 5108, 8953, 8862, 8887, 6478, 3028, 7858, 2462,\n",
      "       8604, 8360, 8723, 8334, 8929, 7870, 8894, 4120, 8810, 7879, 2850,\n",
      "       8037])}\n"
     ]
    }
   ],
   "source": [
    "probe = linear_probe.train_logistic_regression_probe(X, y, lambda_l1=0.001, lambda_l2=0.001)\n",
    "scores = linear_probe.evaluate_probe(probe, X, y, idx_to_class=idx2label)\n",
    "logger.info(f\"üéØ Probe evaluation results: {scores}\")\n",
    "\n",
    "top_neurons_probe, per_class_top_neurons = linear_probe.get_top_neurons(probe, percentage=0.1, class_to_idx=label2idx)\n",
    "logger.info(f\"üîç Top global neurons: {top_neurons_probe}\")\n",
    "logger.info(f\"üîç Top neurons per class: {per_class_top_neurons}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caac4eb9-cda2-4050-b2db-d6cf6e2edb91",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f96bd6-4483-4548-aa6d-20944dc73066",
   "metadata": {},
   "source": [
    "## Original performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc1e0d41-7476-4c5e-891a-e0c61b45011b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y4/zbxddgn52lx1dx5ktc7jch6m0000gn/T/ipykernel_13287/2165693082.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/Users/kikay/Documents/investigacion/.venv/lib/python3.9/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "2025-08-07 11:22:54,341 - INFO - üìÅ Appended classification report with title 'üß™ Sample of 30 - Full Model Evaluation' to data/BigBird/classification_report_sample_eval.csv\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(input_csv)\n",
    "\n",
    "# üéØ Select 50 random examples and reset index\n",
    "sample_df = df.sample(n=50, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# üßπ Convert \"input_ids\" and \"attention_mask\" from string to list format\n",
    "def parse_list(x):\n",
    "    return ast.literal_eval(x)\n",
    "\n",
    "sample_df['input_ids'] = sample_df['input_ids'].apply(parse_list)\n",
    "sample_df['attention_mask'] = sample_df['attention_mask'].apply(parse_list)\n",
    "\n",
    "# üî¢ Encode labels to integers\n",
    "label_encoder = LabelEncoder()\n",
    "sample_df['label'] = label_encoder.fit_transform(sample_df['label'])\n",
    "labels_list = sample_df['label'].tolist()\n",
    "\n",
    "predictions_list = []\n",
    "model.eval()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "for i in range(len(sample_df)):\n",
    "    input_ids_tensor = torch.tensor(sample_df.loc[i, 'input_ids']).unsqueeze(0).to(device)\n",
    "    attention_mask_tensor = torch.tensor(sample_df.loc[i, 'attention_mask']).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with autocast():\n",
    "            device = torch.device(\"cpu\")\n",
    "            outputs = model(input_ids=input_ids_tensor, attention_mask=attention_mask_tensor)\n",
    "            logits = outputs['logits']\n",
    "            pred = torch.argmax(logits, dim=1).item()\n",
    "            predictions_list.append(pred)\n",
    "\n",
    "    del input_ids_tensor, attention_mask_tensor, outputs, logits\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# üìä Compute evaluation metrics\n",
    "accuracy = accuracy_score(labels_list, predictions_list)\n",
    "f1 = f1_score(labels_list, predictions_list, average='weighted')\n",
    "report_dict = classification_report(labels_list, predictions_list, output_dict=True)\n",
    "report_df = pd.DataFrame(report_dict).transpose()\n",
    "\n",
    "# Round for readability\n",
    "report_df = report_df.round(4)\n",
    "\n",
    "# Add accuracy as a separate row\n",
    "accuracy_row = pd.DataFrame({'precision': accuracy, 'recall': accuracy, 'f1-score': accuracy, 'support': sum(report_df['support'])}, index=['accuracy'])\n",
    "report_df = pd.concat([report_df, accuracy_row])\n",
    "\n",
    "# üìù Save or append to CSV\n",
    "\n",
    "experiment_title = \"üß™ Sample of 30 - Full Model Evaluation\"\n",
    "csv_report_path = f\"{BASE_PATH}/classification_report_sample_eval.csv\"\n",
    "\n",
    "# Remove incorrect 'accuracy' row if it exists\n",
    "report_df = report_df.drop(\"accuracy\", errors=\"ignore\")\n",
    "\n",
    "# Append correct accuracy row\n",
    "accuracy_row = pd.DataFrame({\n",
    "    'precision': [\"\"],\n",
    "    'recall': [\"\"],\n",
    "    'f1-score': [accuracy],\n",
    "    'support': [sum(report_df[\"support\"])]\n",
    "}, index=[\"overall_accuracy\"])\n",
    "\n",
    "# Combine\n",
    "final_df = pd.concat([report_df, accuracy_row])\n",
    "\n",
    "# Write to CSV with experiment title as a header\n",
    "with open(csv_report_path, \"a\") as f:\n",
    "    f.write(f\"\\n\\n# {experiment_title}\\n\")\n",
    "final_df.to_csv(csv_report_path, mode=\"a\")\n",
    "\n",
    "logger.info(f\"üìÅ Appended classification report with title '{experiment_title}' to {csv_report_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0dea5554",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def quick_baseline_f1(model, sample_df, labels_list):\n",
    "    \"\"\"\n",
    "    Corre inferencia r√°pida y devuelve solo el F1-weighted para el modelo actual.\n",
    "    √ösalo tras cada experimento para comprobar que el baseline no se contamina.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    for row in sample_df.itertuples():\n",
    "        input_ids = torch.tensor(row.input_ids).unsqueeze(0).to(model.device)\n",
    "        att_mask  = torch.tensor(row.attention_mask).unsqueeze(0).to(model.device)\n",
    "        with torch.no_grad():\n",
    "            logits = model(input_ids=input_ids, attention_mask=att_mask).logits\n",
    "        preds.append(int(logits.argmax(dim=-1)))\n",
    "    f1w = f1_score(labels_list, preds, average=\"weighted\", zero_division=0)\n",
    "    logger.info(f\"[Baseline Check] Weighted F1-score: {f1w:.4f}\")\n",
    "    return f1w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8665af26",
   "metadata": {},
   "source": [
    "## Shortcut: reload model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "634a073d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "def load_model(model_hf: str,\n",
    "                     weights_path: str = None,\n",
    "                     num_labels: int = None,\n",
    "                     device: str = None):\n",
    "    # dispositivo\n",
    "    if device is None:\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    device = torch.device(device)\n",
    "\n",
    "    # carga base\n",
    "    kwargs = {}\n",
    "    if num_labels is not None:\n",
    "        kwargs[\"num_labels\"] = num_labels\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_hf, **kwargs)\n",
    "\n",
    "    # aplica checkpoint propio si se pasa\n",
    "    if weights_path:\n",
    "        state_dict = torch.load(weights_path, map_location=device)\n",
    "        # strict=False por si tu state_dict no coincide exactamente (labels, etc.)\n",
    "        model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "model = load_model(MODEL_HF, weights_path=weights_path, num_labels=NUM_LABELS, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62225a32-2fc7-4fdb-ae4b-53a19393aae6",
   "metadata": {},
   "source": [
    "## Silence and evaluate neurons. Function definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4451f9be-7a5e-47b9-b264-e8328c6a13d8",
   "metadata": {},
   "source": [
    "### Full silencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f72508a7-d93f-4b9c-a991-367e87015919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_k_neurons_exact(probe, percentage: float) -> list[int]:\n",
    "    \"\"\"\n",
    "    Return exactly N = round(total_neurons * percentage) neuron indices, sorted by importance.\n",
    "    Importance is measured as the sum of absolute values of weights across all output classes.\n",
    "    \"\"\"\n",
    "    weight_matrix = probe.linear.weight.detach().abs()  # [num_classes, num_neurons]\n",
    "    importance = weight_matrix.sum(dim=0).cpu().numpy()  # [num_neurons]\n",
    "    total_neurons = len(importance)\n",
    "    top_n = round(total_neurons * percentage)\n",
    "\n",
    "    sorted_indices = importance.argsort()[-top_n:]  # Top-N by importance\n",
    "    return sorted_indices.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2971743e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cls_silence_hook(indices):\n",
    "    indices = [int(i) for i in indices]\n",
    "    indices_tensor = torch.tensor(indices, dtype=torch.long) if indices else None\n",
    "\n",
    "    def hook(module, input, output):\n",
    "        if output.dim() == 3:\n",
    "            new_output = output.clone()\n",
    "            cls_token = new_output[:, 0, :]\n",
    "            mask = torch.ones_like(cls_token)\n",
    "            if indices_tensor is not None:\n",
    "                local_indices = indices_tensor.to(new_output.device)\n",
    "                mask[:, local_indices] = 0.0\n",
    "            new_output[:, 0, :] = cls_token * mask\n",
    "            return new_output\n",
    "        return output\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32084878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# Get encoder layers dynamically\n",
    "# ==========================\n",
    "def get_encoder_layers(model):\n",
    "    if hasattr(model, \"bert\"):\n",
    "        return model.bert.encoder.layer\n",
    "    elif hasattr(model, \"longformer\"):\n",
    "        return model.longformer.encoder.layer\n",
    "    elif hasattr(model, \"distilbert\"):\n",
    "        return model.distilbert.transformer.layer\n",
    "    else:\n",
    "        raise NotImplementedError(\"‚ùå Unsupported model architecture.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b0222e8-2b6d-441f-b032-e0d960da0eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def silence_top_global_percentage_and_evaluate(\n",
    "    model,\n",
    "    sample_df,\n",
    "    labels_list,\n",
    "    probe,\n",
    "    label2idx,\n",
    "    percentage=0.10,\n",
    "    report_path=None,\n",
    "    experiment_title=None\n",
    "):\n",
    "    hidden_dim = model.config.hidden_size\n",
    "    num_layers = model.config.num_hidden_layers\n",
    "    total_neurons = num_layers * hidden_dim\n",
    "\n",
    "    top_neurons_global = get_top_k_neurons_exact(probe, percentage=percentage)\n",
    "    logger.info(f\"üîß Silencing exactly {len(top_neurons_global)} neurons ({percentage:.2%} of total {total_neurons})\")\n",
    "\n",
    "    # Save neuron indices\n",
    "    neurons_dir = f\"{BASE_PATH}/neurons\"\n",
    "    os.makedirs(neurons_dir, exist_ok=True)\n",
    "    json_path = f\"{neurons_dir}/top_{int(percentage * 100)}p_neurons_global.json\"\n",
    "    with open(json_path, \"w\") as f:\n",
    "        json.dump(top_neurons_global, f, indent=4)\n",
    "    logger.info(f\"üìÅ Saved neuron indices to {json_path}\")\n",
    "\n",
    "    # Register hooks per layer (compatible with BERT, DistilBERT, etc.)\n",
    "    encoder_layers = get_encoder_layers(model)\n",
    "    hook_handles = []\n",
    "    for i in range(num_layers):\n",
    "        indices_layer = [idx - i * hidden_dim for idx in top_neurons_global if i * hidden_dim <= idx < (i + 1) * hidden_dim]\n",
    "        if indices_layer:\n",
    "            logger.info(f\"üìå Layer {i}: silencing {len(indices_layer)} neurons\")\n",
    "            # Use 'output' submodule if exists (BERT, RoBERTa), else register on main layer (DistilBERT)\n",
    "            if hasattr(encoder_layers[i], \"output\"):\n",
    "                handle = encoder_layers[i].output.register_forward_hook(make_cls_silence_hook(indices_layer))\n",
    "            else:\n",
    "                handle = encoder_layers[i].register_forward_hook(make_cls_silence_hook(indices_layer))\n",
    "            hook_handles.append(handle)\n",
    "\n",
    "    # Inference\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    for i in range(len(sample_df)):\n",
    "        input_ids_tensor = torch.tensor(sample_df.loc[i, 'input_ids']).unsqueeze(0).to(model.device)\n",
    "        attention_mask_tensor = torch.tensor(sample_df.loc[i, 'attention_mask']).unsqueeze(0).to(model.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids_tensor, attention_mask=attention_mask_tensor)\n",
    "            logits = outputs['logits']\n",
    "            pred = torch.argmax(logits, dim=1).item()\n",
    "            predictions.append(pred)\n",
    "\n",
    "        del input_ids_tensor, attention_mask_tensor, outputs, logits\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # Metrics\n",
    "    accuracy = accuracy_score(labels_list, predictions)\n",
    "    f1 = f1_score(labels_list, predictions, average='weighted')\n",
    "    report_dict = classification_report(labels_list, predictions, output_dict=True)\n",
    "    report_df = pd.DataFrame(report_dict).transpose().round(4)\n",
    "    report_df = report_df.drop(\"accuracy\", errors=\"ignore\")\n",
    "\n",
    "    accuracy_row = pd.DataFrame({\n",
    "        'precision': [\"\"],\n",
    "        'recall': [\"\"],\n",
    "        'f1-score': [accuracy],\n",
    "        'support': [sum(report_df[\"support\"])]\n",
    "    }, index=[\"overall_accuracy\"])\n",
    "    final_df = pd.concat([report_df, accuracy_row])\n",
    "\n",
    "    # Save classification report\n",
    "    if report_path is None:\n",
    "        report_path = f\"{BASE_PATH}/results/full_silencing.csv\"\n",
    "    os.makedirs(os.path.dirname(report_path), exist_ok=True)\n",
    "\n",
    "    if experiment_title is None:\n",
    "        experiment_title = f\"Silencing top {percentage:.2%} global neurons\"\n",
    "\n",
    "    if not os.path.exists(report_path):\n",
    "        with open(report_path, \"w\") as f:\n",
    "            f.write(f\"# {experiment_title}\\n\")\n",
    "            final_df.to_csv(f)\n",
    "    else:\n",
    "        with open(report_path, \"a\") as f:\n",
    "            f.write(f\"\\n\\n# {experiment_title}\\n\")\n",
    "        final_df.to_csv(report_path, mode=\"a\")\n",
    "\n",
    "    logger.info(f\"üéØ Accuracy after silencing: {accuracy:.4f}\")\n",
    "    logger.info(f\"üìè Weighted F1 Score: {f1:.4f}\")\n",
    "    logger.info(f\"üìã Classification report saved to {report_path}\")\n",
    "\n",
    "    # Remove all hooks\n",
    "    for handle in hook_handles:\n",
    "        handle.remove()\n",
    "    logger.info(\"‚úÖ All hooks removed after evaluation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cffd66-99e9-487e-a2ea-e039e47daf75",
   "metadata": {},
   "source": [
    "## Global impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b029e16d-7756-4ec6-933d-dbbd0b1a8569",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-07 11:22:54,370 - INFO - üîß Silencing exactly 230 neurons (2.50% of total 9216)\n",
      "2025-08-07 11:22:54,370 - INFO - üìÅ Saved neuron indices to data/BigBird/neurons/top_2p_neurons_global.json\n",
      "2025-08-07 11:22:54,371 - INFO - üìå Layer 5: silencing 1 neurons\n",
      "2025-08-07 11:22:54,371 - INFO - üìå Layer 6: silencing 2 neurons\n",
      "2025-08-07 11:22:54,372 - INFO - üìå Layer 7: silencing 8 neurons\n",
      "2025-08-07 11:22:54,372 - INFO - üìå Layer 8: silencing 6 neurons\n",
      "2025-08-07 11:22:54,372 - INFO - üìå Layer 9: silencing 11 neurons\n",
      "2025-08-07 11:22:54,373 - INFO - üìå Layer 10: silencing 45 neurons\n",
      "2025-08-07 11:22:54,373 - INFO - üìå Layer 11: silencing 157 neurons\n",
      "2025-08-07 11:24:08,916 - INFO - üéØ Accuracy after silencing: 0.8200\n",
      "2025-08-07 11:24:08,916 - INFO - üìè Weighted F1 Score: 0.8111\n",
      "2025-08-07 11:24:08,917 - INFO - üìã Classification report saved to data/BigBird/results/full_silencing.csv\n",
      "2025-08-07 11:24:08,917 - INFO - ‚úÖ All hooks removed after evaluation\n",
      "2025-08-07 11:24:08,918 - INFO - üîß Silencing exactly 461 neurons (5.00% of total 9216)\n",
      "2025-08-07 11:24:08,919 - INFO - üìÅ Saved neuron indices to data/BigBird/neurons/top_5p_neurons_global.json\n",
      "2025-08-07 11:24:08,919 - INFO - üìå Layer 4: silencing 1 neurons\n",
      "2025-08-07 11:24:08,920 - INFO - üìå Layer 5: silencing 8 neurons\n",
      "2025-08-07 11:24:08,920 - INFO - üìå Layer 6: silencing 9 neurons\n",
      "2025-08-07 11:24:08,920 - INFO - üìå Layer 7: silencing 31 neurons\n",
      "2025-08-07 11:24:08,921 - INFO - üìå Layer 8: silencing 22 neurons\n",
      "2025-08-07 11:24:08,921 - INFO - üìå Layer 9: silencing 28 neurons\n",
      "2025-08-07 11:24:08,921 - INFO - üìå Layer 10: silencing 102 neurons\n",
      "2025-08-07 11:24:08,922 - INFO - üìå Layer 11: silencing 260 neurons\n",
      "2025-08-07 11:25:23,624 - INFO - üéØ Accuracy after silencing: 0.8200\n",
      "2025-08-07 11:25:23,624 - INFO - üìè Weighted F1 Score: 0.8111\n",
      "2025-08-07 11:25:23,625 - INFO - üìã Classification report saved to data/BigBird/results/full_silencing.csv\n",
      "2025-08-07 11:25:23,625 - INFO - ‚úÖ All hooks removed after evaluation\n",
      "2025-08-07 11:25:23,627 - INFO - üîß Silencing exactly 691 neurons (7.50% of total 9216)\n",
      "2025-08-07 11:25:23,628 - INFO - üìÅ Saved neuron indices to data/BigBird/neurons/top_7p_neurons_global.json\n",
      "2025-08-07 11:25:23,628 - INFO - üìå Layer 2: silencing 1 neurons\n",
      "2025-08-07 11:25:23,628 - INFO - üìå Layer 4: silencing 3 neurons\n",
      "2025-08-07 11:25:23,628 - INFO - üìå Layer 5: silencing 11 neurons\n",
      "2025-08-07 11:25:23,629 - INFO - üìå Layer 6: silencing 15 neurons\n",
      "2025-08-07 11:25:23,629 - INFO - üìå Layer 7: silencing 51 neurons\n",
      "2025-08-07 11:25:23,629 - INFO - üìå Layer 8: silencing 45 neurons\n",
      "2025-08-07 11:25:23,630 - INFO - üìå Layer 9: silencing 47 neurons\n",
      "2025-08-07 11:25:23,630 - INFO - üìå Layer 10: silencing 160 neurons\n",
      "2025-08-07 11:25:23,630 - INFO - üìå Layer 11: silencing 358 neurons\n",
      "2025-08-07 11:26:38,380 - INFO - üéØ Accuracy after silencing: 0.7800\n",
      "2025-08-07 11:26:38,380 - INFO - üìè Weighted F1 Score: 0.7658\n",
      "2025-08-07 11:26:38,380 - INFO - üìã Classification report saved to data/BigBird/results/full_silencing.csv\n",
      "2025-08-07 11:26:38,381 - INFO - ‚úÖ All hooks removed after evaluation\n",
      "2025-08-07 11:26:38,382 - INFO - üîß Silencing exactly 922 neurons (10.00% of total 9216)\n",
      "2025-08-07 11:26:38,383 - INFO - üìÅ Saved neuron indices to data/BigBird/neurons/top_10p_neurons_global.json\n",
      "2025-08-07 11:26:38,383 - INFO - üìå Layer 0: silencing 1 neurons\n",
      "2025-08-07 11:26:38,384 - INFO - üìå Layer 2: silencing 2 neurons\n",
      "2025-08-07 11:26:38,384 - INFO - üìå Layer 3: silencing 2 neurons\n",
      "2025-08-07 11:26:38,384 - INFO - üìå Layer 4: silencing 6 neurons\n",
      "2025-08-07 11:26:38,385 - INFO - üìå Layer 5: silencing 17 neurons\n",
      "2025-08-07 11:26:38,385 - INFO - üìå Layer 6: silencing 28 neurons\n",
      "2025-08-07 11:26:38,386 - INFO - üìå Layer 7: silencing 76 neurons\n",
      "2025-08-07 11:26:38,386 - INFO - üìå Layer 8: silencing 65 neurons\n",
      "2025-08-07 11:26:38,386 - INFO - üìå Layer 9: silencing 77 neurons\n",
      "2025-08-07 11:26:38,387 - INFO - üìå Layer 10: silencing 220 neurons\n",
      "2025-08-07 11:26:38,387 - INFO - üìå Layer 11: silencing 428 neurons\n",
      "2025-08-07 11:27:53,459 - INFO - üéØ Accuracy after silencing: 0.8000\n",
      "2025-08-07 11:27:53,460 - INFO - üìè Weighted F1 Score: 0.7915\n",
      "2025-08-07 11:27:53,460 - INFO - üìã Classification report saved to data/BigBird/results/full_silencing.csv\n",
      "2025-08-07 11:27:53,461 - INFO - ‚úÖ All hooks removed after evaluation\n",
      "2025-08-07 11:27:53,463 - INFO - üîß Silencing exactly 1152 neurons (12.50% of total 9216)\n",
      "2025-08-07 11:27:53,463 - INFO - üìÅ Saved neuron indices to data/BigBird/neurons/top_12p_neurons_global.json\n",
      "2025-08-07 11:27:53,464 - INFO - üìå Layer 0: silencing 2 neurons\n",
      "2025-08-07 11:27:53,464 - INFO - üìå Layer 2: silencing 5 neurons\n",
      "2025-08-07 11:27:53,464 - INFO - üìå Layer 3: silencing 5 neurons\n",
      "2025-08-07 11:27:53,465 - INFO - üìå Layer 4: silencing 11 neurons\n",
      "2025-08-07 11:27:53,465 - INFO - üìå Layer 5: silencing 22 neurons\n",
      "2025-08-07 11:27:53,465 - INFO - üìå Layer 6: silencing 43 neurons\n",
      "2025-08-07 11:27:53,466 - INFO - üìå Layer 7: silencing 97 neurons\n",
      "2025-08-07 11:27:53,466 - INFO - üìå Layer 8: silencing 90 neurons\n",
      "2025-08-07 11:27:53,466 - INFO - üìå Layer 9: silencing 112 neurons\n",
      "2025-08-07 11:27:53,467 - INFO - üìå Layer 10: silencing 282 neurons\n",
      "2025-08-07 11:27:53,467 - INFO - üìå Layer 11: silencing 483 neurons\n",
      "2025-08-07 11:29:10,624 - INFO - üéØ Accuracy after silencing: 0.8000\n",
      "2025-08-07 11:29:10,625 - INFO - üìè Weighted F1 Score: 0.7915\n",
      "2025-08-07 11:29:10,625 - INFO - üìã Classification report saved to data/BigBird/results/full_silencing.csv\n",
      "2025-08-07 11:29:10,625 - INFO - ‚úÖ All hooks removed after evaluation\n",
      "2025-08-07 11:29:10,627 - INFO - üîß Silencing exactly 1382 neurons (15.00% of total 9216)\n",
      "2025-08-07 11:29:10,628 - INFO - üìÅ Saved neuron indices to data/BigBird/neurons/top_15p_neurons_global.json\n",
      "2025-08-07 11:29:10,628 - INFO - üìå Layer 0: silencing 3 neurons\n",
      "2025-08-07 11:29:10,628 - INFO - üìå Layer 1: silencing 1 neurons\n",
      "2025-08-07 11:29:10,629 - INFO - üìå Layer 2: silencing 7 neurons\n",
      "2025-08-07 11:29:10,629 - INFO - üìå Layer 3: silencing 9 neurons\n",
      "2025-08-07 11:29:10,629 - INFO - üìå Layer 4: silencing 17 neurons\n",
      "2025-08-07 11:29:10,630 - INFO - üìå Layer 5: silencing 35 neurons\n",
      "2025-08-07 11:29:10,630 - INFO - üìå Layer 6: silencing 64 neurons\n",
      "2025-08-07 11:29:10,630 - INFO - üìå Layer 7: silencing 134 neurons\n",
      "2025-08-07 11:29:10,631 - INFO - üìå Layer 8: silencing 117 neurons\n",
      "2025-08-07 11:29:10,631 - INFO - üìå Layer 9: silencing 144 neurons\n",
      "2025-08-07 11:29:10,631 - INFO - üìå Layer 10: silencing 325 neurons\n",
      "2025-08-07 11:29:10,632 - INFO - üìå Layer 11: silencing 526 neurons\n",
      "2025-08-07 11:30:27,738 - INFO - üéØ Accuracy after silencing: 0.7800\n",
      "2025-08-07 11:30:27,739 - INFO - üìè Weighted F1 Score: 0.7608\n",
      "2025-08-07 11:30:27,740 - INFO - üìã Classification report saved to data/BigBird/results/full_silencing.csv\n",
      "2025-08-07 11:30:27,740 - INFO - ‚úÖ All hooks removed after evaluation\n",
      "2025-08-07 11:30:27,741 - INFO - üîß Silencing exactly 1613 neurons (17.50% of total 9216)\n",
      "2025-08-07 11:30:27,742 - INFO - üìÅ Saved neuron indices to data/BigBird/neurons/top_17p_neurons_global.json\n",
      "2025-08-07 11:30:27,743 - INFO - üìå Layer 0: silencing 6 neurons\n",
      "2025-08-07 11:30:27,743 - INFO - üìå Layer 1: silencing 1 neurons\n",
      "2025-08-07 11:30:27,743 - INFO - üìå Layer 2: silencing 7 neurons\n",
      "2025-08-07 11:30:27,744 - INFO - üìå Layer 3: silencing 17 neurons\n",
      "2025-08-07 11:30:27,744 - INFO - üìå Layer 4: silencing 23 neurons\n",
      "2025-08-07 11:30:27,744 - INFO - üìå Layer 5: silencing 51 neurons\n",
      "2025-08-07 11:30:27,745 - INFO - üìå Layer 6: silencing 87 neurons\n",
      "2025-08-07 11:30:27,745 - INFO - üìå Layer 7: silencing 167 neurons\n",
      "2025-08-07 11:30:27,745 - INFO - üìå Layer 8: silencing 149 neurons\n",
      "2025-08-07 11:30:27,746 - INFO - üìå Layer 9: silencing 178 neurons\n",
      "2025-08-07 11:30:27,746 - INFO - üìå Layer 10: silencing 368 neurons\n",
      "2025-08-07 11:30:27,746 - INFO - üìå Layer 11: silencing 559 neurons\n",
      "2025-08-07 11:31:44,174 - INFO - üéØ Accuracy after silencing: 0.8000\n",
      "2025-08-07 11:31:44,174 - INFO - üìè Weighted F1 Score: 0.7915\n",
      "2025-08-07 11:31:44,175 - INFO - üìã Classification report saved to data/BigBird/results/full_silencing.csv\n",
      "2025-08-07 11:31:44,175 - INFO - ‚úÖ All hooks removed after evaluation\n",
      "2025-08-07 11:31:44,176 - INFO - üîß Silencing exactly 1843 neurons (20.00% of total 9216)\n",
      "2025-08-07 11:31:44,177 - INFO - üìÅ Saved neuron indices to data/BigBird/neurons/top_20p_neurons_global.json\n",
      "2025-08-07 11:31:44,178 - INFO - üìå Layer 0: silencing 12 neurons\n",
      "2025-08-07 11:31:44,178 - INFO - üìå Layer 1: silencing 2 neurons\n",
      "2025-08-07 11:31:44,178 - INFO - üìå Layer 2: silencing 9 neurons\n",
      "2025-08-07 11:31:44,179 - INFO - üìå Layer 3: silencing 21 neurons\n",
      "2025-08-07 11:31:44,179 - INFO - üìå Layer 4: silencing 34 neurons\n",
      "2025-08-07 11:31:44,180 - INFO - üìå Layer 5: silencing 73 neurons\n",
      "2025-08-07 11:31:44,180 - INFO - üìå Layer 6: silencing 113 neurons\n",
      "2025-08-07 11:31:44,180 - INFO - üìå Layer 7: silencing 198 neurons\n",
      "2025-08-07 11:31:44,181 - INFO - üìå Layer 8: silencing 183 neurons\n",
      "2025-08-07 11:31:44,181 - INFO - üìå Layer 9: silencing 215 neurons\n",
      "2025-08-07 11:31:44,181 - INFO - üìå Layer 10: silencing 399 neurons\n",
      "2025-08-07 11:31:44,182 - INFO - üìå Layer 11: silencing 584 neurons\n",
      "/Users/kikay/Documents/investigacion/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kikay/Documents/investigacion/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/kikay/Documents/investigacion/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2025-08-07 11:33:00,706 - INFO - üéØ Accuracy after silencing: 0.7400\n",
      "2025-08-07 11:33:00,707 - INFO - üìè Weighted F1 Score: 0.6534\n",
      "2025-08-07 11:33:00,707 - INFO - üìã Classification report saved to data/BigBird/results/full_silencing.csv\n",
      "2025-08-07 11:33:00,708 - INFO - ‚úÖ All hooks removed after evaluation\n",
      "2025-08-07 11:33:00,709 - INFO - üîß Silencing exactly 2304 neurons (25.00% of total 9216)\n",
      "2025-08-07 11:33:00,710 - INFO - üìÅ Saved neuron indices to data/BigBird/neurons/top_25p_neurons_global.json\n",
      "2025-08-07 11:33:00,711 - INFO - üìå Layer 0: silencing 21 neurons\n",
      "2025-08-07 11:33:00,711 - INFO - üìå Layer 1: silencing 2 neurons\n",
      "2025-08-07 11:33:00,712 - INFO - üìå Layer 2: silencing 23 neurons\n",
      "2025-08-07 11:33:00,712 - INFO - üìå Layer 3: silencing 35 neurons\n",
      "2025-08-07 11:33:00,712 - INFO - üìå Layer 4: silencing 68 neurons\n",
      "2025-08-07 11:33:00,713 - INFO - üìå Layer 5: silencing 108 neurons\n",
      "2025-08-07 11:33:00,713 - INFO - üìå Layer 6: silencing 152 neurons\n",
      "2025-08-07 11:33:00,714 - INFO - üìå Layer 7: silencing 257 neurons\n",
      "2025-08-07 11:33:00,714 - INFO - üìå Layer 8: silencing 245 neurons\n",
      "2025-08-07 11:33:00,715 - INFO - üìå Layer 9: silencing 288 neurons\n",
      "2025-08-07 11:33:00,715 - INFO - üìå Layer 10: silencing 474 neurons\n",
      "2025-08-07 11:33:00,716 - INFO - üìå Layer 11: silencing 631 neurons\n",
      "2025-08-07 11:34:17,428 - INFO - üéØ Accuracy after silencing: 0.7600\n",
      "2025-08-07 11:34:17,428 - INFO - üìè Weighted F1 Score: 0.7438\n",
      "2025-08-07 11:34:17,429 - INFO - üìã Classification report saved to data/BigBird/results/full_silencing.csv\n",
      "2025-08-07 11:34:17,429 - INFO - ‚úÖ All hooks removed after evaluation\n",
      "2025-08-07 11:34:17,431 - INFO - üîß Silencing exactly 2765 neurons (30.00% of total 9216)\n",
      "2025-08-07 11:34:17,432 - INFO - üìÅ Saved neuron indices to data/BigBird/neurons/top_30p_neurons_global.json\n",
      "2025-08-07 11:34:17,432 - INFO - üìå Layer 0: silencing 35 neurons\n",
      "2025-08-07 11:34:17,433 - INFO - üìå Layer 1: silencing 4 neurons\n",
      "2025-08-07 11:34:17,433 - INFO - üìå Layer 2: silencing 40 neurons\n",
      "2025-08-07 11:34:17,433 - INFO - üìå Layer 3: silencing 61 neurons\n",
      "2025-08-07 11:34:17,434 - INFO - üìå Layer 4: silencing 99 neurons\n",
      "2025-08-07 11:34:17,434 - INFO - üìå Layer 5: silencing 144 neurons\n",
      "2025-08-07 11:34:17,435 - INFO - üìå Layer 6: silencing 207 neurons\n",
      "2025-08-07 11:34:17,435 - INFO - üìå Layer 7: silencing 328 neurons\n",
      "2025-08-07 11:34:17,435 - INFO - üìå Layer 8: silencing 302 neurons\n",
      "2025-08-07 11:34:17,436 - INFO - üìå Layer 9: silencing 359 neurons\n",
      "2025-08-07 11:34:17,436 - INFO - üìå Layer 10: silencing 521 neurons\n",
      "2025-08-07 11:34:17,437 - INFO - üìå Layer 11: silencing 665 neurons\n",
      "2025-08-07 11:35:34,212 - INFO - üéØ Accuracy after silencing: 0.7800\n",
      "2025-08-07 11:35:34,213 - INFO - üìè Weighted F1 Score: 0.7507\n",
      "2025-08-07 11:35:34,213 - INFO - üìã Classification report saved to data/BigBird/results/full_silencing.csv\n",
      "2025-08-07 11:35:34,213 - INFO - ‚úÖ All hooks removed after evaluation\n",
      "2025-08-07 11:35:34,215 - INFO - üîß Silencing exactly 3226 neurons (35.00% of total 9216)\n",
      "2025-08-07 11:35:34,216 - INFO - üìÅ Saved neuron indices to data/BigBird/neurons/top_35p_neurons_global.json\n",
      "2025-08-07 11:35:34,216 - INFO - üìå Layer 0: silencing 47 neurons\n",
      "2025-08-07 11:35:34,217 - INFO - üìå Layer 1: silencing 6 neurons\n",
      "2025-08-07 11:35:34,217 - INFO - üìå Layer 2: silencing 54 neurons\n",
      "2025-08-07 11:35:34,218 - INFO - üìå Layer 3: silencing 86 neurons\n",
      "2025-08-07 11:35:34,218 - INFO - üìå Layer 4: silencing 137 neurons\n",
      "2025-08-07 11:35:34,219 - INFO - üìå Layer 5: silencing 194 neurons\n",
      "2025-08-07 11:35:34,219 - INFO - üìå Layer 6: silencing 273 neurons\n",
      "2025-08-07 11:35:34,219 - INFO - üìå Layer 7: silencing 396 neurons\n",
      "2025-08-07 11:35:34,220 - INFO - üìå Layer 8: silencing 362 neurons\n",
      "2025-08-07 11:35:34,220 - INFO - üìå Layer 9: silencing 419 neurons\n",
      "2025-08-07 11:35:34,221 - INFO - üìå Layer 10: silencing 562 neurons\n",
      "2025-08-07 11:35:34,221 - INFO - üìå Layer 11: silencing 690 neurons\n",
      "2025-08-07 11:36:50,704 - INFO - üéØ Accuracy after silencing: 0.6000\n",
      "2025-08-07 11:36:50,705 - INFO - üìè Weighted F1 Score: 0.5853\n",
      "2025-08-07 11:36:50,705 - INFO - üìã Classification report saved to data/BigBird/results/full_silencing.csv\n",
      "2025-08-07 11:36:50,705 - INFO - ‚úÖ All hooks removed after evaluation\n",
      "2025-08-07 11:36:50,707 - INFO - üîß Silencing exactly 3686 neurons (40.00% of total 9216)\n",
      "2025-08-07 11:36:50,708 - INFO - üìÅ Saved neuron indices to data/BigBird/neurons/top_40p_neurons_global.json\n",
      "2025-08-07 11:36:50,709 - INFO - üìå Layer 0: silencing 58 neurons\n",
      "2025-08-07 11:36:50,709 - INFO - üìå Layer 1: silencing 7 neurons\n",
      "2025-08-07 11:36:50,710 - INFO - üìå Layer 2: silencing 77 neurons\n",
      "2025-08-07 11:36:50,710 - INFO - üìå Layer 3: silencing 129 neurons\n",
      "2025-08-07 11:36:50,710 - INFO - üìå Layer 4: silencing 178 neurons\n",
      "2025-08-07 11:36:50,711 - INFO - üìå Layer 5: silencing 249 neurons\n",
      "2025-08-07 11:36:50,711 - INFO - üìå Layer 6: silencing 319 neurons\n",
      "2025-08-07 11:36:50,712 - INFO - üìå Layer 7: silencing 450 neurons\n",
      "2025-08-07 11:36:50,712 - INFO - üìå Layer 8: silencing 423 neurons\n",
      "2025-08-07 11:36:50,713 - INFO - üìå Layer 9: silencing 485 neurons\n",
      "2025-08-07 11:36:50,713 - INFO - üìå Layer 10: silencing 602 neurons\n",
      "2025-08-07 11:36:50,714 - INFO - üìå Layer 11: silencing 709 neurons\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m percentages \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0.025\u001b[39m, \u001b[38;5;241m0.05\u001b[39m, \u001b[38;5;241m0.075\u001b[39m, \u001b[38;5;241m0.10\u001b[39m, \u001b[38;5;241m0.125\u001b[39m, \u001b[38;5;241m0.15\u001b[39m, \u001b[38;5;241m0.175\u001b[39m, \u001b[38;5;241m0.20\u001b[39m, \u001b[38;5;241m0.25\u001b[39m, \u001b[38;5;241m0.30\u001b[39m, \u001b[38;5;241m0.35\u001b[39m, \u001b[38;5;241m0.40\u001b[39m, \u001b[38;5;241m0.45\u001b[39m, \u001b[38;5;241m0.50\u001b[39m, \u001b[38;5;241m0.65\u001b[39m, \u001b[38;5;241m0.75\u001b[39m, \u001b[38;5;241m0.8\u001b[39m, \u001b[38;5;241m0.95\u001b[39m]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pct \u001b[38;5;129;01min\u001b[39;00m percentages:\n\u001b[0;32m----> 4\u001b[0m     \u001b[43msilence_top_global_percentage_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprobe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprobe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel2idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel2idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpercentage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexperiment_title\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSilencing \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpct\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[38;5;132;43;01m:\u001b[39;49;00m\u001b[38;5;124;43m.1f\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m% Global Neurons\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 48\u001b[0m, in \u001b[0;36msilence_top_global_percentage_and_evaluate\u001b[0;34m(model, sample_df, labels_list, probe, label2idx, percentage, report_path, experiment_title)\u001b[0m\n\u001b[1;32m     45\u001b[0m attention_mask_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(sample_df\u001b[38;5;241m.\u001b[39mloc[i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 48\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m     logits \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     50\u001b[0m     pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/Documents/investigacion/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/investigacion/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/investigacion/.venv/lib/python3.9/site-packages/transformers/models/big_bird/modeling_big_bird.py:2596\u001b[0m, in \u001b[0;36mBigBirdForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   2553\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2554\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   2555\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2592\u001b[0m \u001b[38;5;124;03m```\u001b[39;00m\n\u001b[1;32m   2593\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2594\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 2596\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2597\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2598\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2599\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2600\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2601\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2602\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2603\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2604\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2605\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2606\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2608\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   2609\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[0;32m~/Documents/investigacion/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/investigacion/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/investigacion/.venv/lib/python3.9/site-packages/transformers/models/big_bird/modeling_big_bird.py:2032\u001b[0m, in \u001b[0;36mBigBirdModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2022\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m   2024\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m   2025\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2026\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2029\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m   2030\u001b[0m )\n\u001b[0;32m-> 2032\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2033\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2034\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2035\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2036\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2037\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2038\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2039\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2040\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2041\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2042\u001b[0m \u001b[43m    \u001b[49m\u001b[43mband_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mband_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2043\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfrom_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2044\u001b[0m \u001b[43m    \u001b[49m\u001b[43mto_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mto_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2045\u001b[0m \u001b[43m    \u001b[49m\u001b[43mblocked_encoder_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblocked_encoder_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2046\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2047\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2048\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   2050\u001b[0m pooler_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output[:, \u001b[38;5;241m0\u001b[39m, :])) \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/investigacion/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/investigacion/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/investigacion/.venv/lib/python3.9/site-packages/transformers/models/big_bird/modeling_big_bird.py:1612\u001b[0m, in \u001b[0;36mBigBirdEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, band_mask, from_mask, to_mask, blocked_encoder_mask, return_dict)\u001b[0m\n\u001b[1;32m   1597\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1598\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m   1599\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1609\u001b[0m         output_attentions,\n\u001b[1;32m   1610\u001b[0m     )\n\u001b[1;32m   1611\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1612\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1614\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1615\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1616\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1617\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1618\u001b[0m \u001b[43m        \u001b[49m\u001b[43mband_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1619\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfrom_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1620\u001b[0m \u001b[43m        \u001b[49m\u001b[43mto_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1621\u001b[0m \u001b[43m        \u001b[49m\u001b[43mblocked_encoder_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1622\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1623\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1624\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1626\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/Documents/investigacion/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/investigacion/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/investigacion/.venv/lib/python3.9/site-packages/transformers/models/big_bird/modeling_big_bird.py:1518\u001b[0m, in \u001b[0;36mBigBirdLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, band_mask, from_mask, to_mask, blocked_encoder_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m   1515\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1516\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m-> 1518\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1519\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[1;32m   1520\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/investigacion/.venv/lib/python3.9/site-packages/transformers/pytorch_utils.py:253\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 253\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/investigacion/.venv/lib/python3.9/site-packages/transformers/models/big_bird/modeling_big_bird.py:1531\u001b[0m, in \u001b[0;36mBigBirdLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m   1530\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[0;32m-> 1531\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1532\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[1;32m   1533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m~/Documents/investigacion/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/investigacion/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/investigacion/.venv/lib/python3.9/site-packages/transformers/models/big_bird/modeling_big_bird.py:1403\u001b[0m, in \u001b[0;36mBigBirdIntermediate.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m   1402\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(hidden_states)\n\u001b[0;32m-> 1403\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate_act_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/Documents/investigacion/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/investigacion/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/investigacion/.venv/lib/python3.9/site-packages/transformers/activations.py:47\u001b[0m, in \u001b[0;36mNewGELUActivation.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mtanh(math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m2.0\u001b[39m \u001b[38;5;241m/\u001b[39m math\u001b[38;5;241m.\u001b[39mpi) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.044715\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3.0\u001b[39;49m\u001b[43m)\u001b[49m)))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "percentages = [0.025, 0.05, 0.075, 0.10, 0.125, 0.15, 0.175, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.65, 0.75, 0.8, 0.95]\n",
    "\n",
    "for pct in percentages:\n",
    "    silence_top_global_percentage_and_evaluate(\n",
    "        model=model,\n",
    "        sample_df=sample_df,\n",
    "        labels_list=labels_list,\n",
    "        probe=probe,\n",
    "        label2idx=label2idx,\n",
    "        percentage=pct,\n",
    "        experiment_title=f\"Silencing {pct*100:.1f}% Global Neurons\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec3cbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "def plot_f1_scores_from_file(filepath, output_path= f\"{BASE_PATH}/figs/f1_curve_global.png\"):\n",
    "    with open(filepath, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Estructuras para almacenar los datos\n",
    "    results = defaultdict(list)  # clase -> lista de F1-scores\n",
    "    global_f1_scores = {}\n",
    "    percentages = []\n",
    "    current_percentage = None\n",
    "\n",
    "    # Parsear el contenido\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "\n",
    "        # Detectar inicio de bloque\n",
    "        if line.startswith(\"# Silencing\"):\n",
    "            match = re.search(r\"# Silencing ([\\d.]+)% Global Neurons\", line)\n",
    "            if match:\n",
    "                current_percentage = float(match.group(1))\n",
    "                percentages.append(current_percentage)\n",
    "            continue\n",
    "\n",
    "        if line.startswith(\",precision\") or not line:\n",
    "            continue\n",
    "\n",
    "        parts = line.split(\",\")\n",
    "        label = parts[0]\n",
    "\n",
    "        if label.isdigit():\n",
    "            class_index = int(label)\n",
    "            try:\n",
    "                f1 = float(parts[3])\n",
    "                results[class_index].append(f1)\n",
    "            except:\n",
    "                results[class_index].append(None)\n",
    "        elif label == \"weighted avg\":\n",
    "            try:\n",
    "                global_f1_scores[current_percentage] = float(parts[3])\n",
    "            except:\n",
    "                global_f1_scores[current_percentage] = None\n",
    "\n",
    "    # Ordenar porcentajes\n",
    "    sorted_percentages = sorted(global_f1_scores.keys())\n",
    "    global_f1 = [global_f1_scores[p] for p in sorted_percentages]\n",
    "\n",
    "    # Crear la figura\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # F1 global\n",
    "    plt.plot(sorted_percentages, global_f1, label=\"Global F1\", linewidth=2, marker='o')\n",
    "\n",
    "    # F1 por clase\n",
    "    for class_index in sorted(results.keys()):\n",
    "        f1s = results[class_index]\n",
    "        plt.plot(sorted_percentages, f1s, label=f\"Class {class_index}\", linestyle='--', marker='x')\n",
    "\n",
    "    # Formato\n",
    "    plt.title(\"F1 Scores vs. % of Silenced Global Neurons\")\n",
    "    plt.xlabel(\"% of Silenced Neurons\")\n",
    "    plt.ylabel(\"F1 Score\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Guardar como PNG\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    print(f\"Gr√°fica guardada como: {output_path}\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca23f20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f1_scores_from_file(f\"{BASE_PATH}/results/full_silencing.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f318510-19fb-424a-a75e-eeedc5ac36fc",
   "metadata": {},
   "source": [
    "## Impact per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56729e96-13c8-467f-a563-4ac5c96a58fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_k_neurons_for_class_exact(probe, percentage: float, class_to_idx: dict, class_id: int) -> list[int]:\n",
    "    \"\"\"\n",
    "    Return top-k neurons most important for a specific class, measured by absolute weight.\n",
    "    \"\"\"\n",
    "    weight_matrix = probe.linear.weight.detach().abs()  # [num_classes, num_neurons]\n",
    "    class_weights = weight_matrix[class_id]  # [num_neurons]\n",
    "    total_neurons = class_weights.size(0)\n",
    "    top_n = round(percentage * total_neurons)\n",
    "    top_indices = class_weights.cpu().numpy().argsort()[-top_n:]\n",
    "    return top_indices.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0609da1d-3fde-4fc7-9913-bd3c3b4642da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# Get encoder layers dynamically\n",
    "# ==========================\n",
    "def get_encoder_layers(model):\n",
    "    if hasattr(model, \"bert\"):\n",
    "        return model.bert.encoder.layer\n",
    "    elif hasattr(model, \"longformer\"):\n",
    "        return model.longformer.encoder.layer\n",
    "    elif hasattr(model, \"distilbert\"):\n",
    "        return model.distilbert.transformer.layer\n",
    "    else:\n",
    "        raise NotImplementedError(\"‚ùå Unsupported model architecture.\")\n",
    "\n",
    "# ==========================\n",
    "# Silence and evaluate top per-class neurons\n",
    "# ==========================\n",
    "\n",
    "def silence_top_class_percentage_and_evaluate(\n",
    "    model,\n",
    "    sample_df,\n",
    "    labels_list,\n",
    "    probe,\n",
    "    label2idx,\n",
    "    class_id: int,\n",
    "    percentage: float = 0.1,\n",
    "    report_path: str = None,\n",
    "    experiment_title: str = None\n",
    "):\n",
    "    class_name = f\"class_{class_id}\"\n",
    "    hidden_dim = model.config.hidden_size\n",
    "    num_layers = model.config.num_hidden_layers\n",
    "    total_neurons = num_layers * hidden_dim\n",
    "\n",
    "    # Get top neurons for specific class\n",
    "    top_class_neurons = get_top_k_neurons_for_class_exact(\n",
    "        probe, percentage=percentage, class_to_idx=label2idx, class_id=class_id\n",
    "    )\n",
    "\n",
    "    logger.info(f\"üîß Silencing {len(top_class_neurons)} neurons for class {class_id} ({percentage:.2%} of total)\")\n",
    "\n",
    "    # Save neurons to JSON\n",
    "    neurons_dir = f\"{BASE_PATH}/neurons\"\n",
    "    os.makedirs(neurons_dir, exist_ok=True)\n",
    "    json_path = f\"{neurons_dir}/top_{int(percentage * 100)}p_neurons_{class_name}.json\"\n",
    "    with open(json_path, \"w\") as f:\n",
    "        json.dump(top_class_neurons, f, indent=4)\n",
    "    logger.info(f\"üìÅ Saved neuron indices to {json_path}\")\n",
    "\n",
    "    # Register hooks per layer\n",
    "    encoder_layers = get_encoder_layers(model)\n",
    "    hook_handles = []\n",
    "    for i in range(num_layers):\n",
    "        indices_layer = [idx - i * hidden_dim for idx in top_class_neurons if i * hidden_dim <= idx < (i + 1) * hidden_dim]\n",
    "        if indices_layer:\n",
    "            logger.info(f\"üìå Layer {i}: silencing {len(indices_layer)} neurons for class {class_id}\")\n",
    "            handle = encoder_layers[i].output.register_forward_hook(make_cls_silence_hook(indices_layer))\n",
    "            hook_handles.append(handle)\n",
    "\n",
    "    # Inference\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    for i in range(len(sample_df)):\n",
    "        input_ids_tensor = torch.tensor(sample_df.loc[i, 'input_ids']).unsqueeze(0).to(model.device)\n",
    "        attention_mask_tensor = torch.tensor(sample_df.loc[i, 'attention_mask']).unsqueeze(0).to(model.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids_tensor, attention_mask=attention_mask_tensor)\n",
    "            logits = outputs['logits']\n",
    "            pred = torch.argmax(logits, dim=1).item()\n",
    "            predictions.append(pred)\n",
    "\n",
    "        del input_ids_tensor, attention_mask_tensor, outputs, logits\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # Metrics\n",
    "    accuracy = accuracy_score(labels_list, predictions)\n",
    "    f1 = f1_score(labels_list, predictions, average='weighted')\n",
    "    report_dict = classification_report(labels_list, predictions, output_dict=True)\n",
    "    report_df = pd.DataFrame(report_dict).transpose().round(4)\n",
    "    report_df = report_df.drop(\"accuracy\", errors=\"ignore\")\n",
    "\n",
    "    accuracy_row = pd.DataFrame({\n",
    "        'precision': [\"\"],\n",
    "        'recall': [\"\"],\n",
    "        'f1-score': [accuracy],\n",
    "        'support': [sum(report_df[\"support\"])]\n",
    "    }, index=[\"overall_accuracy\"])\n",
    "    final_df = pd.concat([report_df, accuracy_row])\n",
    "\n",
    "    # Save classification report\n",
    "    if report_path is None:\n",
    "        report_path = f\"{BASE_PATH}/results/class_silencing{class_id}.csv\"\n",
    "    os.makedirs(os.path.dirname(report_path), exist_ok=True)\n",
    "\n",
    "    if experiment_title is None:\n",
    "        experiment_title = f\"Silencing top {percentage:.2%} neurons for class {class_id}\"\n",
    "\n",
    "    if not os.path.exists(report_path):\n",
    "        with open(report_path, \"w\") as f:\n",
    "            f.write(f\"# {experiment_title}\\n\")\n",
    "            final_df.to_csv(f)\n",
    "    else:\n",
    "        with open(report_path, \"a\") as f:\n",
    "            f.write(f\"\\n\\n# {experiment_title}\\n\")\n",
    "        final_df.to_csv(report_path, mode=\"a\")\n",
    "\n",
    "    logger.info(f\"üéØ Accuracy after class-specific silencing: {accuracy:.4f}\")\n",
    "    logger.info(f\"üìè Weighted F1 Score: {f1:.4f}\")\n",
    "    logger.info(f\"üìã Classification report saved to {report_path}\")\n",
    "\n",
    "    # Remove all hooks\n",
    "    for handle in hook_handles:\n",
    "        handle.remove()\n",
    "    logger.info(\"‚úÖ All hooks removed after evaluation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3d65d1-ff4c-457b-90d9-a1a76563ef48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentages = [0.025, 0.05, 0.075, 0.10, 0.125, 0.15, 0.175, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.65, 0.75, 0.8, 0.95]\n",
    "percentages = [0.50]\n",
    "target_class_id = 4\n",
    "\n",
    "for pct in percentages:\n",
    "    silence_top_class_percentage_and_evaluate(\n",
    "        model=model,\n",
    "        sample_df=sample_df,\n",
    "        labels_list=labels_list,\n",
    "        probe=probe,\n",
    "        label2idx=label2idx,\n",
    "        class_id=target_class_id,\n",
    "        percentage=pct,\n",
    "        experiment_title=f\"Silencing {pct*100:.1f}% of Neurons for Class {target_class_id}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f09f679-c5bd-4b64-b72d-13adefa9d49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages = [0.025, 0.05, 0.075, 0.10, 0.125, 0.15, 0.175, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.65, 0.75, 0.8, 0.95]\n",
    "\n",
    "target_class_id = 3\n",
    "\n",
    "for pct in percentages:\n",
    "    silence_top_class_percentage_and_evaluate(\n",
    "        model=model,\n",
    "        sample_df=sample_df,\n",
    "        labels_list=labels_list,\n",
    "        probe=probe,\n",
    "        label2idx=label2idx,\n",
    "        class_id=target_class_id,\n",
    "        percentage=pct,\n",
    "        experiment_title=f\"Silencing {pct*100:.1f}% of Neurons for Class {target_class_id}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55026e28-3e0a-4272-9f64-a3ba04776f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages = [0.025, 0.05, 0.075, 0.10, 0.125, 0.15, 0.175, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.65, 0.75, 0.8, 0.95]\n",
    "\n",
    "target_class_id = 2\n",
    "for pct in percentages:\n",
    "    silence_top_class_percentage_and_evaluate(\n",
    "        model=model,\n",
    "        sample_df=sample_df,\n",
    "        labels_list=labels_list,\n",
    "        probe=probe,\n",
    "        label2idx=label2idx,\n",
    "        class_id=target_class_id,\n",
    "        percentage=pct,\n",
    "        experiment_title=f\"Silencing {pct*100:.1f}% of Neurons for Class {target_class_id}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f21b1e0-d603-4dd5-b662-9724969b598d",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages = [0.025, 0.05, 0.075, 0.10, 0.125, 0.15, 0.175, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.65, 0.75, 0.8, 0.95]\n",
    "\n",
    "target_class_id = 1\n",
    "\n",
    "for pct in percentages:\n",
    "    silence_top_class_percentage_and_evaluate(\n",
    "        model=model,\n",
    "        sample_df=sample_df,\n",
    "        labels_list=labels_list,\n",
    "        probe=probe,\n",
    "        label2idx=label2idx,\n",
    "        class_id=target_class_id,\n",
    "        percentage=pct,\n",
    "        experiment_title=f\"Silencing {pct*100:.1f}% of Neurons for Class {target_class_id}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59760190-c9cc-406e-b53b-6edef73639d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentages = [0.025, 0.05, 0.075, 0.10, 0.125, 0.15, 0.175, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.65, 0.75, 0.8, 0.95]\n",
    "\n",
    "target_class_id = 0\n",
    "\n",
    "for pct in percentages:\n",
    "    silence_top_class_percentage_and_evaluate(\n",
    "        model=model,\n",
    "        sample_df=sample_df,\n",
    "        labels_list=labels_list,\n",
    "        probe=probe,\n",
    "        label2idx=label2idx,\n",
    "        class_id=target_class_id,\n",
    "        percentage=pct,\n",
    "        experiment_title=f\"Silencing {pct*100:.1f}% of Neurons for Class {target_class_id}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b6dfed-1928-40c7-99f8-0ed26e3b96b2",
   "metadata": {},
   "source": [
    "# Attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e2541c-cad9-4a8d-97a6-d2d0e8bd28cf",
   "metadata": {},
   "source": [
    "## FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a240dcaa-e052-424d-b037-145db9683c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "def run_fgsm_attack_and_evaluate(\n",
    "    model,\n",
    "    sample_df,\n",
    "    labels_list,\n",
    "    epsilon: float = 0.1,\n",
    "    report_path: str = f\"{BASE_PATH}/fgsm.csv\",\n",
    "    experiment_title: str = None\n",
    "):\n",
    "    logger.info(f\"‚öîÔ∏è Running FGSM attack with Œµ = {epsilon}\")\n",
    "    model.eval()\n",
    "    predictions_fgsm = []\n",
    "    loss_fn = CrossEntropyLoss()\n",
    "\n",
    "    is_longformer = hasattr(model, \"longformer\")\n",
    "\n",
    "    for i in range(len(sample_df)):\n",
    "        # ===============================\n",
    "        # üî¢ Prepare input tensors\n",
    "        # ===============================\n",
    "        input_ids_tensor = torch.tensor(sample_df.loc[i, 'input_ids'], dtype=torch.long).unsqueeze(0).to(model.device)\n",
    "        attention_mask_tensor = torch.tensor(sample_df.loc[i, 'attention_mask'], dtype=torch.long).unsqueeze(0).to(model.device)\n",
    "        true_label = torch.tensor([labels_list[i]], dtype=torch.long).to(model.device)\n",
    "\n",
    "        # ===============================\n",
    "        # üîç Extract embeddings as leaf tensor\n",
    "        # ===============================\n",
    "        with torch.no_grad():\n",
    "            embedding_output = model.base_model.embeddings(input_ids_tensor)\n",
    "        embeds = embedding_output.clone().detach().requires_grad_(True)\n",
    "\n",
    "        # ===============================\n",
    "        # üîÅ Forward pass\n",
    "        # ===============================\n",
    "        if is_longformer:\n",
    "            global_attention_mask = torch.zeros_like(attention_mask_tensor)\n",
    "            global_attention_mask[:, 0] = 1\n",
    "            outputs = model(\n",
    "                inputs_embeds=embeds,\n",
    "                attention_mask=attention_mask_tensor,\n",
    "                global_attention_mask=global_attention_mask\n",
    "            )\n",
    "        else:\n",
    "            outputs = model(\n",
    "                inputs_embeds=embeds,\n",
    "                attention_mask=attention_mask_tensor\n",
    "            )\n",
    "\n",
    "        logits = outputs.logits\n",
    "        loss = loss_fn(logits, true_label)\n",
    "\n",
    "        # ===============================\n",
    "        # üîÅ Backward pass\n",
    "        # ===============================\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # ===============================\n",
    "        # ‚öîÔ∏è FGSM perturbation\n",
    "        # ===============================\n",
    "        perturbation = epsilon * embeds.grad.data.sign()\n",
    "        adv_embeds = embeds + perturbation\n",
    "\n",
    "        # ===============================\n",
    "        # üîÆ Inference with adversarial input\n",
    "        # ===============================\n",
    "        with torch.no_grad():\n",
    "            if is_longformer:\n",
    "                adv_outputs = model(\n",
    "                    inputs_embeds=adv_embeds,\n",
    "                    attention_mask=attention_mask_tensor,\n",
    "                    global_attention_mask=global_attention_mask\n",
    "                )\n",
    "            else:\n",
    "                adv_outputs = model(\n",
    "                    inputs_embeds=adv_embeds,\n",
    "                    attention_mask=attention_mask_tensor\n",
    "                )\n",
    "            adv_logits = adv_outputs.logits\n",
    "            pred = torch.argmax(adv_logits, dim=1).item()\n",
    "            predictions_fgsm.append(pred)\n",
    "\n",
    "        del input_ids_tensor, attention_mask_tensor, embeds, adv_embeds, outputs, adv_outputs, logits, adv_logits\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # ===============================\n",
    "    # üìä Evaluation\n",
    "    # ===============================\n",
    "    accuracy = accuracy_score(labels_list, predictions_fgsm)\n",
    "    f1 = f1_score(labels_list, predictions_fgsm, average='weighted')\n",
    "    report_dict = classification_report(labels_list, predictions_fgsm, output_dict=True)\n",
    "    report_df = pd.DataFrame(report_dict).transpose().round(4).drop(\"accuracy\", errors=\"ignore\")\n",
    "\n",
    "    accuracy_row = pd.DataFrame({\n",
    "        'precision': [\"\"],\n",
    "        'recall': [\"\"],\n",
    "        'f1-score': [accuracy],\n",
    "        'support': [sum(report_df[\"support\"])]\n",
    "    }, index=[\"overall_accuracy\"])\n",
    "    final_df = pd.concat([report_df, accuracy_row])\n",
    "\n",
    "    # ===============================\n",
    "    # üíæ Save report\n",
    "    # ===============================\n",
    "    if experiment_title is None:\n",
    "        experiment_title = f\"FGSM Attack (Œµ = {epsilon})\"\n",
    "    if not os.path.exists(report_path):\n",
    "        with open(report_path, \"w\") as f:\n",
    "            f.write(f\"# {experiment_title}\\n\")\n",
    "            final_df.to_csv(f)\n",
    "    else:\n",
    "        with open(report_path, \"a\") as f:\n",
    "            f.write(f\"\\n\\n# {experiment_title}\\n\")\n",
    "        final_df.to_csv(report_path, mode=\"a\")\n",
    "\n",
    "    logger.info(f\"üéØ Accuracy under FGSM (Œµ={epsilon}): {accuracy:.4f}\")\n",
    "    logger.info(f\"üìè Weighted F1 Score: {f1:.4f}\")\n",
    "    logger.info(f\"üìã Classification report saved to {report_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666b89b9-b9d6-4f76-b93d-beabcaee9722",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "model.to(\"cpu\")\n",
    "device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ee84d3-e9d3-47ca-8590-8465da7aafff",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_fgsm_attack_and_evaluate(\n",
    "    model=model,\n",
    "    sample_df=sample_df,\n",
    "    labels_list=labels_list,\n",
    "    epsilon=0.1,\n",
    "    experiment_title=\"FGSM Adversarial Attack with Œµ = 0.1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c245bc3d-f654-4e2d-bdc2-bdeead37e0f1",
   "metadata": {},
   "source": [
    "## Random Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71365102-736c-4fc4-b060-228fe966b49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_random_noise_attack(\n",
    "    model,\n",
    "    sample_df,\n",
    "    labels_list,\n",
    "    epsilon=0.3,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    import torch\n",
    "    from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "    logger.info(f\"üé≤ Running random noise attack (epsilon={epsilon})\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    predictions_noise = []\n",
    "\n",
    "    is_longformer = hasattr(model, \"longformer\")\n",
    "\n",
    "    for i in range(len(sample_df)):\n",
    "        input_ids_tensor = torch.tensor(sample_df.loc[i, 'input_ids'], dtype=torch.long).unsqueeze(0).to(device)\n",
    "        attention_mask_tensor = torch.tensor(sample_df.loc[i, 'attention_mask'], dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            embeddings = model.base_model.embeddings(input_ids_tensor)\n",
    "            noisy_embeddings = embeddings + epsilon * torch.randn_like(embeddings)\n",
    "\n",
    "            if is_longformer:\n",
    "                global_attention_mask = torch.zeros_like(attention_mask_tensor)\n",
    "                global_attention_mask[:, 0] = 1\n",
    "                outputs = model(\n",
    "                    inputs_embeds=noisy_embeddings,\n",
    "                    attention_mask=attention_mask_tensor,\n",
    "                    global_attention_mask=global_attention_mask\n",
    "                )\n",
    "            else:\n",
    "                outputs = model(\n",
    "                    inputs_embeds=noisy_embeddings,\n",
    "                    attention_mask=attention_mask_tensor\n",
    "                )\n",
    "\n",
    "            logits = outputs.logits\n",
    "            pred = torch.argmax(logits, dim=1).item()\n",
    "            predictions_noise.append(pred)\n",
    "\n",
    "    accuracy = accuracy_score(labels_list, predictions_noise)\n",
    "    f1 = f1_score(labels_list, predictions_noise, average='weighted')\n",
    "    report = classification_report(labels_list, predictions_noise)\n",
    "\n",
    "    logger.info(f\"üìâ Random noise attack results (epsilon={epsilon}):\")\n",
    "    logger.info(f\"Accuracy: {accuracy:.4f} | F1 Score: {f1:.4f}\")\n",
    "    logger.info(f\"\\nClassification Report:\\n{report}\")\n",
    "\n",
    "    return accuracy, f1, predictions_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c5486c-42b6-4f4f-acd5-1697a6be21f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "epsilons = np.linspace(0.1, 1.0, 10)  # 10 valores de 0.1 a 1.0\n",
    "results = []\n",
    "\n",
    "for epsilon in epsilons:\n",
    "    logger.info(f\"\\nüé≤ Running random noise attack with Œµ={epsilon:.2f}\")\n",
    "\n",
    "    acc_noise, f1_noise, preds_noise = run_random_noise_attack(\n",
    "        model=model,\n",
    "        sample_df=sample_df,\n",
    "        labels_list=labels_list,\n",
    "        epsilon=epsilon,\n",
    "        device=\"cpu\"\n",
    "    )\n",
    "\n",
    "    logger.info(f\"üìâ Results for Œµ={epsilon:.2f} ‚Üí Accuracy: {acc_noise:.4f} | F1 Score: {f1_noise:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        \"epsilon\": round(epsilon, 2),\n",
    "        \"accuracy\": acc_noise,\n",
    "        \"f1_score\": f1_noise\n",
    "    })\n",
    "\n",
    "# Convertimos resultados a dataframe\n",
    "noise_sweep_df = pd.DataFrame(results)\n",
    "noise_sweep_df.to_csv(\"results/random_noise_sweep_up_to_1.csv\", index=False)\n",
    "\n",
    "logger.info(\"üìÅ Random noise sweep results saved to 'results/random_noise_sweep_up_to_1.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c89693e",
   "metadata": {},
   "source": [
    "## Logit Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e25742af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:22:46 INFO __main__: [LogitBiasMajority] Fraction‚Üíclass_3: 40.00% (bias=8.0)\n",
      "11:22:46 WARNING __main__: [LogitBiasMajority] Fraction below threshold: got 40.00%, expected at least 80.00%\n",
      "11:22:46 INFO __main__: [LogitBiasMajority] Accuracy under attack: 0.7000\n",
      "11:22:46 INFO __main__: [LogitBiasMajority] Weighted F1 Score: 0.6867\n",
      "11:22:46 INFO __main__: [LogitBiasMajority] Prediction distribution: {3: 20, 2: 13, 0: 9, 1: 5, 4: 3}\n",
      "11:22:46 INFO __main__: [LogitBiasMajority] Mapping original‚Üíattacked (FULL): {'3‚Üí3': 8, '2‚Üí2': 11, '4‚Üí3': 7, '2‚Üí3': 3, '0‚Üí0': 9, '1‚Üí1': 5, '4‚Üí4': 2, '4‚Üí2': 2, '1‚Üí3': 2, '2‚Üí4': 1}\n",
      "11:22:46 INFO __main__: [LogitBiasMajority] ONLY to target 3: {'3‚Üí3': 8, '4‚Üí3': 7, '2‚Üí3': 3, '1‚Üí3': 2}\n",
      "11:22:46 INFO __main__: [LogitBiasMajority] Flips to target (from other classes): 12\n",
      "11:22:46 INFO __main__: [LogitBiasMajority] Kept as target (target‚Üítarget): 8\n",
      "11:22:46 INFO __main__: [LogitBiasMajority] Frac of non-target that flipped‚Üítarget: 28.57%\n",
      "11:22:46 INFO __main__: [LogitBiasMajority] Overall frac predicted as target: 40.00%\n",
      "11:22:46 INFO __main__: [LogitBiasMajority] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         9\n",
      "           1       1.00      0.71      0.83         7\n",
      "           2       0.85      0.73      0.79        15\n",
      "           3       0.40      1.00      0.57         8\n",
      "           4       0.67      0.18      0.29        11\n",
      "\n",
      "    accuracy                           0.70        50\n",
      "   macro avg       0.78      0.73      0.70        50\n",
      "weighted avg       0.78      0.70      0.69        50\n",
      "\n",
      "11:22:46 INFO __main__: Test completed, results: {'target_class': 3, 'bias': 8.0, 'min_frac': 0.8, 'fraction_to_target': 0.4, 'accuracy': 0.7, 'f1_weighted': 0.6866666666666668, 'prediction_distribution': {3: 20, 2: 13, 0: 9, 1: 5, 4: 3}, 'mapping_full': {'3‚Üí3': 8, '2‚Üí2': 11, '4‚Üí3': 7, '2‚Üí3': 3, '0‚Üí0': 9, '1‚Üí1': 5, '4‚Üí4': 2, '4‚Üí2': 2, '1‚Üí3': 2, '2‚Üí4': 1}, 'only_to_target': {'3‚Üí3': 8, '4‚Üí3': 7, '2‚Üí3': 3, '1‚Üí3': 2}, 'flips_to_target': 12, 'kept_as_target': 8, 'frac_flips_from_non_target': 0.2857142857142857, 'frac_all_to_target': 0.4, 'classification_report': '              precision    recall  f1-score   support\\n\\n           0       1.00      1.00      1.00         9\\n           1       1.00      0.71      0.83         7\\n           2       0.85      0.73      0.79        15\\n           3       0.40      1.00      0.57         8\\n           4       0.67      0.18      0.29        11\\n\\n    accuracy                           0.70        50\\n   macro avg       0.78      0.73      0.70        50\\nweighted avg       0.78      0.70      0.69        50\\n', 'attacked_preds': [3, 2, 3, 2, 2, 2, 2, 3, 2, 3, 3, 0, 1, 0, 1, 3, 3, 4, 1, 2, 2, 4, 2, 0, 1, 3, 2, 4, 3, 3, 0, 3, 2, 3, 3, 0, 3, 3, 3, 0, 3, 0, 0, 3, 2, 0, 3, 2, 1, 3]}\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import torch\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# Configure logging to show INFO and above\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s %(levelname)s %(name)s: %(message)s\",\n",
    "    datefmt=\"%H:%M:%S\"\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# ‚Äî Helper de inferencia com√∫n ‚Äî\n",
    "def run_inference(model, sample_df):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    for row in sample_df.itertuples():\n",
    "        input_ids = torch.tensor(row.input_ids).unsqueeze(0).to(model.device)\n",
    "        att_mask  = torch.tensor(row.attention_mask).unsqueeze(0).to(model.device)\n",
    "        with torch.no_grad():\n",
    "            logits = model(input_ids=input_ids, attention_mask=att_mask).logits\n",
    "        preds.append(int(logits.argmax(dim=-1)))\n",
    "    return preds\n",
    "\n",
    "# ==============================\n",
    "# TEST Logit‚ÄêBias Majority Attack con reporte completo\n",
    "# ==============================\n",
    "def test_logit_bias_majority(\n",
    "    model,\n",
    "    sample_df,\n",
    "    labels_list,\n",
    "    target_class: int = 3,\n",
    "    bias: float = 5.0,\n",
    "    min_frac: float = 0.8\n",
    "):\n",
    "    \"\"\"\n",
    "    A√±ade un sesgo al logit de la clase `target_class` y:\n",
    "      ‚Ä¢ Ejecuta inferencia\n",
    "      ‚Ä¢ Mide la fracci√≥n de predicciones forzadas hacia target_class\n",
    "      ‚Ä¢ Calcula accuracy, F1, distribuci√≥n de predicciones\n",
    "      ‚Ä¢ Mapea original‚Üíatacado (completo) y SOLO las transiciones hacia la clase objetivo\n",
    "      ‚Ä¢ Devuelve un dict con todos los resultados (no detiene ejecuci√≥n)\n",
    "    \"\"\"\n",
    "    # 1) Define e instala el hook\n",
    "    def make_logit_bias_hook(target, b):\n",
    "        def hook(module, inp, out):\n",
    "            out.logits[:, target] += b\n",
    "            return out\n",
    "        return hook\n",
    "\n",
    "    handle = model.register_forward_hook(make_logit_bias_hook(target_class, bias))\n",
    "\n",
    "    # 2) Inferencia bajo ataque\n",
    "    attacked = run_inference(model, sample_df)\n",
    "\n",
    "    # 3) Quita el hook\n",
    "    handle.remove()\n",
    "\n",
    "    # 4) Fracci√≥n de muestras clasificadas como target_class\n",
    "    count_to_target = sum(1 for p in attacked if p == target_class)\n",
    "    frac_to_target = count_to_target / len(attacked) if attacked else 0.0\n",
    "    logger.info(f\"[LogitBiasMajority] Fraction‚Üíclass_{target_class}: {frac_to_target:.2%} (bias={bias})\")\n",
    "    if frac_to_target < min_frac:\n",
    "        logger.warning(\n",
    "            f\"[LogitBiasMajority] Fraction below threshold: got {frac_to_target:.2%}, \"\n",
    "            f\"expected at least {min_frac:.2%}\"\n",
    "        )\n",
    "    else:\n",
    "        logger.info(\n",
    "            f\"[LogitBiasMajority] Fraction meets threshold: {frac_to_target:.2%} ‚â• {min_frac:.2%}\"\n",
    "        )\n",
    "\n",
    "    # 5) M√©tricas de rendimiento\n",
    "    accuracy = accuracy_score(labels_list, attacked)\n",
    "    f1w      = f1_score(labels_list, attacked, average='weighted', zero_division=0)\n",
    "    logger.info(f\"[LogitBiasMajority] Accuracy under attack: {accuracy:.4f}\")\n",
    "    logger.info(f\"[LogitBiasMajority] Weighted F1 Score: {f1w:.4f}\")\n",
    "\n",
    "    # 6) Distribuci√≥n de predicciones\n",
    "    dist = dict(Counter(attacked))\n",
    "    logger.info(f\"[LogitBiasMajority] Prediction distribution: {dist}\")\n",
    "\n",
    "    # 7) Mapeo completo: clase original ‚Üí clase atacada\n",
    "    mapping_full = Counter(zip(labels_list, attacked))\n",
    "    mapping_full_str = {f\"{orig}‚Üí{pred}\": cnt for (orig, pred), cnt in mapping_full.items()}\n",
    "    logger.info(f\"[LogitBiasMajority] Mapping original‚Üíattacked (FULL): {mapping_full_str}\")\n",
    "\n",
    "    # 7a) SOLO transiciones que acaban en la clase objetivo (target_class)\n",
    "    to_target_only = {f\"{orig}‚Üí{pred}\": cnt\n",
    "                      for (orig, pred), cnt in mapping_full.items()\n",
    "                      if pred == target_class}\n",
    "    flips_to_target = sum(cnt for (orig, pred), cnt in mapping_full.items()\n",
    "                          if pred == target_class and orig != target_class)\n",
    "    kept_as_target  = mapping_full.get((target_class, target_class), 0)\n",
    "\n",
    "    total_non_target = sum(1 for y in labels_list if y != target_class)\n",
    "    frac_flips_from_non_target = (flips_to_target / total_non_target) if total_non_target else 0.0\n",
    "    frac_all_to_target = (sum(to_target_only.values()) / len(labels_list)) if labels_list else 0.0\n",
    "\n",
    "    logger.info(f\"[LogitBiasMajority] ONLY to target {target_class}: {to_target_only}\")\n",
    "    logger.info(f\"[LogitBiasMajority] Flips to target (from other classes): {flips_to_target}\")\n",
    "    logger.info(f\"[LogitBiasMajority] Kept as target (target‚Üítarget): {kept_as_target}\")\n",
    "    logger.info(f\"[LogitBiasMajority] Frac of non-target that flipped‚Üítarget: {frac_flips_from_non_target:.2%}\")\n",
    "    logger.info(f\"[LogitBiasMajority] Overall frac predicted as target: {frac_all_to_target:.2%}\")\n",
    "\n",
    "    # 8) Classification report completo\n",
    "    report = classification_report(labels_list, attacked, zero_division=0)\n",
    "    logger.info(f\"[LogitBiasMajority] Classification Report:\\n{report}\")\n",
    "\n",
    "    # 9) Devolver detalles para inspecci√≥n adicional\n",
    "    return {\n",
    "        \"target_class\": target_class,\n",
    "        \"bias\": bias,\n",
    "        \"min_frac\": min_frac,\n",
    "        \"fraction_to_target\": frac_to_target,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"f1_weighted\": f1w,\n",
    "        \"prediction_distribution\": dist,\n",
    "        \"mapping_full\": mapping_full_str,\n",
    "        \"only_to_target\": to_target_only,\n",
    "        \"flips_to_target\": flips_to_target,\n",
    "        \"kept_as_target\": kept_as_target,\n",
    "        \"frac_flips_from_non_target\": frac_flips_from_non_target,\n",
    "        \"frac_all_to_target\": frac_all_to_target,\n",
    "        \"classification_report\": report,\n",
    "        \"attacked_preds\": attacked\n",
    "    }\n",
    "# ==============================\n",
    "# Ejecutar el test y almacenar resultados\n",
    "# ==============================\n",
    "results = test_logit_bias_majority(\n",
    "    model=model,\n",
    "    sample_df=sample_df,\n",
    "    labels_list=labels_list,\n",
    "    target_class=3,\n",
    "    bias=8.0,\n",
    "    min_frac=0.8\n",
    ")\n",
    "logger.info(f\"Test completed, results: {results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1243a058",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "11:58:21 INFO __main__: [Baseline Check] Weighted F1-score: 0.8306\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8306384351683807"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_HF, num_labels=NUM_LABELS)\n",
    "\n",
    "# Load trained weights from disk\n",
    "state_dict = torch.load(weights_path, map_location=device)\n",
    "model.load_state_dict(state_dict)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "device = \"cpu\"\n",
    "\n",
    "quick_baseline_f1(model, sample_df, labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7906cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "233534da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:52:07 INFO __main__: [Baseline Check] Weighted F1-score: 0.8306\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8306384351683807"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quick_baseline_f1(model, sample_df, labels_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbc100a",
   "metadata": {},
   "source": [
    "## Gaussian Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f625cbaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:41:57 INFO __main__: [GaussNoise] Injecting œÉ=0.5 into 3686 neurons (40%)\n",
      "11:44:36 INFO __main__: [GaussNoise] 2 changes (4.00% of samples)\n",
      "11:44:36 INFO __main__: [GaussNoise] Accuracy under attack: 0.8800\n",
      "11:44:36 INFO __main__: [GaussNoise] Weighted F1 Score: 0.8750\n",
      "11:44:36 INFO __main__: [GaussNoise] Prediction distribution: {3: 10, 2: 15, 4: 8, 1: 8, 0: 9}\n",
      "11:44:36 INFO __main__: [GaussNoise] Mapping original‚Üíattacked: {'3‚Üí3': 8, '2‚Üí2': 13, '4‚Üí4': 7, '2‚Üí1': 1, '0‚Üí0': 9, '1‚Üí1': 7, '4‚Üí2': 2, '2‚Üí4': 1, '4‚Üí3': 2}\n",
      "11:44:36 INFO __main__: [GaussNoise] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         9\n",
      "           1       0.88      1.00      0.93         7\n",
      "           2       0.87      0.87      0.87        15\n",
      "           3       0.80      1.00      0.89         8\n",
      "           4       0.88      0.64      0.74        11\n",
      "\n",
      "    accuracy                           0.88        50\n",
      "   macro avg       0.88      0.90      0.89        50\n",
      "weighted avg       0.88      0.88      0.87        50\n",
      "\n",
      "11:44:36 INFO __main__: Gaussian Noise test results: {'num_changes': 2, 'frac_changed': 0.04, 'accuracy': 0.88, 'f1_weighted': 0.8749941520467837, 'prediction_distribution': {3: 10, 2: 15, 4: 8, 1: 8, 0: 9}, 'original_to_attacked_mapping': {'3‚Üí3': 8, '2‚Üí2': 13, '4‚Üí4': 7, '2‚Üí1': 1, '0‚Üí0': 9, '1‚Üí1': 7, '4‚Üí2': 2, '2‚Üí4': 1, '4‚Üí3': 2}, 'classification_report': '              precision    recall  f1-score   support\\n\\n           0       1.00      1.00      1.00         9\\n           1       0.88      1.00      0.93         7\\n           2       0.87      0.87      0.87        15\\n           3       0.80      1.00      0.89         8\\n           4       0.88      0.64      0.74        11\\n\\n    accuracy                           0.88        50\\n   macro avg       0.88      0.90      0.89        50\\nweighted avg       0.88      0.88      0.87        50\\n', 'attacked_preds': [3, 2, 3, 2, 2, 2, 2, 4, 2, 1, 2, 0, 1, 0, 1, 2, 4, 4, 1, 2, 2, 4, 2, 0, 1, 1, 2, 4, 3, 3, 0, 3, 2, 4, 4, 0, 3, 3, 3, 0, 1, 0, 0, 4, 2, 0, 3, 2, 1, 3]}\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import torch\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# (Re)configura logging si es necesario\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s %(levelname)s %(name)s: %(message)s\",\n",
    "    datefmt=\"%H:%M:%S\"\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# ‚Äî Helper de inferencia com√∫n ‚Äî\n",
    "def run_inference(model, sample_df):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    for row in sample_df.itertuples():\n",
    "        input_ids = torch.tensor(row.input_ids).unsqueeze(0).to(model.device)\n",
    "        att_mask  = torch.tensor(row.attention_mask).unsqueeze(0).to(model.device)\n",
    "        with torch.no_grad():\n",
    "            logits = model(input_ids=input_ids, attention_mask=att_mask).logits\n",
    "        preds.append(int(logits.argmax(dim=-1)))\n",
    "    return preds\n",
    "\n",
    "# ==============================\n",
    "# TEST Gaussian‚ÄêNoise Attack con reporte completo\n",
    "# ==============================\n",
    "def test_gaussian_noise_detailed(\n",
    "    model,\n",
    "    sample_df,\n",
    "    labels_list,\n",
    "    probe,\n",
    "    percentage: float = 0.10,\n",
    "    sigma: float = 0.2\n",
    "):\n",
    "    \"\"\"\n",
    "    Inyecta ruido Gaussiano en las top‚Äêk neuronas del CLS token y:\n",
    "      ‚Ä¢ Ejecuta inferencia\n",
    "      ‚Ä¢ Mide cu√°ntas predicciones cambiaron (y su fracci√≥n)\n",
    "      ‚Ä¢ Calcula accuracy, F1, distribuci√≥n de predicciones,\n",
    "        mapeo original‚Üíatacado y classification report completo\n",
    "      ‚Ä¢ Informa todo v√≠a logger.info / logger.warning\n",
    "    \"\"\"\n",
    "    hidden = model.config.hidden_size\n",
    "    num_layers = model.config.num_hidden_layers\n",
    "\n",
    "    # 1) Selecci√≥n de top‚Äêk neuronas\n",
    "    topk = get_top_k_neurons_exact(probe, percentage=percentage)\n",
    "    logger.info(f\"[GaussNoise] Injecting œÉ={sigma} into {len(topk)} neurons ({percentage:.0%})\")\n",
    "\n",
    "    # 2) Hook maker\n",
    "    def make_noise_hook(indices, œÉ):\n",
    "        idxs = torch.tensor(indices, dtype=torch.long)\n",
    "        def hook(module, inp, out):\n",
    "            if out.dim()==3 and idxs.numel()>0:\n",
    "                o = out.clone()\n",
    "                cls = o[:, 0, :]\n",
    "                noise = torch.randn_like(cls[:, idxs]) * œÉ\n",
    "                cls[:, idxs] += noise.to(o.device)\n",
    "                o[:, 0, :] = cls\n",
    "                return o\n",
    "            return out\n",
    "        return hook\n",
    "\n",
    "    # 3) Registrar hooks por capa\n",
    "    handles = []\n",
    "    enc_layers = get_encoder_layers(model)\n",
    "    for l in range(num_layers):\n",
    "        local = [i - l*hidden for i in topk if l*hidden <= i < (l+1)*hidden]\n",
    "        if not local:\n",
    "            continue\n",
    "        handles.append(\n",
    "            enc_layers[l].output.register_forward_hook(make_noise_hook(local, sigma))\n",
    "        )\n",
    "\n",
    "    # 4) Inferencia baseline y bajo ruido\n",
    "    baseline = run_inference(model, sample_df)\n",
    "    attacked = run_inference(model, sample_df)\n",
    "\n",
    "    # 5) Limpieza de hooks\n",
    "    for h in handles:\n",
    "        h.remove()\n",
    "\n",
    "    # 6) Cu√°ntas predicciones cambiaron\n",
    "    diff = sum(1 for b, a in zip(baseline, attacked) if b != a)\n",
    "    frac_changed = diff / len(baseline)\n",
    "    if diff == 0:\n",
    "        logger.warning(f\"[GaussNoise] NO changes detected at œÉ={sigma}, {percentage:.0%}\")\n",
    "    else:\n",
    "        logger.info(f\"[GaussNoise] {diff} changes ({frac_changed:.2%} of samples)\")\n",
    "\n",
    "    # 7) M√©tricas de rendimiento\n",
    "    accuracy = accuracy_score(labels_list, attacked)\n",
    "    f1w      = f1_score(labels_list, attacked, average='weighted')\n",
    "    logger.info(f\"[GaussNoise] Accuracy under attack: {accuracy:.4f}\")\n",
    "    logger.info(f\"[GaussNoise] Weighted F1 Score: {f1w:.4f}\")\n",
    "\n",
    "    # 8) Distribuci√≥n de predicciones\n",
    "    dist = dict(Counter(attacked))\n",
    "    logger.info(f\"[GaussNoise] Prediction distribution: {dist}\")\n",
    "\n",
    "    # 9) Mapeo clase original ‚Üí clase atacada\n",
    "    mapping = Counter(zip(labels_list, attacked))\n",
    "    mapping_str = {f\"{orig}‚Üí{pred}\": cnt for (orig, pred), cnt in mapping.items()}\n",
    "    logger.info(f\"[GaussNoise] Mapping original‚Üíattacked: {mapping_str}\")\n",
    "\n",
    "    # 10) Classification report completo\n",
    "    report = classification_report(labels_list, attacked, zero_division=0)\n",
    "    logger.info(f\"[GaussNoise] Classification Report:\\n{report}\")\n",
    "\n",
    "    # 11) Devolver resultados\n",
    "    return {\n",
    "        \"num_changes\": diff,\n",
    "        \"frac_changed\": frac_changed,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"f1_weighted\": f1w,\n",
    "        \"prediction_distribution\": dist,\n",
    "        \"original_to_attacked_mapping\": mapping_str,\n",
    "        \"classification_report\": report,\n",
    "        \"attacked_preds\": attacked\n",
    "    }\n",
    "\n",
    "# ==============================\n",
    "# Ejecutar el test\n",
    "# ==============================\n",
    "results_noise = test_gaussian_noise_detailed(\n",
    "    model=model,\n",
    "    sample_df=sample_df,\n",
    "    labels_list=labels_list,\n",
    "    probe=probe,\n",
    "    percentage=0.40,\n",
    "    sigma=0.5\n",
    ")\n",
    "logger.info(f\"Gaussian Noise test results: {results_noise}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c9a2dcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# ‚Äî Utilidad: localizar la capa lineal de clasificaci√≥n en distintas arquitecturas ‚Äî\n",
    "def get_classifier_linear(model):\n",
    "    \"\"\"\n",
    "    Devuelve el m√≥dulo lineal final (con .weight y .bias):\n",
    "    - BERT/RoBERTa/DistilBERT: model.classifier (nn.Linear)\n",
    "    - BigBird: model.classifier.out_proj\n",
    "    - Otros: model.score (si existe)\n",
    "    \"\"\"\n",
    "    if hasattr(model, \"classifier\"):\n",
    "        clf = model.classifier\n",
    "        if hasattr(clf, \"out_proj\"):  # BigBirdClassificationHead\n",
    "            return clf.out_proj\n",
    "        if hasattr(clf, \"weight\") and hasattr(clf, \"bias\"):\n",
    "            return clf\n",
    "    if hasattr(model, \"score\"):  # algunos heads usan \"score\"\n",
    "        return model.score\n",
    "    raise NotImplementedError(\"‚ùå No se encontr√≥ capa lineal de clasificaci√≥n compatible.\")\n",
    "\n",
    "# ‚Äî Inference helper (ya lo usas) ‚Äî\n",
    "def run_inference(model, sample_df):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    for row in sample_df.itertuples():\n",
    "        input_ids = torch.tensor(row.input_ids).unsqueeze(0).to(model.device)\n",
    "        att_mask  = torch.tensor(row.attention_mask).unsqueeze(0).to(model.device)\n",
    "        with torch.no_grad():\n",
    "            logits = model(input_ids=input_ids, attention_mask=att_mask).logits\n",
    "        preds.append(int(logits.argmax(dim=-1)))\n",
    "    return preds\n",
    "\n",
    "# ==============================\n",
    "# ‚öôÔ∏è  WEIGHT ATTACK (Fault-Sneak dirigido, con restore)\n",
    "# ==============================\n",
    "def test_weight_attack_targeted(\n",
    "    model,\n",
    "    sample_df,\n",
    "    labels_list,\n",
    "    probe,\n",
    "    target_class: int,\n",
    "    percentage: float = 0.10,\n",
    "    delta_scale: float = 0.05,\n",
    "    balanced_push: bool = True  # empuja + a la clase objetivo y - (peque√±o) al resto\n",
    "):\n",
    "    \"\"\"\n",
    "    Modifica temporalmente los PESOS de la capa de clasificaci√≥n (W: [num_labels, hidden])\n",
    "    en las columnas asociadas a las neuronas top-k (seg√∫n el probe), para favorecer\n",
    "    la 'target_class'. Restaura al final (no deja el modelo contaminado).\n",
    "    \"\"\"\n",
    "    # --- Selecci√≥n de neuronas top-k y mapeo a columnas del clasificador ---\n",
    "    hidden = model.config.hidden_size\n",
    "    num_layers = model.config.num_hidden_layers\n",
    "    topk_global = get_top_k_neurons_exact(probe, percentage=percentage)\n",
    "\n",
    "    # Mapeamos √≠ndices globales (capa*largo + neurona) a columnas locales de la √∫ltima capa\n",
    "    # Truco pr√°ctico: columna = idx % hidden  (columna del vector [CLS] que alimenta a la head)\n",
    "    cols = sorted({ g % hidden for g in topk_global })\n",
    "    if len(cols) == 0:\n",
    "        logger.warning(\"[WeightAttack] No hay columnas seleccionadas; abortando.\")\n",
    "        return None\n",
    "\n",
    "    clf = get_classifier_linear(model)\n",
    "    W = clf.weight            # [C, H]\n",
    "    b = clf.bias              # [C] (puede ser None)\n",
    "    C, H = W.shape\n",
    "\n",
    "    logger.info(\n",
    "        f\"[WeightAttack] Target class={target_class}, top-k={len(cols)} cols, \"\n",
    "        f\"delta_scale={delta_scale}, balanced_push={balanced_push}\"\n",
    "    )\n",
    "\n",
    "    # --- Backup de pesos (y bias) ---\n",
    "    W_orig = W.data.clone()\n",
    "    b_orig = b.data.clone() if b is not None else None\n",
    "\n",
    "    # --- Construcci√≥n de ŒîW (solo columnas seleccionadas) ---\n",
    "    delta = torch.zeros_like(W.data)  # [C, H]\n",
    "    # Empuja a favor de la clase objetivo en esas columnas\n",
    "    delta[target_class, cols] += delta_scale\n",
    "\n",
    "    if balanced_push and C > 1:\n",
    "        # Para mantener efecto \"sigiloso\", empuj√≥n negativo suave al resto de clases\n",
    "        neg = (-delta_scale) / (C - 1)\n",
    "        mask_other = torch.ones(C, dtype=torch.bool, device=W.device)\n",
    "        mask_other[target_class] = False\n",
    "        delta[mask_other][:, cols] += neg\n",
    "\n",
    "    # --- Aplicar Œî (ataque de PESOS) ---\n",
    "    W.data.add_(delta.to(W.device))\n",
    "\n",
    "    # --- Inferencia atacada ---\n",
    "    attacked = run_inference(model, sample_df)\n",
    "\n",
    "    # --- Restaurar pesos (y bias si procede) ---\n",
    "    W.data.copy_(W_orig)\n",
    "    if b is not None and b_orig is not None:\n",
    "        b.data.copy_(b_orig)\n",
    "\n",
    "    # ===============================\n",
    "    # üìä Evaluaci√≥n y reportes\n",
    "    # ===============================\n",
    "    accuracy = accuracy_score(labels_list, attacked)\n",
    "    f1w      = f1_score(labels_list, attacked, average='weighted', zero_division=0)\n",
    "    logger.info(f\"[WeightAttack] Accuracy under attack: {accuracy:.4f}\")\n",
    "    logger.info(f\"[WeightAttack] Weighted F1 Score: {f1w:.4f}\")\n",
    "\n",
    "    # Distribuci√≥n de predicciones\n",
    "    dist = dict(Counter(attacked))\n",
    "    logger.info(f\"[WeightAttack] Prediction distribution: {dist}\")\n",
    "\n",
    "    # Mapeo original ‚Üí atacado (completo)\n",
    "    mapping = Counter(zip(labels_list, attacked))\n",
    "    mapping_full_str = {f\"{orig}‚Üí{pred}\": cnt for (orig, pred), cnt in mapping.items()}\n",
    "    logger.info(f\"[WeightAttack] Mapping original‚Üíattacked (FULL): {mapping_full_str}\")\n",
    "\n",
    "    # Solo transiciones hacia la clase objetivo\n",
    "    to_target_only = {f\"{orig}‚Üí{pred}\": cnt\n",
    "                      for (orig, pred), cnt in mapping.items()\n",
    "                      if pred == target_class}\n",
    "    flips_to_target = sum(cnt for (orig, pred), cnt in mapping.items()\n",
    "                          if pred == target_class and orig != target_class)\n",
    "    kept_as_target  = mapping.get((target_class, target_class), 0)\n",
    "\n",
    "    total_non_target = sum(1 for y in labels_list if y != target_class)\n",
    "    frac_flips_from_non_target = (flips_to_target / total_non_target) if total_non_target else 0.0\n",
    "    frac_all_to_target = (sum(to_target_only.values()) / len(labels_list)) if labels_list else 0.0\n",
    "\n",
    "    logger.info(f\"[WeightAttack] ONLY to target {target_class}: {to_target_only}\")\n",
    "    logger.info(f\"[WeightAttack] Flips‚Üítarget (from other classes): {flips_to_target}\")\n",
    "    logger.info(f\"[WeightAttack] Kept as target (target‚Üítarget): {kept_as_target}\")\n",
    "    logger.info(f\"[WeightAttack] Frac non-target that flipped‚Üítarget: {frac_flips_from_non_target:.2%}\")\n",
    "    logger.info(f\"[WeightAttack] Overall frac predicted as target: {frac_all_to_target:.2%}\")\n",
    "\n",
    "    # Classification report\n",
    "    report = classification_report(labels_list, attacked, zero_division=0)\n",
    "    logger.info(f\"[WeightAttack] Classification Report:\\n{report}\")\n",
    "\n",
    "    return {\n",
    "        \"target_class\": target_class,\n",
    "        \"percentage_neurons\": percentage,\n",
    "        \"delta_scale\": delta_scale,\n",
    "        \"balanced_push\": balanced_push,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"f1_weighted\": f1w,\n",
    "        \"prediction_distribution\": dist,\n",
    "        \"mapping_full\": mapping_full_str,\n",
    "        \"only_to_target\": to_target_only,\n",
    "        \"flips_to_target\": flips_to_target,\n",
    "        \"kept_as_target\": kept_as_target,\n",
    "        \"frac_flips_from_non_target\": frac_flips_from_non_target,\n",
    "        \"frac_all_to_target\": frac_all_to_target,\n",
    "        \"classification_report\": report,\n",
    "        \"attacked_preds\": attacked,\n",
    "        \"used_columns\": cols\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7853785",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102690ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:51:30 INFO __main__: [WeightAttack] Target class=3, top-k=593 cols, delta_scale=0.05, balanced_push=True\n",
      "11:52:48 INFO __main__: [WeightAttack] Accuracy under attack: 0.7800\n",
      "11:52:48 INFO __main__: [WeightAttack] Weighted F1 Score: 0.7578\n",
      "11:52:48 INFO __main__: [WeightAttack] Prediction distribution: {3: 14, 2: 14, 4: 5, 1: 8, 0: 9}\n",
      "11:52:48 INFO __main__: [WeightAttack] Mapping original‚Üíattacked (FULL): {'3‚Üí3': 8, '2‚Üí2': 12, '4‚Üí4': 3, '2‚Üí1': 1, '2‚Üí4': 2, '0‚Üí0': 9, '1‚Üí1': 7, '4‚Üí3': 6, '4‚Üí2': 2}\n",
      "11:52:48 INFO __main__: [WeightAttack] ONLY to target 3: {'3‚Üí3': 8, '4‚Üí3': 6}\n",
      "11:52:48 INFO __main__: [WeightAttack] Flips‚Üítarget (from other classes): 6\n",
      "11:52:48 INFO __main__: [WeightAttack] Kept as target (target‚Üítarget): 8\n",
      "11:52:48 INFO __main__: [WeightAttack] Frac non-target that flipped‚Üítarget: 14.29%\n",
      "11:52:48 INFO __main__: [WeightAttack] Overall frac predicted as target: 28.00%\n",
      "11:52:48 INFO __main__: [WeightAttack] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         9\n",
      "           1       0.88      1.00      0.93         7\n",
      "           2       0.86      0.80      0.83        15\n",
      "           3       0.57      1.00      0.73         8\n",
      "           4       0.60      0.27      0.38        11\n",
      "\n",
      "    accuracy                           0.78        50\n",
      "   macro avg       0.78      0.81      0.77        50\n",
      "weighted avg       0.78      0.78      0.76        50\n",
      "\n",
      "11:52:48 INFO __main__: Weight attack results: {'target_class': 3, 'percentage_neurons': 0.1, 'delta_scale': 0.05, 'balanced_push': True, 'accuracy': 0.78, 'f1_weighted': 0.7578061650992686, 'prediction_distribution': {3: 14, 2: 14, 4: 5, 1: 8, 0: 9}, 'mapping_full': {'3‚Üí3': 8, '2‚Üí2': 12, '4‚Üí4': 3, '2‚Üí1': 1, '2‚Üí4': 2, '0‚Üí0': 9, '1‚Üí1': 7, '4‚Üí3': 6, '4‚Üí2': 2}, 'only_to_target': {'3‚Üí3': 8, '4‚Üí3': 6}, 'flips_to_target': 6, 'kept_as_target': 8, 'frac_flips_from_non_target': 0.14285714285714285, 'frac_all_to_target': 0.28, 'classification_report': '              precision    recall  f1-score   support\\n\\n           0       1.00      1.00      1.00         9\\n           1       0.88      1.00      0.93         7\\n           2       0.86      0.80      0.83        15\\n           3       0.57      1.00      0.73         8\\n           4       0.60      0.27      0.38        11\\n\\n    accuracy                           0.78        50\\n   macro avg       0.78      0.81      0.77        50\\nweighted avg       0.78      0.78      0.76        50\\n', 'attacked_preds': [3, 2, 3, 2, 2, 2, 2, 4, 2, 1, 4, 0, 1, 0, 1, 2, 4, 3, 1, 2, 2, 3, 2, 0, 1, 1, 2, 4, 3, 3, 0, 3, 2, 4, 3, 0, 3, 3, 3, 0, 1, 0, 0, 3, 2, 0, 3, 2, 1, 3], 'used_columns': [1, 3, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 18, 19, 20, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 42, 44, 46, 47, 48, 49, 52, 53, 54, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 74, 75, 78, 79, 80, 82, 83, 84, 86, 87, 89, 90, 91, 92, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 116, 117, 118, 119, 122, 123, 124, 125, 126, 127, 128, 130, 131, 133, 134, 135, 136, 137, 138, 139, 140, 141, 143, 144, 145, 146, 148, 149, 150, 153, 154, 155, 156, 157, 159, 161, 164, 166, 168, 169, 170, 172, 173, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 206, 207, 208, 209, 210, 211, 214, 215, 216, 218, 219, 221, 222, 223, 224, 225, 227, 228, 229, 230, 231, 232, 233, 234, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 251, 252, 253, 254, 255, 258, 259, 260, 261, 262, 263, 264, 267, 268, 270, 272, 273, 274, 275, 276, 277, 278, 281, 282, 283, 284, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 297, 298, 302, 304, 305, 306, 307, 311, 312, 313, 314, 315, 316, 318, 320, 321, 323, 325, 326, 327, 328, 331, 332, 333, 334, 335, 337, 338, 339, 340, 341, 342, 343, 345, 347, 348, 349, 350, 351, 352, 354, 355, 356, 357, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 382, 383, 384, 390, 391, 392, 393, 394, 395, 396, 397, 398, 400, 401, 403, 406, 408, 409, 411, 413, 414, 415, 416, 417, 418, 420, 421, 422, 423, 424, 425, 428, 429, 430, 431, 432, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 450, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 467, 470, 471, 472, 473, 475, 476, 477, 478, 479, 481, 482, 483, 485, 487, 488, 489, 490, 491, 493, 494, 495, 497, 498, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 513, 514, 515, 516, 518, 519, 521, 523, 525, 526, 527, 528, 529, 530, 531, 532, 534, 536, 537, 539, 540, 542, 543, 544, 545, 546, 549, 550, 552, 553, 554, 556, 557, 558, 560, 562, 564, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 584, 587, 590, 592, 593, 595, 596, 598, 599, 600, 602, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 615, 616, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 631, 632, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 654, 655, 656, 657, 659, 660, 661, 662, 663, 664, 666, 668, 669, 670, 671, 673, 675, 677, 678, 680, 681, 682, 683, 684, 686, 688, 689, 691, 693, 694, 695, 696, 697, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 714, 715, 716, 718, 719, 721, 723, 724, 725, 726, 727, 728, 730, 731, 732, 733, 734, 737, 738, 739, 740, 741, 743, 744, 745, 746, 747, 749, 750, 751, 752, 753, 754, 755, 757, 758, 759, 760, 761, 762, 763, 765, 766]}\n"
     ]
    }
   ],
   "source": [
    "results_weight = test_weight_attack_targeted(\n",
    "    model=model,\n",
    "    sample_df=sample_df,\n",
    "    labels_list=labels_list,\n",
    "    probe=probe,\n",
    "    target_class=3,      # objetivo \n",
    "    percentage=0.10,     # top-k neuronas (global ‚Üí columnas √∫nicas)\n",
    "    delta_scale=0.05,    # intensidad del empuj√≥n en pesos\n",
    "    balanced_push=True   # empuja + a target y - (suave) al resto\n",
    ")\n",
    "logger.info(f\"Weight attack results: {results_weight}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaa0ab6",
   "metadata": {},
   "source": [
    "## Global Noise Injection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc8b18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# Par√°metros\n",
    "PERCENTAGE  = 0.10\n",
    "SIGMA       = 0.1\n",
    "REPORT_PATH = os.path.join(BASE_PATH, \"results\", f\"global_noise_{int(PERCENTAGE*100)}p.csv\")\n",
    "\n",
    "# Seleccionar top‚Äêk\n",
    "top_neurons = get_top_k_neurons_exact(probe, percentage=PERCENTAGE)\n",
    "os.makedirs(f\"{BASE_PATH}/neurons\", exist_ok=True)\n",
    "with open(f\"{BASE_PATH}/neurons/top_{int(PERCENTAGE*100)}p_global_noise.json\", \"w\") as f:\n",
    "    json.dump(top_neurons, f, indent=2)\n",
    "\n",
    "# Hook maker\n",
    "def make_partial_noise_hook(indices, sigma):\n",
    "    idxs = torch.tensor(indices, dtype=torch.long)\n",
    "    def hook(module, inp, out):\n",
    "        if out.dim()==3 and idxs.numel()>0:\n",
    "            o = out.clone()\n",
    "            vals = o[:,:,idxs]             # (b, seq_len, |idxs|)\n",
    "            o[:,:,idxs] = vals + torch.randn_like(vals)*sigma\n",
    "            return o\n",
    "        return out\n",
    "    return hook\n",
    "\n",
    "# Registrar\n",
    "handles = []\n",
    "for layer_idx, layer in enumerate(get_encoder_layers(model)):\n",
    "    local = [i - layer_idx*model.config.hidden_size for i in top_neurons\n",
    "             if layer_idx*model.config.hidden_size <= i < (layer_idx+1)*model.config.hidden_size]\n",
    "    if not local: continue\n",
    "    handles.append(\n",
    "        layer.output.register_forward_hook(make_partial_noise_hook(local, SIGMA))\n",
    "    )\n",
    "\n",
    "# Inferencia\n",
    "model.eval()\n",
    "predictions_gnoise = []\n",
    "for row in sample_df.itertuples():\n",
    "    input_ids = torch.tensor(row.input_ids).unsqueeze(0).to(model.device)\n",
    "    att_mask  = torch.tensor(row.attention_mask).unsqueeze(0).to(model.device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_ids=input_ids, attention_mask=att_mask).logits\n",
    "    predictions_gnoise.append(int(logits.argmax(dim=-1)))\n",
    "\n",
    "# ===============================\n",
    "# üìä Evaluation\n",
    "# ===============================\n",
    "accuracy = accuracy_score(labels_list, predictions_gnoise)\n",
    "f1       = f1_score(labels_list, predictions_gnoise, average='weighted')\n",
    "report_dict = classification_report(labels_list, predictions_gnoise, output_dict=True, zero_division=0)\n",
    "report_df   = pd.DataFrame(report_dict).transpose().round(4).drop(\"accuracy\", errors=\"ignore\")\n",
    "\n",
    "accuracy_row = pd.DataFrame({\n",
    "    'precision': [\"\"],\n",
    "    'recall':    [\"\"],\n",
    "    'f1-score':  [accuracy],\n",
    "    'support':   [report_df[\"support\"].sum()]\n",
    "}, index=[\"overall_accuracy\"])\n",
    "final_df = pd.concat([report_df, accuracy_row])\n",
    "\n",
    "# ===============================\n",
    "# üíæ Save report\n",
    "# ===============================\n",
    "experiment_title = f\"Partial Global Noise ({PERCENTAGE:.0%} top neurons, œÉ={SIGMA})\"\n",
    "os.makedirs(os.path.dirname(REPORT_PATH), exist_ok=True)\n",
    "mode = \"w\" if not os.path.exists(REPORT_PATH) else \"a\"\n",
    "with open(REPORT_PATH, mode) as f:\n",
    "    if mode == \"w\":\n",
    "        f.write(f\"# {experiment_title}\\n\")\n",
    "    else:\n",
    "        f.write(f\"\\n\\n# {experiment_title}\\n\")\n",
    "    final_df.to_csv(f)\n",
    "\n",
    "logger.info(f\"üéØ Accuracy under Partial Global Noise: {accuracy:.4f}\")\n",
    "logger.info(f\"üìè Weighted F1 Score: {f1:.4f}\")\n",
    "logger.info(f\"üìã Classification report saved to {REPORT_PATH}\")\n",
    "\n",
    "# Cleanup\n",
    "for h in handles:\n",
    "    h.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e86a5f2",
   "metadata": {},
   "source": [
    "## Fault Sneaking (sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d586ac78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, torch, pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# Par√°metros\n",
    "PERCENTAGE  = 0.10\n",
    "DELTA_SCALE = 0.05\n",
    "REPORT_PATH = os.path.join(BASE_PATH, \"results\", f\"fault_sneak_{int(PERCENTAGE*100)}p.csv\")\n",
    "\n",
    "# 1) Selecci√≥n top‚Äêk\n",
    "top_neurons = get_top_k_neurons_exact(probe, percentage=PERCENTAGE)\n",
    "os.makedirs(f\"{BASE_PATH}/neurons\", exist_ok=True)\n",
    "with open(f\"{BASE_PATH}/neurons/top_{int(PERCENTAGE*100)}p_fault.json\", \"w\") as f:\n",
    "    json.dump(top_neurons, f, indent=2)\n",
    "\n",
    "# 2) Construir delta sobre out_proj\n",
    "hidden = model.config.hidden_size\n",
    "# out_proj: Linear(hidden, num_labels)\n",
    "out_proj = model.classifier.out_proj  \n",
    "delta = torch.zeros_like(out_proj.weight.data)\n",
    "for g in top_neurons:\n",
    "    idx = g % hidden\n",
    "    # para cada clase (fila), a√±adimos ruido peque√±o en la columna idx\n",
    "    delta[:, idx] = torch.randn(delta.shape[0]) * DELTA_SCALE\n",
    "\n",
    "# 3) Hook pre‚Äêforward sobre out_proj\n",
    "def make_fault_hook(delta_tensor):\n",
    "    def hook(module, inp):\n",
    "        module.weight.data += delta_tensor.to(module.weight.device)\n",
    "    return hook\n",
    "\n",
    "handle = out_proj.register_forward_pre_hook(make_fault_hook(delta))\n",
    "\n",
    "# 4) Inferencia\n",
    "model.eval()\n",
    "predictions_fault = []\n",
    "for row in sample_df.itertuples():\n",
    "    input_ids = torch.tensor(row.input_ids).unsqueeze(0).to(model.device)\n",
    "    att_mask  = torch.tensor(row.attention_mask).unsqueeze(0).to(model.device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_ids=input_ids, attention_mask=att_mask).logits\n",
    "    predictions_fault.append(int(logits.argmax(dim=-1)))\n",
    "\n",
    "# ===============================\n",
    "# üìä Evaluation\n",
    "# ===============================\n",
    "accuracy = accuracy_score(labels_list, predictions_fault)\n",
    "f1       = f1_score(labels_list, predictions_fault, average='weighted')\n",
    "report_dict = classification_report(labels_list, predictions_fault, output_dict=True, zero_division=0)\n",
    "report_df   = pd.DataFrame(report_dict).transpose().round(4).drop(\"accuracy\", errors=\"ignore\")\n",
    "\n",
    "accuracy_row = pd.DataFrame({\n",
    "    'precision': [\"\"],\n",
    "    'recall':    [\"\"],\n",
    "    'f1-score':  [accuracy],\n",
    "    'support':   [report_df[\"support\"].sum()]\n",
    "}, index=[\"overall_accuracy\"])\n",
    "final_df = pd.concat([report_df, accuracy_row])\n",
    "\n",
    "# ===============================\n",
    "# üíæ Save report\n",
    "# ===============================\n",
    "experiment_title = f\"Fault Sneaking ({PERCENTAGE:.0%} top neurons, scale={DELTA_SCALE})\"\n",
    "os.makedirs(os.path.dirname(REPORT_PATH), exist_ok=True)\n",
    "mode = \"w\" if not os.path.exists(REPORT_PATH) else \"a\"\n",
    "with open(REPORT_PATH, mode) as f:\n",
    "    if mode == \"w\":\n",
    "        f.write(f\"# {experiment_title}\\n\")\n",
    "    else:\n",
    "        f.write(f\"\\n\\n# {experiment_title}\\n\")\n",
    "    final_df.to_csv(f)\n",
    "\n",
    "logger.info(f\"üéØ Accuracy under Fault Sneaking: {accuracy:.4f}\")\n",
    "logger.info(f\"üìè Weighted F1 Score: {f1:.4f}\")\n",
    "logger.info(f\"üìã Classification report saved to {REPORT_PATH}\")\n",
    "\n",
    "# 5) Cleanup\n",
    "handle.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d903c365",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171e781c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# ‚Äî Helper de inferencia com√∫n ‚Äî\n",
    "def run_inference(model, sample_df):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    for row in sample_df.itertuples():\n",
    "        input_ids = torch.tensor(row.input_ids).unsqueeze(0).to(model.device)\n",
    "        att_mask  = torch.tensor(row.attention_mask).unsqueeze(0).to(model.device)\n",
    "        with torch.no_grad():\n",
    "            logits = model(input_ids=input_ids, attention_mask=att_mask).logits\n",
    "        preds.append(int(logits.argmax(dim=-1)))\n",
    "    return preds\n",
    "\n",
    "# ==============================\n",
    "# 1) TEST Logit‚ÄêBias Majority Attack (sin cortar ejecuci√≥n)\n",
    "# ==============================\n",
    "def test_logit_bias_majority(\n",
    "    model,\n",
    "    sample_df,\n",
    "    labels_list,\n",
    "    target_class: int = 3,\n",
    "    bias: float = 5.0,\n",
    "    min_frac: float = 0.8\n",
    "):\n",
    "    # instalar hook\n",
    "    def hook(m, inp, out):\n",
    "        out.logits[:, target_class] += bias\n",
    "        return out\n",
    "    handle = model.register_forward_hook(hook)\n",
    "\n",
    "    # inferencia\n",
    "    attacked = run_inference(model, sample_df)\n",
    "    handle.remove()\n",
    "\n",
    "    # comprobaci√≥n\n",
    "    count_target = sum(1 for p in attacked if p == target_class)\n",
    "    frac = count_target / len(attacked)\n",
    "    expected = f\">= {min_frac:.0%} to class {target_class}\"\n",
    "    actual = f\"{frac:.0%} to class {target_class}\"\n",
    "    if frac < min_frac:\n",
    "        logger.error(f\"[LogitBiasMajority] FAILURE: expected {expected}, got {actual}\")\n",
    "    else:\n",
    "        logger.info(f\"[LogitBiasMajority] SUCCESS: {actual} (bias={bias})\")\n",
    "\n",
    "    # m√©tricas\n",
    "    acc = accuracy_score(labels_list, attacked)\n",
    "    logger.info(f\"[LogitBiasMajority] Accuracy under attack: {acc:.4f}\")\n",
    "    # opcional: devolver attacked para inspecci√≥n\n",
    "    return attacked\n",
    "\n",
    "# ==============================\n",
    "# 2) TEST Gaussian Noise en top‚Äêk (sin cortar ejecuci√≥n)\n",
    "# ==============================\n",
    "def test_gaussian_noise(\n",
    "    model,\n",
    "    sample_df,\n",
    "    labels_list,\n",
    "    probe,\n",
    "    percentage: float = 0.1,\n",
    "    sigma: float = 0.2\n",
    "):\n",
    "    # baseline y atacada\n",
    "    baseline = run_inference(model, sample_df)\n",
    "    topk = get_top_k_neurons_exact(probe, percentage=percentage)\n",
    "\n",
    "    # instalar hooks\n",
    "    def make_noise(idx_list, œÉ):\n",
    "        idxs = torch.tensor(idx_list, dtype=torch.long)\n",
    "        def hook(m, inp, out):\n",
    "            if out.dim()==3 and idxs.numel()>0:\n",
    "                o = out.clone()\n",
    "                cls = o[:,0,:]\n",
    "                cls[:, idxs] += torch.randn_like(cls[:, idxs]) * œÉ\n",
    "                o[:,0,:] = cls\n",
    "                return o\n",
    "            return out\n",
    "        return hook\n",
    "\n",
    "    handles = []\n",
    "    for i, layer in enumerate(get_encoder_layers(model)):\n",
    "        local = [g - i*model.config.hidden_size for g in topk\n",
    "                 if i*model.config.hidden_size <= g < (i+1)*model.config.hidden_size]\n",
    "        if not local: continue\n",
    "        handles.append(layer.output.register_forward_hook(make_noise(local, sigma)))\n",
    "\n",
    "    attacked = run_inference(model, sample_df)\n",
    "    for h in handles: h.remove()\n",
    "\n",
    "    # ver cu√°ntas cambiaron\n",
    "    diff = sum(1 for b,a in zip(baseline, attacked) if b != a)\n",
    "    expected = \"> 0 changes\"\n",
    "    actual = f\"{diff} changes\"\n",
    "    if diff == 0:\n",
    "        logger.error(f\"[GaussNoise] FAILURE: expected {expected}, got {actual}\")\n",
    "    else:\n",
    "        logger.info(f\"[GaussNoise] SUCCESS: {actual} (œÉ={sigma}, {percentage:.0%} neurons)\")\n",
    "\n",
    "    acc = accuracy_score(labels_list, attacked)\n",
    "    logger.info(f\"[GaussNoise] Accuracy under attack: {acc:.4f}\")\n",
    "    return attacked\n",
    "\n",
    "# ==============================\n",
    "# 3) TEST Partial Global Noise en top‚Äêk (sin cortar ejecuci√≥n)\n",
    "# ==============================\n",
    "def test_partial_noise(\n",
    "    model,\n",
    "    sample_df,\n",
    "    labels_list,\n",
    "    probe,\n",
    "    percentage: float = 0.1,\n",
    "    sigma: float = 0.1\n",
    "):\n",
    "    baseline = run_inference(model, sample_df)\n",
    "    topk = get_top_k_neurons_exact(probe, percentage=percentage)\n",
    "\n",
    "    def make_partial(idx_list, œÉ):\n",
    "        idxs = torch.tensor(idx_list, dtype=torch.long)\n",
    "        def hook(m, inp, out):\n",
    "            if out.dim()==3 and idxs.numel()>0:\n",
    "                o = out.clone()\n",
    "                o[:,:,idxs] += torch.randn_like(o[:,:,idxs]) * œÉ\n",
    "                return o\n",
    "            return out\n",
    "        return hook\n",
    "\n",
    "    handles = []\n",
    "    for i, layer in enumerate(get_encoder_layers(model)):\n",
    "        local = [g - i*model.config.hidden_size for g in topk\n",
    "                 if i*model.config.hidden_size <= g < (i+1)*model.config.hidden_size]\n",
    "        if not local: continue\n",
    "        handles.append(layer.output.register_forward_hook(make_partial(local, sigma)))\n",
    "\n",
    "    attacked = run_inference(model, sample_df)\n",
    "    for h in handles: h.remove()\n",
    "\n",
    "    diff = sum(1 for b,a in zip(baseline, attacked) if b != a)\n",
    "    expected = \"> 0 changes\"\n",
    "    actual = f\"{diff} changes\"\n",
    "    if diff == 0:\n",
    "        logger.error(f\"[PartialNoise] FAILURE: expected {expected}, got {actual}\")\n",
    "    else:\n",
    "        logger.info(f\"[PartialNoise] SUCCESS: {actual} (œÉ={sigma}, {percentage:.0%} neurons)\")\n",
    "\n",
    "    acc = accuracy_score(labels_list, attacked)\n",
    "    logger.info(f\"[PartialNoise] Accuracy under attack: {acc:.4f}\")\n",
    "    return attacked\n",
    "\n",
    "# ==============================\n",
    "# 4) TEST Fault‚ÄêSneaking simulado en top‚Äêk (sin cortar ejecuci√≥n)\n",
    "# ==============================\n",
    "def test_fault_sneaking(\n",
    "    model,\n",
    "    sample_df,\n",
    "    labels_list,\n",
    "    probe,\n",
    "    percentage: float = 0.1,\n",
    "    delta_scale: float = 0.05\n",
    "):\n",
    "    baseline = run_inference(model, sample_df)\n",
    "    topk = get_top_k_neurons_exact(probe, percentage=percentage)\n",
    "\n",
    "    # delta sobre out_proj\n",
    "    hidden = model.config.hidden_size\n",
    "    out_proj = model.classifier.out_proj\n",
    "    delta = torch.zeros_like(out_proj.weight.data)\n",
    "    for g in topk:\n",
    "        idx = g % hidden\n",
    "        delta[:, idx] = torch.randn(delta.shape[0]) * delta_scale\n",
    "\n",
    "    # hook\n",
    "    def make_fault_hook(delta_tensor):\n",
    "        def hook(m, inp):\n",
    "            m.weight.data += delta_tensor.to(m.weight.device)\n",
    "        return hook\n",
    "\n",
    "    handle = out_proj.register_forward_pre_hook(make_fault_hook(delta))\n",
    "    attacked = run_inference(model, sample_df)\n",
    "    handle.remove()\n",
    "\n",
    "    diff = sum(1 for b,a in zip(baseline, attacked) if b != a)\n",
    "    expected = \"> 0 changes\"\n",
    "    actual = f\"{diff} changes\"\n",
    "    if diff == 0:\n",
    "        logger.error(f\"[FaultSneak] FAILURE: expected {expected}, got {actual}\")\n",
    "    else:\n",
    "        logger.info(f\"[FaultSneak] SUCCESS: {actual} (scale={delta_scale}, {percentage:.0%} neurons)\")\n",
    "\n",
    "    acc = accuracy_score(labels_list, attacked)\n",
    "    logger.info(f\"[FaultSneak] Accuracy under attack: {acc:.4f}\")\n",
    "    return attacked\n",
    "\n",
    "# ==============================\n",
    "# Ejecutar tests sin cortar ejecuci√≥n\n",
    "# ==============================\n",
    "att_logit   = test_logit_bias_majority(model, sample_df, labels_list)\n",
    "att_gauss   = test_gaussian_noise(model, sample_df, labels_list, probe)\n",
    "att_partial = test_partial_noise(model, sample_df, labels_list, probe)\n",
    "att_fault   = test_fault_sneaking(model, sample_df, labels_list, probe)\n",
    "\n",
    "logger.info(\"‚úÖ All attack tests completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e366135-17f4-4089-a9e4-3a847d88dda1",
   "metadata": {},
   "source": [
    "# Conjuntos disjuntos de neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c30e1c-0f78-480e-976a-1d9b4607ab32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import os\n",
    "import json\n",
    "\n",
    "top_percentage = 0.1  # 50% \n",
    "\n",
    "# Detect and convert (layer, neuron) tuples to global indices if needed\n",
    "hidden_dim = model.config.hidden_size\n",
    "\n",
    "def tuple_to_global_index(neuron_tuples, hidden_dim):\n",
    "    return [layer * hidden_dim + neuron for (layer, neuron) in neuron_tuples]\n",
    "\n",
    "per_class_top_indices = {}\n",
    "for class_id, neuron_list in per_class_top_neurons.items():\n",
    "    if len(neuron_list) > 0 and isinstance(neuron_list[0], tuple):\n",
    "        per_class_top_indices[class_id] = tuple_to_global_index(neuron_list, hidden_dim)\n",
    "    else:\n",
    "        per_class_top_indices[class_id] = neuron_list\n",
    "\n",
    "# Exclusive neurons: present in top of class A but not in any other class\n",
    "exclusive_class_neurons = {}\n",
    "for cid, own_top in per_class_top_indices.items():\n",
    "    other = set()\n",
    "    for other_cid, other_top in per_class_top_indices.items():\n",
    "        if other_cid != cid:\n",
    "            other.update(other_top)\n",
    "    exclusive = sorted(set(own_top) - other)\n",
    "    exclusive_class_neurons[cid] = exclusive\n",
    "    print(f\"Class {cid}: {len(exclusive)} exclusive neurons out of {len(own_top)} top neurons\")\n",
    "\n",
    "# Save exclusive neurons to JSON\n",
    "exclusive_dir = f\"{BASE_PATH}/exclusive_neurons\"\n",
    "os.makedirs(exclusive_dir, exist_ok=True)\n",
    "for class_id, neuron_list in exclusive_class_neurons.items():\n",
    "    path = f\"{exclusive_dir}/exclusive_top{int(top_percentage*100)}p_class_{class_id}.json\"\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump([int(x) for x in neuron_list], f, indent=2)\n",
    "    logger.info(f\"Saved exclusive neurons for class {class_id} to {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd121ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def silence_exclusive_class_and_evaluate(\n",
    "    model,\n",
    "    sample_df,\n",
    "    labels_list,\n",
    "    exclusive_neuron_indices,\n",
    "    class_id,\n",
    "    report_path=None,\n",
    "    experiment_title=None\n",
    "):\n",
    "    hidden_dim = model.config.hidden_size\n",
    "    num_layers = model.config.num_hidden_layers\n",
    "\n",
    "    logger.info(f\"üîß Silencing {len(exclusive_neuron_indices)} EXCLUSIVE neurons for class {class_id}\")\n",
    "\n",
    "    encoder_layers = get_encoder_layers(model)\n",
    "    hook_handles = []\n",
    "    for i in range(num_layers):\n",
    "        indices_layer = [idx - i * hidden_dim for idx in exclusive_neuron_indices if i * hidden_dim <= idx < (i + 1) * hidden_dim]\n",
    "        if indices_layer:\n",
    "            logger.info(f\"üìå Layer {i}: silencing {len(indices_layer)} exclusive neurons for class {class_id}\")\n",
    "            if hasattr(encoder_layers[i], \"output\"):\n",
    "                handle = encoder_layers[i].output.register_forward_hook(make_cls_silence_hook(indices_layer))\n",
    "            else:\n",
    "                handle = encoder_layers[i].register_forward_hook(make_cls_silence_hook(indices_layer))\n",
    "            hook_handles.append(handle)\n",
    "\n",
    "    # --- Evaluation ---\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    for i in range(len(sample_df)):\n",
    "        input_ids_tensor = torch.tensor(sample_df.loc[i, 'input_ids']).unsqueeze(0).to(model.device)\n",
    "        attention_mask_tensor = torch.tensor(sample_df.loc[i, 'attention_mask']).unsqueeze(0).to(model.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids_tensor, attention_mask=attention_mask_tensor)\n",
    "            logits = outputs['logits']\n",
    "            pred = torch.argmax(logits, dim=1).item()\n",
    "            predictions.append(pred)\n",
    "        del input_ids_tensor, attention_mask_tensor, outputs, logits\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # --- Metrics & reporting ---\n",
    "    from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "    import pandas as pd\n",
    "    accuracy = accuracy_score(labels_list, predictions)\n",
    "    f1 = f1_score(labels_list, predictions, average='weighted')\n",
    "    report_dict = classification_report(labels_list, predictions, output_dict=True)\n",
    "    report_df = pd.DataFrame(report_dict).transpose().round(4)\n",
    "    report_df = report_df.drop(\"accuracy\", errors=\"ignore\")\n",
    "\n",
    "    accuracy_row = pd.DataFrame({\n",
    "        'precision': [\"\"],\n",
    "        'recall': [\"\"],\n",
    "        'f1-score': [accuracy],\n",
    "        'support': [sum(report_df[\"support\"])]\n",
    "    }, index=[\"overall_accuracy\"])\n",
    "    final_df = pd.concat([report_df, accuracy_row])\n",
    "\n",
    "    # --- Save classification report ---\n",
    "    if report_path is None:\n",
    "        report_path = f\"{BASE_PATH}/results/exclusive_class_silencing_{class_id}.csv\"\n",
    "    os.makedirs(os.path.dirname(report_path), exist_ok=True)\n",
    "    if experiment_title is None:\n",
    "        experiment_title = f\"Silencing exclusive neurons for class {class_id}\"\n",
    "    if not os.path.exists(report_path):\n",
    "        with open(report_path, \"w\") as f:\n",
    "            f.write(f\"# {experiment_title}\\n\")\n",
    "            final_df.to_csv(f)\n",
    "    else:\n",
    "        with open(report_path, \"a\") as f:\n",
    "            f.write(f\"\\n\\n# {experiment_title}\\n\")\n",
    "        final_df.to_csv(report_path, mode=\"a\")\n",
    "\n",
    "    logger.info(f\"üéØ Accuracy after exclusive silencing: {accuracy:.4f}\")\n",
    "    logger.info(f\"üìè Weighted F1 Score: {f1:.4f}\")\n",
    "    logger.info(f\"üìã Classification report saved to {report_path}\")\n",
    "\n",
    "    # Remove hooks\n",
    "    for handle in hook_handles:\n",
    "        handle.remove()\n",
    "    logger.info(\"‚úÖ All hooks removed after evaluation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e495203-de9e-413c-8dd7-48848971d1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Run silencing experiments for each class with its exclusive neurons ---\n",
    "for class_id, neuron_indices in exclusive_class_neurons.items():\n",
    "    silence_exclusive_class_and_evaluate(\n",
    "        model=model,\n",
    "        sample_df=sample_df,\n",
    "        labels_list=labels_list,\n",
    "        exclusive_neuron_indices=neuron_indices,\n",
    "        class_id=class_id,\n",
    "        report_path=f\"{BASE_PATH}/results/exclusive_class_silencing_{class_id}.csv\",\n",
    "        experiment_title=f\"Silencing exclusive neurons for class {class_id}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffe637b",
   "metadata": {},
   "source": [
    "# GoEmotions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cd5efc",
   "metadata": {},
   "source": [
    "## Dataset Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075a5800-8b1d-49a9-a078-ac3bed4a42cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìÅ Dataset and mappings\n",
    "GOEMOTIONS_PATH = \"data/goemotions\"\n",
    "INPUT_FILE = f\"{GOEMOTIONS_PATH}/test.tsv\"\n",
    "EMOTIONS_FILE = f\"{GOEMOTIONS_PATH}/emotions.txt\"\n",
    "\n",
    "# üéØ Target emotions (subset of original GoEmotions)\n",
    "TARGET_EMOTIONS = [\"anger\", \"disgust\", \"fear\", \"joy\", \"sadness\", \"surprise\"]\n",
    "\n",
    "# üß† Pretrained Model\n",
    "GOEMOTIONS_MODEL_HF = \"monologg/bert-base-cased-goemotions-original\"\n",
    "\n",
    "# üíæ Outputs\n",
    "SAMPLE_OUTPUT = f\"{GOEMOTIONS_PATH}/sample_60.json\"\n",
    "TOKENIZED_OUTPUT = f\"{GOEMOTIONS_PATH}/tokenized.pt\"\n",
    "LABELS_OUTPUT = f\"{GOEMOTIONS_PATH}/labels.pt\"\n",
    "LABEL_MAPPING_OUTPUT = f\"{GOEMOTIONS_PATH}/label_mapping.json\"\n",
    "CSV_REPORT_PATH = f\"{GOEMOTIONS_PATH}/classification_report_eval.csv\"\n",
    "CSV_REPORT_GOBAL_SILENCING = f\"{GOEMOTIONS_PATH}/classification_report_global_silencing.csv\"\n",
    "ACTIVATIONS_GOEMOTIONS = f\"{GOEMOTIONS_PATH}/activations.json\"\n",
    "SAMPLE_OUTPUT_JSON = \"data/goemotions/sample_df.json\"\n",
    "# üìü Device\n",
    "\n",
    "device_goemo = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c86fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def silence_top_global_percentage_and_evaluate(\n",
    "    model,\n",
    "    sample_df,\n",
    "    labels_list,\n",
    "    probe,\n",
    "    label2idx,\n",
    "    percentage=None,\n",
    "    experiment_title=None,\n",
    "    report_path=None,\n",
    "    custom_indices=None  # Nuevo: permite pasar neuronas custom (por ejemplo aleatorias)\n",
    "):\n",
    "    import os\n",
    "    import torch\n",
    "    import pandas as pd\n",
    "    from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "    hidden_dim = model.config.hidden_size\n",
    "    num_layers = model.config.num_hidden_layers\n",
    "    total_neurons = num_layers * hidden_dim\n",
    "\n",
    "    # Decide qu√© neuronas silenciar\n",
    "    if custom_indices is not None:\n",
    "        top_neurons = custom_indices\n",
    "        print(f\"üîß Silencing custom list of {len(top_neurons)} neurons\")\n",
    "    else:\n",
    "        # Si no, selecciona top del probe (como siempre)\n",
    "        top_neurons = top_neurons_probe(\n",
    "            probe, percentage=percentage, class_to_idx=label2idx\n",
    "        )\n",
    "        print(f\"üîß Silencing {len(top_neurons)} neurons from probe (percentage={percentage})\")\n",
    "\n",
    "    # Hook setup\n",
    "    encoder_layers = get_encoder_layers(model)\n",
    "    hook_handles = []\n",
    "    for i in range(num_layers):\n",
    "        # Neuronas de esta capa\n",
    "        indices_layer = [idx - i * hidden_dim for idx in top_neurons if i * hidden_dim <= idx < (i + 1) * hidden_dim]\n",
    "        if indices_layer:\n",
    "            print(f\"üìå Layer {i}: silencing {len(indices_layer)} neurons\")\n",
    "            if hasattr(encoder_layers[i], \"output\"):\n",
    "                handle = encoder_layers[i].output.register_forward_hook(make_cls_silence_hook(indices_layer))\n",
    "            else:\n",
    "                handle = encoder_layers[i].register_forward_hook(make_cls_silence_hook(indices_layer))\n",
    "            hook_handles.append(handle)\n",
    "\n",
    "    # Evaluaci√≥n est√°ndar (igual que ya tienes)\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    for i in range(len(sample_df)):\n",
    "        input_ids_tensor = torch.tensor(sample_df.loc[i, 'input_ids']).unsqueeze(0).to(model.device)\n",
    "        attention_mask_tensor = torch.tensor(sample_df.loc[i, 'attention_mask']).unsqueeze(0).to(model.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids_tensor, attention_mask=attention_mask_tensor)\n",
    "            logits = outputs['logits']\n",
    "            pred = torch.argmax(logits, dim=1).item()\n",
    "            predictions.append(pred)\n",
    "        del input_ids_tensor, attention_mask_tensor, outputs, logits\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # M√©tricas y reporte\n",
    "    accuracy = accuracy_score(labels_list, predictions)\n",
    "    f1 = f1_score(labels_list, predictions, average='weighted')\n",
    "    report_dict = classification_report(labels_list, predictions, output_dict=True)\n",
    "    report_df = pd.DataFrame(report_dict).transpose().round(4)\n",
    "    report_df = report_df.drop(\"accuracy\", errors=\"ignore\")\n",
    "\n",
    "    accuracy_row = pd.DataFrame({\n",
    "        'precision': [\"\"],\n",
    "        'recall': [\"\"],\n",
    "        'f1-score': [accuracy],\n",
    "        'support': [sum(report_df[\"support\"])]\n",
    "    }, index=[\"overall_accuracy\"])\n",
    "    final_df = pd.concat([report_df, accuracy_row])\n",
    "\n",
    "    # Guardar reporte\n",
    "    if report_path is None:\n",
    "        report_path = \"results/class_silencing_global.csv\"\n",
    "    os.makedirs(os.path.dirname(report_path), exist_ok=True)\n",
    "\n",
    "    if experiment_title is None:\n",
    "        experiment_title = \"Silencing top global neurons\"\n",
    "    if not os.path.exists(report_path):\n",
    "        with open(report_path, \"w\") as f:\n",
    "            f.write(f\"# {experiment_title}\\n\")\n",
    "            final_df.to_csv(f)\n",
    "    else:\n",
    "        with open(report_path, \"a\") as f:\n",
    "            f.write(f\"\\n\\n# {experiment_title}\\n\")\n",
    "        final_df.to_csv(report_path, mode=\"a\")\n",
    "\n",
    "    print(f\"üéØ Accuracy after silencing: {accuracy:.4f}\")\n",
    "    print(f\"üìè Weighted F1 Score: {f1:.4f}\")\n",
    "    print(f\"üìã Classification report saved to {report_path}\")\n",
    "\n",
    "    # Quitar hooks\n",
    "    for handle in hook_handles:\n",
    "        handle.remove()\n",
    "    print(\"‚úÖ All hooks removed after evaluation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8f3cfa-1009-480a-9bf3-7648189e4b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(SAMPLE_OUTPUT):\n",
    "    # üì• Load emotion names\n",
    "    with open(EMOTIONS_FILE, \"r\") as f:\n",
    "        id2emotion = [line.strip() for line in f.readlines()]\n",
    "    emotion2id = {e: i for i, e in enumerate(id2emotion)}\n",
    "\n",
    "    # üéØ Select target emotions and their GoEmotions IDs\n",
    "    TARGET_EMOTIONS = [\"anger\", \"disgust\", \"fear\", \"joy\", \"sadness\", \"surprise\"]\n",
    "    target_ids = [emotion2id[e] for e in TARGET_EMOTIONS]\n",
    "\n",
    "    # üåê Mapping from GoEmotion ID to 0‚Äì5 label\n",
    "    goemo2local = {eid: i for i, eid in enumerate(target_ids)}\n",
    "\n",
    "    # üìä Load dataset\n",
    "    df = pd.read_csv(INPUT_FILE, sep=\"\\t\", header=None, names=[\"text\", \"labels\", \"split\"])\n",
    "    df = df.dropna(subset=[\"labels\"])\n",
    "    df[\"label_ids\"] = df[\"labels\"].apply(lambda x: list(map(int, str(x).split(\",\"))))\n",
    "\n",
    "    # üßº Filter: single-label only & target emotions\n",
    "    df_filtered = df[df[\"label_ids\"].apply(lambda ids: len(ids) == 1 and ids[0] in target_ids)].copy()\n",
    "    df_filtered[\"label_id\"] = df_filtered[\"label_ids\"].apply(lambda ids: goemo2local[ids[0]])\n",
    "\n",
    "    # üìâ Count examples per class\n",
    "    counts = df_filtered[\"label_id\"].value_counts()\n",
    "    print(\"Available examples for selected emotions:\")\n",
    "    print(counts)\n",
    "\n",
    "    # üéØ Balanced subset (max 10 per class)\n",
    "    max_per_class = 10\n",
    "    samples = []\n",
    "\n",
    "    for label in counts.index:\n",
    "        subset = df_filtered[df_filtered[\"label_id\"] == label]\n",
    "        sampled = shuffle(subset, random_state=42).iloc[:max_per_class]\n",
    "        samples.append(sampled[[\"text\", \"label_id\"]])\n",
    "\n",
    "    df_final = pd.concat(samples).reset_index(drop=True)\n",
    "\n",
    "    # üíæ Save to JSON\n",
    "    df_final.to_json(SAMPLE_OUTPUT, orient=\"records\", lines=True, force_ascii=False)\n",
    "    print(f\"\\n‚úÖ Saved dataset: {len(df_final)} examples (max {max_per_class} per emotion)\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Skipping dataset generation: {SAMPLE_OUTPUT} already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6171c43b",
   "metadata": {},
   "source": [
    "## Original Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6ee02c",
   "metadata": {},
   "source": [
    "### Load model, tokenizer and inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1427f3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì• Load dataset\n",
    "with open(SAMPLE_OUTPUT, \"r\") as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "\n",
    "texts = [x[\"text\"] for x in data]\n",
    "labels = [x[\"label_id\"] for x in data]\n",
    "\n",
    "# üî¢ Label mappings\n",
    "label2id = {label: i for i, label in enumerate(sorted(set(labels)))}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "label_ids = [label2id[label] for label in labels]\n",
    "\n",
    "# üî† Tokenize and save only if not already saved\n",
    "tokenizer = AutoTokenizer.from_pretrained(GOEMOTIONS_MODEL_HF)\n",
    "\n",
    "if not os.path.exists(TOKENIZED_OUTPUT):\n",
    "    encodings = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    torch.save(encodings, TOKENIZED_OUTPUT)\n",
    "    logger.info(\"‚úÖ Tokenized inputs saved.\")\n",
    "else:\n",
    "    logger.warning(f\"‚ö†Ô∏è Skipping: {TOKENIZED_OUTPUT} already exists.\")\n",
    "\n",
    "if not os.path.exists(LABELS_OUTPUT):\n",
    "    torch.save(torch.tensor(label_ids), LABELS_OUTPUT)\n",
    "    logger.info(\"‚úÖ Label tensor saved.\")\n",
    "else:\n",
    "    logger.warning(f\"‚ö†Ô∏è Skipping: {LABELS_OUTPUT} already exists.\")\n",
    "\n",
    "if not os.path.exists(LABEL_MAPPING_OUTPUT):\n",
    "    with open(LABEL_MAPPING_OUTPUT, \"w\") as f:\n",
    "        json.dump(label2id, f, indent=2)\n",
    "    logger.info(\"‚úÖ Label mapping saved.\")\n",
    "else:\n",
    "    logger.warning(f\"‚ö†Ô∏è Skipping: {LABEL_MAPPING_OUTPUT} already exists.\")\n",
    "\n",
    "# ‚úÖ NEW: Generate sample_df for later neuron silencing evaluation\n",
    "if not os.path.exists(SAMPLE_OUTPUT_JSON):\n",
    "    logger.info(\"üìÑ Creating and saving sample_df.json for evaluation hooks...\")\n",
    "    sample_rows = []\n",
    "    for text in texts:\n",
    "        encoded = tokenizer(text, truncation=True, padding=\"max_length\", max_length=128)\n",
    "        sample_rows.append({\n",
    "            \"input_ids\": encoded[\"input_ids\"],\n",
    "            \"attention_mask\": encoded[\"attention_mask\"]\n",
    "        })\n",
    "    sample_df = pd.DataFrame(sample_rows)\n",
    "    sample_df.to_json(SAMPLE_OUTPUT_JSON, orient=\"records\", lines=True)\n",
    "    logger.info(f\"‚úÖ sample_df saved to {SAMPLE_OUTPUT_JSON}\")\n",
    "else:\n",
    "    logger.warning(f\"‚ö†Ô∏è Skipping: {SAMPLE_OUTPUT_JSON} already exists.\")\n",
    "\n",
    "# Summary\n",
    "logger.info(\"üß† Emotions (IDs): %s\", sorted(label2id.keys()))\n",
    "logger.info(\"üî¢ Label mapping: %s\", label2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7c6bd3",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da771ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "# Define the target GoEmotions IDs\n",
    "target_emotion_names = [\"anger\", \"disgust\", \"fear\", \"joy\", \"sadness\", \"surprise\"]\n",
    "\n",
    "# Load emotion mapping\n",
    "with open(EMOTIONS_FILE, \"r\") as f:\n",
    "    id2emotion = [line.strip() for line in f.readlines()]\n",
    "emotion2id = {e: i for i, e in enumerate(id2emotion)}\n",
    "\n",
    "target_ids = [emotion2id[e] for e in target_emotion_names]\n",
    "target_ids_tensor = torch.tensor(target_ids).to(device_goemo)\n",
    "\n",
    "# Map GoEmotions IDs ‚Üí local labels\n",
    "label2id = {goid: i for i, goid in enumerate(target_ids)}\n",
    "id2label = {i: goid for goid, i in label2id.items()}\n",
    "\n",
    "print(f\"üéØ Target GoEmotions IDs: {target_ids}\")\n",
    "print(f\"üó∫Ô∏è Mapping to local labels: {label2id}\")\n",
    "\n",
    "# Load model_goem\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "model_goem = AutoModelForSequenceClassification.from_pretrained(GOEMOTIONS_MODEL_HF)\n",
    "model_goem.to(device_goemo)\n",
    "model_goem.eval()\n",
    "\n",
    "# Load data\n",
    "inputs = torch.load(TOKENIZED_OUTPUT, weights_only=False)\n",
    "labels = torch.load(LABELS_OUTPUT).tolist()\n",
    "\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(len(labels))):\n",
    "        input_ids = inputs[\"input_ids\"][i].unsqueeze(0).to(device_goemo)\n",
    "        attention_mask = inputs[\"attention_mask\"][i].unsqueeze(0).to(device_goemo)\n",
    "\n",
    "        logits = model_goem(input_ids=input_ids, attention_mask=attention_mask).logits.squeeze(0)\n",
    "\n",
    "        selected_logits = logits[target_ids_tensor]\n",
    "        pred_local = torch.argmax(selected_logits).item()\n",
    "\n",
    "        predictions.append(pred_local)\n",
    "        true_labels.append(labels[i])  # already 0‚Äì5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c214269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Report\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "f1 = f1_score(true_labels, predictions, average=\"weighted\")\n",
    "ordered_labels = sorted(label2id.values())\n",
    "\n",
    "report = classification_report(\n",
    "    true_labels,\n",
    "    predictions,\n",
    "    labels=ordered_labels,\n",
    "    target_names=[id2label[i] for i in ordered_labels],\n",
    "    output_dict=True,\n",
    "    zero_division=0\n",
    ")\n",
    "\n",
    "report_df = pd.DataFrame(report).transpose().round(4)\n",
    "accuracy_row = pd.DataFrame({\n",
    "    'precision': [\"\"],\n",
    "    'recall': [\"\"],\n",
    "    'f1-score': [accuracy],\n",
    "    'support': [sum(report_df[\"support\"])]\n",
    "}, index=[\"overall_accuracy\"])\n",
    "\n",
    "final_df = pd.concat([report_df, accuracy_row])\n",
    "\n",
    "if not os.path.exists(CSV_REPORT_PATH):\n",
    "    final_df.to_csv(CSV_REPORT_PATH)\n",
    "    print(f\"‚úÖ Report saved to {CSV_REPORT_PATH}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Skipping save: {CSV_REPORT_PATH} already exists.\")\n",
    "\n",
    "print(f\"‚úÖ Accuracy: {accuracy:.4f}\")\n",
    "print(f\"‚úÖ F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c26588",
   "metadata": {},
   "source": [
    "## Dataset Wrapper and DataLoader (Goemotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c9a2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "class GoEmotionsDataset(Dataset):\n",
    "    def __init__(self, input_ids, labels):\n",
    "        self.input_ids = input_ids\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.input_ids[idx]), torch.tensor(self.labels[idx])\n",
    "\n",
    "# Load input IDs and labels from disk\n",
    "input_data = torch.load(TOKENIZED_OUTPUT, weights_only=False)\n",
    "labels = torch.load(LABELS_OUTPUT).tolist()\n",
    "\n",
    "input_ids_list = input_data[\"input_ids\"].tolist()\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = GoEmotionsDataset(input_ids_list, labels)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "logger.info(\"‚úÖ Dataloader created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ec9474",
   "metadata": {},
   "source": [
    "## Extract Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0016430b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(ACTIVATIONS_GOEMOTIONS):\n",
    "    logger.info(f\"‚ö° Activations already exist at {ACTIVATIONS_GOEMOTIONS}. Skipping extraction.\")\n",
    "else:\n",
    "    logger.info(\"üöÄ Starting activation extraction from model (CLS token only).\")\n",
    "    \n",
    "    transformers_extractor.extract_representations(\n",
    "        model=model_goem,\n",
    "        input_tokens_list=input_ids_list,   \n",
    "        output_file=ACTIVATIONS_GOEMOTIONS,\n",
    "        device=device_goemo,\n",
    "        output_type=\"json\",                \n",
    "        decompose_layers=False,\n",
    "        filter_layers=None\n",
    "    )\n",
    "\n",
    "    logger.info(f\"‚úÖ Activations successfully saved to {ACTIVATIONS_GOEMOTIONS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2363399",
   "metadata": {},
   "source": [
    "## Load Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7eff78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def create_tensors_goemo(tokens_data, activations, task_specific_tag=\"NN\", task_type=\"classification\", dtype=torch.float32):\n",
    "    \"\"\"\n",
    "    Create input/output tensors from CLS activations and labels for classification tasks.\n",
    "\n",
    "    Args:\n",
    "        tokens_data (list): List of dicts with keys \"tokens\" and \"target\"\n",
    "        activations (list): List of numpy arrays with CLS activations\n",
    "        task_specific_tag (str): Not used for CLS, kept for compatibility\n",
    "        task_type (str): \"classification\" or \"regression\"\n",
    "        dtype (torch.dtype): Data type of the tensors\n",
    "\n",
    "    Returns:\n",
    "        X (torch.Tensor): Input features (num_samples, num_layers * hidden_size)\n",
    "        y (torch.Tensor): Labels\n",
    "        mapping (tuple): label2idx, idx2label, None, None\n",
    "    \"\"\"\n",
    "\n",
    "    logger.info(\"üîÑ Creating tensors from activations and labels\")\n",
    "\n",
    "    # Number of samples\n",
    "    num_samples = len(tokens_data)\n",
    "    assert num_samples == len(activations), \"Mismatch between tokens and activations\"\n",
    "\n",
    "    logger.info(f\"üß™ Number of samples: {num_samples}\")\n",
    "\n",
    "    # Flatten each activation: (num_layers, 1, hidden_dim) ‚Üí (num_layers * hidden_dim)\n",
    "    X = []\n",
    "    for i, sample in enumerate(activations):\n",
    "        if sample.ndim == 3 and sample.shape[1] == 1:\n",
    "            flattened = sample.squeeze(1).flatten()\n",
    "        elif sample.ndim == 2:\n",
    "            flattened = sample.flatten()\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected shape for activation {i}: {sample.shape}\")\n",
    "        X.append(flattened)\n",
    "    X = np.array(X)\n",
    "\n",
    "    \n",
    "    # Encode labels\n",
    "    labels = [sample[\"target\"] for sample in tokens_data]\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(labels)\n",
    "\n",
    "    # Logging label mapping\n",
    "    label2idx = {label: int(idx) for idx, label in enumerate(label_encoder.classes_)}\n",
    "    idx2label = {int(idx): label for label, idx in label2idx.items()}\n",
    "    logger.info(f\"üî¢ Labels mapping: {label2idx}\")\n",
    "\n",
    "    return (\n",
    "        torch.tensor(X, dtype=dtype),\n",
    "        torch.tensor(y),\n",
    "        (label2idx, idx2label, None, None)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c29373",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neurox.data.loader import load_activations\n",
    "from neurox.interpretation import utils\n",
    "\n",
    "# ‚ö° Load activations\n",
    "activations, num_layers = load_activations(ACTIVATIONS_GOEMOTIONS)\n",
    "logger.info(f\"‚úÖ Activations loaded from {ACTIVATIONS_GOEMOTIONS} with {num_layers} layers\")\n",
    "\n",
    "# üß† Prepare dataset with correct structure\n",
    "sentence_data = [{\"tokens\": [\"[CLS]\"], \"target\": label} for label in labels]\n",
    "\n",
    "# üì¶ Convert to tensors\n",
    "X, y, mapping = create_tensors_goemo(\n",
    "    sentence_data,\n",
    "    activations,\n",
    "    task_specific_tag=\"NN\",\n",
    "    task_type=\"classification\"\n",
    ")\n",
    "\n",
    "label2idx, idx2label, _, _ = mapping\n",
    "logger.info(\"‚úÖ Tensors and label mappings created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670171ad",
   "metadata": {},
   "source": [
    "## Train Probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc4f72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Convert tensors to numpy arrays (required by train_logistic_regression_probe)\n",
    "X_np = X.numpy() if isinstance(X, torch.Tensor) else X\n",
    "y_np = y.numpy() if isinstance(y, torch.Tensor) else y\n",
    "\n",
    "# üß™ Train logistic regression probe\n",
    "logger.info(\"üîß Training logistic regression probe\")\n",
    "probe = linear_probe.train_logistic_regression_probe(\n",
    "    X_np, y_np,\n",
    "    lambda_l1=1.1,\n",
    "    lambda_l2=1.1\n",
    ")\n",
    "\n",
    "# üßæ Evaluate the trained probe\n",
    "logger.info(\"üìà Evaluating the probe\")\n",
    "scores = linear_probe.evaluate_probe(probe, X_np, y_np, idx_to_class=idx2label)\n",
    "logger.info(f\"üéØ Probe evaluation results:\\n{scores}\")\n",
    "\n",
    "# üîç Get top neurons\n",
    "top_neurons_probe, per_class_top_neurons = linear_probe.get_top_neurons(\n",
    "    probe,\n",
    "    percentage=0.1,\n",
    "    class_to_idx=label2idx\n",
    ")\n",
    "logger.info(f\"üß† Top global neurons: {top_neurons_probe}\")\n",
    "logger.info(f\"üß† Top neurons per class: {per_class_top_neurons}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393dc71c",
   "metadata": {},
   "source": [
    "## Global Silencing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594d8e58",
   "metadata": {},
   "source": [
    "## Silencing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ed7c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Load tokenized input and labels\n",
    "sample_df = pd.read_json(SAMPLE_OUTPUT_JSON, lines=True)\n",
    "labels_list = torch.load(LABELS_OUTPUT).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8feeaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "hidden_dim = model_goem.config.hidden_size\n",
    "num_layers = model_goem.config.num_hidden_layers\n",
    "total_neurons = num_layers * hidden_dim\n",
    "num_to_silence = int(0.1 * total_neurons)  # mismo porcentaje que top global\n",
    "\n",
    "random_indices = random.sample(range(total_neurons), num_to_silence)\n",
    "\n",
    "silence_top_global_percentage_and_evaluate(\n",
    "    model=model_goem,\n",
    "    sample_df=sample_df,\n",
    "    labels_list=labels_list,\n",
    "    probe=None,  # No se usa\n",
    "    label2idx=label2idx,\n",
    "    percentage=None,\n",
    "    experiment_title=\"Silencing random 10% global neurons\",\n",
    "    report_path=\"data/goemotions/classification_report_random_silencing.csv\",\n",
    "    custom_indices=random_indices\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d187e65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentages = [0.025, 0.05, 0.075, 0.10, 0.125, 0.15, 0.175, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.65, 0.75, 0.8, 0.95]\n",
    "percentages = [0.1]\n",
    "\n",
    "for pct in percentages:\n",
    "    silence_top_global_percentage_and_evaluate(\n",
    "        model=model_goem,                    # o tu variable del modelo cargado\n",
    "        sample_df=sample_df,\n",
    "        labels_list=labels_list,\n",
    "        probe=probe,\n",
    "        label2idx=label2idx,\n",
    "        percentage=pct,\n",
    "        experiment_title=f\"Silencing {pct*100:.1f}% Global Neurons\",\n",
    "        report_path=CSV_REPORT_GOBAL_SILENCING\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598ece4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# üßê Ver las primeras filas\n",
    "print(sample_df.head())\n",
    "\n",
    "# üîç Ver los tipos de cada columna\n",
    "print(sample_df.dtypes)\n",
    "\n",
    "# üß™ Ver si hay valores nulos\n",
    "print(sample_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f208db",
   "metadata": {},
   "source": [
    "# Diagnostico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34e234e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica dimensiones del probe\n",
    "print(\"üîç probe.linear.weight shape:\", probe.linear.weight.shape)\n",
    "\n",
    "# Deber√≠a dar (num_classes, total_neurons) ‚Üí en tu caso: (6, 9216)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d108b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = model_goem.config.hidden_size\n",
    "num_layers = model_goem.config.num_hidden_layers\n",
    "\n",
    "layer_counts = {i: 0 for i in range(num_layers)}\n",
    "for idx in top_neurons_probe:\n",
    "    layer = idx // hidden_dim\n",
    "    layer_counts[layer] += 1\n",
    "\n",
    "print(\"Neuronas silenciadas por capa (top global):\")\n",
    "for l in range(num_layers):\n",
    "    print(f\"  Layer {l}: {layer_counts[l]} neurons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30afd2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üß∑ label2idx:\", label2idx)\n",
    "\n",
    "# Crea tensor con las IDs originales (de GoEmotions)\n",
    "target_goemotion_ids = torch.tensor(list(label2idx.keys()))\n",
    "print(\"üéØ target_goemotion_ids:\", target_goemotion_ids.tolist())\n",
    "\n",
    "# Confirma si las posiciones corresponden 1:1 con etiquetas de `labels_list` que t√∫ usas\n",
    "print(\"üß™ Sample labels_list:\", labels_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea339942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usa solo 1 ejemplo\n",
    "i = 0\n",
    "\n",
    "# Sin silenciamiento todav√≠a\n",
    "input_ids_tensor = torch.tensor(sample_df.loc[i, 'input_ids']).unsqueeze(0).to(model_goem.device)\n",
    "attention_mask_tensor = torch.tensor(sample_df.loc[i, 'attention_mask']).unsqueeze(0).to(model_goem.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model_goem(input_ids=input_ids_tensor, attention_mask=attention_mask_tensor)\n",
    "    logits = outputs.logits\n",
    "    selected_logits = logits[:, target_goemotion_ids]  # [1, 6]\n",
    "    pred_local = torch.argmax(selected_logits, dim=1).item()\n",
    "\n",
    "print(\"üî¢ Full logits:\", logits.tolist())\n",
    "print(\"üéØ Selected logits (target emotions):\", selected_logits.tolist())\n",
    "print(\"‚úÖ Predicted class index (0‚Äì5):\", pred_local)\n",
    "print(\"üè∑Ô∏è True label:\", labels_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a8be7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ö†Ô∏è Hook solo para capa 11 (donde vimos que hay muchas neuronas silenciadas)\n",
    "\n",
    "\n",
    "encoder_layers = get_encoder_layers(model_goem)\n",
    "hook_handles = []\n",
    "\n",
    "for i in range(num_layers):\n",
    "    indices_layer = [idx - i * hidden_dim for idx in top_neurons_global if i * hidden_dim <= idx < (i + 1) * hidden_dim]\n",
    "    if indices_layer:\n",
    "        handle = encoder_layers[i].output.register_forward_hook(make_cls_silence_hook2(indices_layer))\n",
    "        hook_handles.append(handle)\n",
    "\n",
    "# Misma inferencia que antes\n",
    "with torch.no_grad():\n",
    "    outputs = model_goem(input_ids=input_ids_tensor, attention_mask=attention_mask_tensor)\n",
    "    logits = outputs.logits\n",
    "    selected_logits = logits[:, target_goemotion_ids]\n",
    "    pred_local = torch.argmax(selected_logits, dim=1).item()\n",
    "\n",
    "print(\"üß™ Silenced logits:\", selected_logits.tolist())\n",
    "print(\"üéØ New prediction:\", pred_local)\n",
    "\n",
    "# Limpiar hooks\n",
    "for h in hook_handles:\n",
    "    h.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d019d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecuta una sola inferencia para ver qu√© capa da output y qu√© se usa como input al classifier\n",
    "with torch.no_grad():\n",
    "    outputs = model_goem(input_ids=input_ids_tensor, attention_mask=attention_mask_tensor, output_hidden_states=True)\n",
    "    hidden_states = outputs.hidden_states  # Tuple: (layer_0, ..., layer_n)\n",
    "    final_hidden = hidden_states[-1]  # shape: [1, seq_len, hidden_size]\n",
    "\n",
    "    print(\"üß† Final hidden state shape:\", final_hidden.shape)\n",
    "    print(\"üîç CLS vector (posici√≥n 0):\", final_hidden[:, 0, :].abs().sum().item())\n",
    "\n",
    "    logits = model_goem.classifier(final_hidden[:, 0, :])  # ¬øas√≠ lo hace el modelo?\n",
    "    print(\"üéØ Recomputed logits from CLS:\", logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5219f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel\n",
    "import logging\n",
    "\n",
    "# Suponemos que ya tienes estas variables cargadas:\n",
    "# model_goem, input_ids_tensor, attention_mask_tensor, top_neurons_global, make_cls_silence_hook2, get_encoder_layers\n",
    "\n",
    "# Configura el logger\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Accede a capas internas\n",
    "hidden_dim = model_goem.config.hidden_size\n",
    "num_layers = model_goem.config.num_hidden_layers\n",
    "encoder_layers = get_encoder_layers(model_goem)\n",
    "\n",
    "# --- 1. Inference sin silenciar (sin hook) ---\n",
    "with torch.no_grad():\n",
    "    outputs_original = model_goem(\n",
    "        input_ids=input_ids_tensor,\n",
    "        attention_mask=attention_mask_tensor,\n",
    "        output_hidden_states=True\n",
    "    )\n",
    "    hidden_states_original = outputs_original.hidden_states[-1][:, 0, :]  # [CLS] final layer\n",
    "\n",
    "# --- 2. Aplicar hooks para silenciar ---\n",
    "hook_handles = []\n",
    "for i in range(num_layers):\n",
    "    indices_layer = [idx - i * hidden_dim for idx in top_neurons_global if i * hidden_dim <= idx < (i + 1) * hidden_dim]\n",
    "    if indices_layer:\n",
    "        handle = encoder_layers[i].output.register_forward_hook(make_cls_silence_hook2(indices_layer))\n",
    "        hook_handles.append(handle)\n",
    "\n",
    "# --- 3. Inference con neuronas silenciadas ---\n",
    "with torch.no_grad():\n",
    "    outputs_silenced = model_goem(\n",
    "        input_ids=input_ids_tensor,\n",
    "        attention_mask=attention_mask_tensor,\n",
    "        output_hidden_states=True\n",
    "    )\n",
    "    hidden_states_silenced = outputs_silenced.hidden_states[-1][:, 0, :]  # [CLS] silenciado\n",
    "\n",
    "# --- 4. Comparar los vectores CLS ---\n",
    "diff = torch.abs(hidden_states_original - hidden_states_silenced)\n",
    "logger.info(f\"üîç CLS difference after silencing: mean={diff.mean()}, max={diff.max()}\")\n",
    "\n",
    "# Limpieza: eliminar hooks\n",
    "for handle in hook_handles:\n",
    "    handle.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758539a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(get_encoder_layers(model_goem)):\n",
    "    print(f\"Layer {i} -> {layer.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b601b4b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e8c1eb1",
   "metadata": {},
   "source": [
    "## Second try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea85504",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def make_cls_silence_hook(indices: list[int]):\n",
    "    # crea un tensor de √≠ndices (vac√≠o si no hay nada que silenciar)\n",
    "    indices_tensor = torch.tensor(indices, dtype=torch.long) if indices else torch.tensor([], dtype=torch.long)\n",
    "\n",
    "    def hook(module, input, output):\n",
    "        # s√≥lo intervenimos si es un Tensor\n",
    "        if not isinstance(output, torch.Tensor):\n",
    "            return output\n",
    "\n",
    "        out = output.clone()\n",
    "        idx = indices_tensor.to(out.device)\n",
    "\n",
    "        if out.dim() == 3:\n",
    "            # batch √ó seq_len √ó hidden\n",
    "            cls = out[:, 0, :]                      # (batch, hidden)\n",
    "            mask = torch.ones_like(cls)\n",
    "            if idx.numel() > 0:\n",
    "                mask[:, idx] = 0.0\n",
    "            out[:, 0, :] = cls * mask\n",
    "        elif out.dim() == 2:\n",
    "            # batch √ó hidden  (ej. pooler)\n",
    "            mask = torch.ones_like(out)\n",
    "            if idx.numel() > 0:\n",
    "                mask[:, idx] = 0.0\n",
    "            out = out * mask\n",
    "\n",
    "        return out\n",
    "\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81761776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# üîç 2Ô∏è‚É£ Celda: Entrenar el probe y extraer los TOP_NEURONS\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "# (a) Entrena tu logistic regression probe como antes\n",
    "probe = linear_probe.train_logistic_regression_probe(\n",
    "    X_np, y_np,\n",
    "    lambda_l1=0.001,\n",
    "    lambda_l2=0.001\n",
    ")\n",
    "\n",
    "# (b) Obt√©n los √≠ndices globales de las neuronas m√°s relevantes\n",
    "#     `top_neurons_probe` es una lista de enteros en [0, num_layers*hidden_size)\n",
    "top_neurons_probe, per_class_top_neurons = linear_probe.get_top_neurons(\n",
    "    probe,\n",
    "    percentage=0.10,        # 10% de las neuronas\n",
    "    class_to_idx=label2idx\n",
    ")\n",
    "\n",
    "# (c) Ahora s√≠ definimos `global_indices` para usar en el hook\n",
    "global_indices = top_neurons_probe\n",
    "\n",
    "# üìã Comprueba un par de valores:\n",
    "print(f\"N√∫mero total de neuronas a silenciar: {len(global_indices)}\")\n",
    "print(f\"Primeros 10 √≠ndices globales: {global_indices[:10]}\")  # deben estar entre 0 y hidden_size*num_layers-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdb3e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d792781",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "hidden_size = model_goem.config.hidden_size      # p.ej. 768\n",
    "num_layers  = model_goem.config.num_hidden_layers  # p.ej. 12\n",
    "\n",
    "layer_to_indices = defaultdict(list)\n",
    "for gidx in global_indices:\n",
    "    layer_idx  = gidx // hidden_size\n",
    "    neuron_idx = gidx %  hidden_size\n",
    "    layer_to_indices[layer_idx].append(int(neuron_idx))\n",
    "\n",
    "# Verifica que todo est√© correcto\n",
    "for L in sorted(layer_to_indices):\n",
    "    print(f\"Capa {L}: {len(layer_to_indices[L])} neuronas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957c463c",
   "metadata": {},
   "outputs": [],
   "source": [
    "handles = []  # para luego removerlos\n",
    "\n",
    "for layer_idx, layer in enumerate(model_goem.bert.encoder.layer):\n",
    "    idxs = layer_to_indices.get(layer_idx, [])\n",
    "    if idxs:\n",
    "        h = layer.output.LayerNorm.register_forward_hook(\n",
    "            make_cls_silence_hook(idxs)\n",
    "        )\n",
    "        handles.append(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26881cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si quieres adem√°s silenciar en la salida del pooler:\n",
    "final_layer_idxs = layer_to_indices.get(num_layers-1, [])\n",
    "if final_layer_idxs:\n",
    "    h = model_goem.bert.pooler.dense.register_forward_hook(\n",
    "        make_cls_silence_hook(final_layer_idxs)\n",
    "    )\n",
    "    handles.append(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217134b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67714ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "import torch\n",
    "\n",
    "def evaluate_silenced_model(\n",
    "    model,\n",
    "    sample_df,\n",
    "    labels_list,\n",
    "    target_ids_tensor,\n",
    "    device,\n",
    "    label2idx\n",
    "):\n",
    "    \"\"\"\n",
    "    Corre inferencia en el modelo (con hooks ya activos),\n",
    "    selecciona s√≥lo los logits de los target_ids_tensor,\n",
    "    calcula accuracy, f1 y classification_report.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    preds, trues = [], []\n",
    "    with torch.no_grad():\n",
    "        for i, row in sample_df.iterrows():\n",
    "            input_ids   = torch.tensor(row[\"input_ids\"]).unsqueeze(0).to(device)\n",
    "            attention_mask = torch.tensor(row[\"attention_mask\"]).unsqueeze(0).to(device)\n",
    "\n",
    "            logits = model(input_ids=input_ids, attention_mask=attention_mask).logits.squeeze(0)\n",
    "            sel_logits = logits[target_ids_tensor]\n",
    "            pred_local = torch.argmax(sel_logits).item()\n",
    "\n",
    "            preds.append(pred_local)\n",
    "            trues.append(labels_list[i])\n",
    "\n",
    "    acc = accuracy_score(trues, preds)\n",
    "    f1  = f1_score(trues, preds, average=\"weighted\", zero_division=0)\n",
    "    report_dict = classification_report(\n",
    "        trues,\n",
    "        preds,\n",
    "        labels=list(label2idx.values()),\n",
    "        target_names=[str(k) for k in sorted(label2idx.keys())],\n",
    "        zero_division=0,\n",
    "        output_dict=True\n",
    "    )\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"report\": report_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f83cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import defaultdict\n",
    "\n",
    "def silence_top_global_percentage_and_evaluate(\n",
    "    model,\n",
    "    sample_df,\n",
    "    labels_list,\n",
    "    probe,\n",
    "    label2idx,\n",
    "    percentage=0.10,\n",
    "    experiment_title=\"Silencing neurons\",\n",
    "    report_path=None,\n",
    "    custom_indices=None      # <-- nuevo par√°metro\n",
    "):\n",
    "    # ‚ë† Selecci√≥n de √≠ndices\n",
    "    if custom_indices is not None:\n",
    "        top_neurons = custom_indices\n",
    "        print(f\"üîß Silencing custom list of {len(top_neurons)} neurons\")\n",
    "    else:\n",
    "        # si no se pasa custom_indices, volvemos a llamar al probe (no existe shadowing aqu√≠)\n",
    "        top_neurons, _ = linear_probe.get_top_neurons(\n",
    "            probe, percentage=percentage, class_to_idx=label2idx\n",
    "        )\n",
    "        print(f\"üîß Silencing {len(top_neurons)} neurons from probe (percentage={percentage})\")\n",
    "\n",
    "    # ‚ë° Mapeo global‚Üípor capa\n",
    "    hidden_size = model.config.hidden_size\n",
    "    layer_to_indices = defaultdict(list)\n",
    "    for gidx in top_neurons:\n",
    "        layer_idx  = gidx // hidden_size\n",
    "        neuron_idx = gidx %  hidden_size\n",
    "        layer_to_indices[layer_idx].append(int(neuron_idx))\n",
    "\n",
    "    # ‚ë¢ Registro de hooks\n",
    "    handles = []\n",
    "    for layer_idx, indices in layer_to_indices.items():\n",
    "        if not indices:\n",
    "            continue\n",
    "        # hook en la LayerNorm de cada encoder.layer\n",
    "        h = model.bert.encoder.layer[layer_idx].output.LayerNorm.register_forward_hook(\n",
    "            make_cls_silence_hook(indices)\n",
    "        )\n",
    "        handles.append(h)\n",
    "\n",
    "    # (Opcional) pooler\n",
    "    final_idxs = layer_to_indices.get(model.config.num_hidden_layers-1, [])\n",
    "    if final_idxs:\n",
    "        h = model.bert.pooler.dense.register_forward_hook(\n",
    "            make_cls_silence_hook(final_idxs)\n",
    "        )\n",
    "        handles.append(h)\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ ‚ë£ Evaluaci√≥n ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    from pathlib import Path\n",
    "    # aseg√∫rate de tener target_ids_tensor disponible en el scope\n",
    "    silence_scores = evaluate_silenced_model(\n",
    "        model,\n",
    "        sample_df,\n",
    "        labels_list,\n",
    "        target_ids_tensor,   # tu tensor con los IDs GoEmotions\n",
    "        device_goemo,\n",
    "        label2idx\n",
    "    )\n",
    "\n",
    "    # guardar el classification_report en CSV\n",
    "    report_df = (\n",
    "        pd.DataFrame(silence_scores[\"report\"])\n",
    "          .transpose()\n",
    "          .round(4)\n",
    "    )\n",
    "    # a√±adir fila de accuracy/f1 global si quieres\n",
    "    report_df.to_csv(report_path, index=True)\n",
    "    print(f\"‚úÖ Accuracy after silencing: {silence_scores['accuracy']:.4f}\")\n",
    "    print(f\"‚úÖ F1 Score after silencing: {silence_scores['f1']:.4f}\")\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ ‚ë§ Remove hooks ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    for h in handles:\n",
    "        h.remove()\n",
    "    print(\"‚úÖ All hooks removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672fdb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tras cargar sample_df, labels_list y probe como hac√≠as\n",
    "silence_top_global_percentage_and_evaluate(\n",
    "    model=model_goem,\n",
    "    sample_df=sample_df,\n",
    "    labels_list=labels_list,\n",
    "    probe=probe,\n",
    "    label2idx=label2idx,\n",
    "    percentage=0.8,\n",
    "    experiment_title=\"Silencing 10% Global Neurons\",\n",
    "    report_path=CSV_REPORT_GOBAL_SILENCING\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10108e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for h in handles:\n",
    "    h.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e986022",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
